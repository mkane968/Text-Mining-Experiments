{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial 5: Intro to Sentiment Analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPC+pB1IWG1PuNSoESMGnCk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkane968/Text-Mining-Experiments/blob/main/NLTK/Tutorial%205-1%3A%20Intro%20to%20Sentiment%20Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial 5-1: Intro to Sentiment Analysis"
      ],
      "metadata": {
        "id": "Bbr0cfEraN10"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment analysis is the practice of using algorithms to classify various samples of related text into overall positive and negative categories. With NLTK, you can employ these algorithms through powerful built-in machine learning operations to obtain insights from linguistic data.\n",
        "\n",
        "Based on [Exercise B: Sentiment Analysis in Natural Language Processing with Python/NLTK by Luciano M. Guasco](https://github.com/luchux/ipython-notebook-nltk/blob/master/NLP%20-%20MelbDjango.ipynb)"
      ],
      "metadata": {
        "id": "NyovRjxyaevV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Step 1: Explore the movie_reviews corpus*** "
      ],
      "metadata": {
        "id": "DvYftuKwaxDd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import movie_reviews from nltk and clean spacing"
      ],
      "metadata": {
        "id": "V0Nx_mEsbVKb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "X3Qsvmn0aGiT",
        "outputId": "066a5646-9e13-4ee8-c5d4-157ae2f74dfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Sentiment Polarity Dataset Version 2.0 Bo Pang and Lillian Lee  http://www.cs.cornell.edu/people/pabo/movie-review-data/  Distributed with NLTK with permission from the authors.  =======  Introduction  This README v2.0 (June, 2004) for the v2.0 polarity dataset comes from the URL http://www.cs.cornell.edu/people/pabo/movie-review-data .  =======  What\\'s New -- June, 2004  This dataset represents an enhancement of the review corpus v1.0 described in README v1.1: it contains more reviews, and labels were created with an improved rating-extraction system.  =======  Citation Info   This data was first used in Bo Pang and Lillian Lee, \"A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization  Based on Minimum Cuts\",  Proceedings of the ACL, 2004.  @InProceedings{Pang+Lee:04a,   author =       {Bo Pang and Lillian Lee},   title =        {A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts},   booktitle =    \"Proceedings of the ACL\",   year =         2004 }  =======  Data Format Summary   - review_polarity.tar.gz: contains this readme and  data used in   the experiments described in Pang/Lee ACL 2004.    Specifically:    Within the folder \"txt_sentoken\" are the 2000 processed down-cased   text files used in Pang/Lee ACL 2004; the names of the two   subdirectories in that folder, \"pos\" and \"neg\", indicate the true   classification (sentiment) of the component files according to our   automatic rating classifier (see section \"Rating Decision\" below).    File names consist of a cross-validation tag plus the name of the   original html file.  The ten folds used in the Pang/Lee ACL 2004 paper\\'s   experiments were:       fold 1: files tagged cv000 through cv099, in numerical order      fold 2: files tagged cv100 through cv199, in numerical order           ...      fold 10: files tagged cv900 through cv999, in numerical order    Hence, the file neg/cv114_19501.txt, for example, was labeled as   negative, served as a member of fold 2, and was extracted from the   file 19501.html in polarity_html.zip (see below).    Each line in each text file corresponds to a single sentence, as   determined by Adwait Ratnaparkhi\\'s sentence boundary detector   MXTERMINATOR.     Preliminary steps were taken to remove rating information from the   text files, but only the rating information upon which the rating   decision was based is guaranteed to have been removed. Thus, if the   original review contains several instances of rating information,   potentially given in different forms, those not recognized as valid   ratings remain part of the review text.  - polarity_html.zip: The original source files from which the   processed, labeled, and (randomly) selected data in   review_polarity.tar.gz was derived.    Specifically:      This data consists of unprocessed, unlabeled html files from the   IMDb archive of the rec.arts.movies.reviews newsgroup,   http://reviews.imdb.com/Reviews. The files in review_polarity.tar.gz   represent a processed subset of these files.   =======  Rating Decision (Appendix A)  This section describes how we determined whether a review was positive or negative.  The original html files do not have consistent formats -- a review may not have the author\\'s rating with it, and when it does, the rating can appear at different places in the file in different forms.  We only recognize some of the more explicit ratings, which are extracted via a set of ad-hoc rules.  In essence, a file\\'s classification is determined based on the first rating we were able to identify.   - In order to obtain more accurate rating decisions, the maximum rating must be specified explicitly, both for numerical ratings and star ratings.  (\"8/10\", \"four out of five\", and \"OUT OF ****: ***\" are examples of rating indications we recognize.)  - With a five-star system (or compatible number systems): three-and-a-half stars and up are considered positive,  two stars and below are considered negative. - With a four-star system (or compatible number system): three stars and up are considered positive,  one-and-a-half stars and below are considered negative.   - With a letter grade system: B or above is considered positive, C- or below is considered negative.  We attempted to recognize half stars, but they are specified in an especially free way, which makes them difficult to recognize.  Hence, we may lose a half star very occasionally; but this only results in 2.5 stars in five star system being categorized as negative, which is  still reasonable.   '"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('movie_reviews')\n",
        "from nltk.corpus import movie_reviews # These are movie reviews already separated as positive and negative.\n",
        "movie_reviews.readme().replace('\\n', ' ').replace('\\t', '').replace('``', '\"').replace(\"''\", '\"').replace('`', \"'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want, you can print the file ids from movie_reviews; it generates a very long list. But you can see the structure of the ids and how the label includes \"pos\" or \"neg\""
      ],
      "metadata": {
        "id": "Pr30athMbfr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#movie_reviews.fileids()"
      ],
      "metadata": {
        "id": "lUszG-ZZbgCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To determine how many movie reviews are in the corpus, print the length of the list of file ids"
      ],
      "metadata": {
        "id": "0ucelACgcPtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(movie_reviews.fileids())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6YFBq_EcVXu",
        "outputId": "946b0f23-d98e-485d-d25d-94f84862845c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's an additional cleaning trick to get rid of \\' in text - but only if there were no \" used. See how it works with just one file."
      ],
      "metadata": {
        "id": "Gzrs1XiCcaNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movie_reviews.raw(\"neg/cv000_29416.txt\").replace(\"\\n\", \"\").replace(\"'\", '\"').replace('\"', \"'\") "
      ],
      "metadata": {
        "id": "7atoJ3dEcYGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Step 2: Building and testing the classifier*** "
      ],
      "metadata": {
        "id": "LpekNwyLc55v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before building the classifier, you'll want to generate a list of stopwords which will NOT be considered when making lists of positive and negative words. We'll import English stopwords from NLTK and put them in \"stops,\" then add additional features we don't want to include in classification using stops.extend. To see check full list of stopwords, print stops."
      ],
      "metadata": {
        "id": "xDZrX3P9dSXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')  \n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stops = stopwords.words('english')\n",
        "stops.extend('.,[,],(,),;,/,-,\\',?,\",:,<,>,n\\'t,|,#,\\'s,\\\",\\'re,\\'ve,\\'ll,\\'d,\\'re'.split(','))\n",
        "stops.extend(',')\n",
        "#stops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7oDaru7dqA7",
        "outputId": "45042f4e-d5cf-4afc-ec73-9f4f5da859c4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the NaiveBayes Classifier. Learn more about Naive Bayes [here](https://www.analyticsvidhya.com/blog/2021/01/a-guide-to-the-naive-bayes-algorithm/). "
      ],
      "metadata": {
        "id": "tVFeM1Azd7L3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.classify import NaiveBayesClassifier\n",
        "import nltk.classify.util # Utility functions and classes for classifiers. Contains functions such as accuracy(classifier, gold)"
      ],
      "metadata": {
        "id": "TNf4UEcWd7a6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a function which, given a word, returns a dict `{word: True}.` This will be our feature in the classifier. "
      ],
      "metadata": {
        "id": "Rv2kNMtEeWww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word_feats(words):\n",
        "    return dict([(word, True) for word in words if word not in stops and word.isalpha()])"
      ],
      "metadata": {
        "id": "tSikwcVCeWI1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create new variables for all positive and all negative movie reviews and get combined length (should be same as  length of original file ids list)."
      ],
      "metadata": {
        "id": "RFhcNDA_e-4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos_ids = movie_reviews.fileids('pos')\n",
        "neg_ids = movie_reviews.fileids('neg')\n",
        "\n",
        "len(pos_ids) + len(neg_ids) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pcNw3kGe-gL",
        "outputId": "8593a121-3b63-4749-9e49-a83321d8b998"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We take the positive/negative words, create the feature for such words, and store it in a positive/negative features list. You can print pos_feats to check list of words has loaded correctly; it will print VERY long list, since it will include words from every positive review.\n"
      ],
      "metadata": {
        "id": "IrrKfwbifS2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos_feats = [(word_feats(movie_reviews.words(fileids=[f])), 'pos') for f in pos_ids]\n",
        "neg_feats = [(word_feats(movie_reviews.words(fileids=[f])), 'neg') for f in neg_ids]\n",
        "\n",
        "#pos_feats"
      ],
      "metadata": {
        "id": "qZTBXV8vfTBZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store 3/4 of features for training the classifier and check length of positive training features. "
      ],
      "metadata": {
        "id": "IMtJeNTjgNCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos_len_train = int(len(pos_feats) * 3 / 4)\n",
        "neg_len_train = int(len(neg_feats) * 3 / 4)\n",
        "\n",
        "pos_len_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_7g_OV6gOFl",
        "outputId": "6a312f4e-2cc8-4b54-b1f6-d0a06d4db5b9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "750"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine positive and negative training features into one set and put the rest in \"test features\" "
      ],
      "metadata": {
        "id": "FvC41GKMgbXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_feats = neg_feats[:neg_len_train] + pos_feats[:pos_len_train]\n",
        "test_feats = neg_feats[neg_len_train:] + pos_feats[pos_len_train:]"
      ],
      "metadata": {
        "id": "cokZ_I7igacQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a NaiveBayesClassifier with our training feature words."
      ],
      "metadata": {
        "id": "TmfvBYSAgjkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = NaiveBayesClassifier.train(train_feats)"
      ],
      "metadata": {
        "id": "_ODzgc6cgjHQ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get accuracy of the classifier we have just trained."
      ],
      "metadata": {
        "id": "lBzproVxgonT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy: ', nltk.classify.util.accuracy(classifier, test_feats))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAnPOblEgovV",
        "outputId": "7f38200a-34ad-4c21-ae23-fbbea4a77499"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see which words fit best in each class by getting the classifier's most informative features. "
      ],
      "metadata": {
        "id": "FQIFYUr_gu3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.show_most_informative_features()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0ZeR30Wgu9x",
        "outputId": "5fe079a8-a8d6-4c3c-9d09-d3de0023e694"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n",
            "             magnificent = True              pos : neg    =     15.0 : 1.0\n",
            "             outstanding = True              pos : neg    =     13.6 : 1.0\n",
            "               insulting = True              neg : pos    =     13.0 : 1.0\n",
            "              vulnerable = True              pos : neg    =     12.3 : 1.0\n",
            "               ludicrous = True              neg : pos    =     11.8 : 1.0\n",
            "                  avoids = True              pos : neg    =     11.7 : 1.0\n",
            "             uninvolving = True              neg : pos    =     11.7 : 1.0\n",
            "              astounding = True              pos : neg    =     10.3 : 1.0\n",
            "             fascination = True              pos : neg    =     10.3 : 1.0\n",
            "                 idiotic = True              neg : pos    =      9.8 : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###***Step 3: Classifying new data***"
      ],
      "metadata": {
        "id": "OqYtDEXkg7MW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add a new sentence to test our classifier and tokenize it, adding features to tokens that are NOT in \"stops\" we defined above."
      ],
      "metadata": {
        "id": "QtIJfk7-hEU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize, pos_tag\n",
        "\n",
        "sentence = \"I feel so miserable, it makes me amazing\"\n",
        "tokens = [word for word in word_tokenize(sentence) if word not in stops]\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORWI_qhUhD3j",
        "outputId": "b08327f7-37c0-4f2a-eabf-06368ef195d1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', 'feel', 'miserable', 'makes', 'amazing']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make tokens into features using word_feats function defined above."
      ],
      "metadata": {
        "id": "DnsXTKNPhZuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feats = word_feats(word for word in tokens)\n",
        "feats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obKYKmY1hZ1h",
        "outputId": "c297149d-1bad-43e5-e5ea-b752157e236a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'I': True, 'amazing': True, 'feel': True, 'makes': True, 'miserable': True}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use classifier to classify new sentence as either positive or negative. The result may not be what you expect!"
      ],
      "metadata": {
        "id": "wk-DyJoGhzsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.classify(feats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aYV-7yIZhy2l",
        "outputId": "195eb0bb-0d23-411c-ef45-ced21561f3f1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'pos'"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try classifying another sentence - go through the same tokenizing process."
      ],
      "metadata": {
        "id": "7hyPwIASiAQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence2 = \"You are a pathetic fool, a terrible excuse for a human being.\"\n",
        "tokens2 = [word for word in word_tokenize(sentence2) if word not in stops]\n",
        "tokens2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8I3Ci43UiAah",
        "outputId": "222bf238-cfb5-49d4-feb7-f2d8763da2c9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['You', 'pathetic', 'fool', 'terrible', 'excuse', 'human']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load tokens into new variable - instead of retaining all tokens, just capture the adjectives using `if pos[] == JJ`"
      ],
      "metadata": {
        "id": "NO2dphAviilC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "pos_tags2 = [pos for pos in pos_tag(tokens2) if pos[1] == 'JJ']\n",
        "pos_tags2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxAhIxPBiMXG",
        "outputId": "6ccb05f2-0955-4fae-baa8-9ba2c9667c9b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('pathetic', 'JJ'), ('terrible', 'JJ')]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Put reduced list of tokens into variable for classificaiton"
      ],
      "metadata": {
        "id": "AoZcDaGqjEgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feats2 = word_feats([word for (word,_) in pos_tags2])\n",
        "feats2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDO4_fJcjFFo",
        "outputId": "98b3ea67-e9d2-4449-889e-aa67659a8877"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pathetic': True, 'terrible': True}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use classifier to classify new sentence as either positive or negative."
      ],
      "metadata": {
        "id": "cc61rB-WiLYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.classify(feats2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OEAYqGgkjMb4",
        "outputId": "cc935e48-b730-4a34-da40-954588ee7ded"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'neg'"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Step 4: Incorporating bigram features***\n",
        "In order to improve the classifier, bigram features can be examined using `nltk.util.ngrams`. This is because, for instance, 'not funny' is very different from 'funny'."
      ],
      "metadata": {
        "id": "QzR7R_NhjTOC"
      }
    }
  ]
}