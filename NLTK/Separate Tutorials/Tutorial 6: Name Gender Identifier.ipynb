{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial 4-1: Name Gender Identifier.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMH9UIT/g/oT3V3rPDsPNNW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkane968/Text-Mining-Experiments/blob/main/NLTK/Tutorial%206%3A%20Name%20Gender%20Identifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial 6: Name Gender Identifier"
      ],
      "metadata": {
        "id": "vMmbC3Fdpft9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Building a feature extractor***\n",
        "\n",
        "An idea is to use the last letter of the name to predict the gender. For instance, names ending in a, e and i are likely to be female, while names ending in k, o, r, s and t are likely to be male."
      ],
      "metadata": {
        "id": "NO4My2LJplDG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature extractor which returns the last letter of a word"
      ],
      "metadata": {
        "id": "f7rtv2SrdFPr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyRo-wL0pLUE",
        "outputId": "1667aac4-7361-493e-af5d-53d93e83fcde"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'last_letter': 'n'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "def gender_features(word):\n",
        "    return {'last_letter': word[-1]}\n",
        "\n",
        "gender_features('John')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The returned dictionary is known as a feature set."
      ],
      "metadata": {
        "id": "H3Q1nzabpzwg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import and open the names corpus"
      ],
      "metadata": {
        "id": "EVBqXON8dI9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('names')\n",
        "from nltk.corpus import names\n",
        "\n",
        "names.readme().replace('\\n', ' ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "0wEXt9xCpy5P",
        "outputId": "85536762-e9ed-4807-fbf6-e50429163c6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/names.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Names Corpus, Version 1.3 (1994-03-29) Copyright (C) 1991 Mark Kantrowitz Additions by Bill Ross  This corpus contains 5001 female names and 2943 male names, sorted alphabetically, one per line.  You may use the lists of names for any purpose, so long as credit is given in any published work. You may also redistribute the list if you provide the recipients with a copy of this README file. The lists are not in the public domain (I retain the copyright on the lists) but are freely redistributable.  If you have any additions to the lists of names, I would appreciate receiving them.  Mark Kantrowitz <mkant+@cs.cmu.edu> http://www-2.cs.cmu.edu/afs/cs/project/ai-repository/ai/areas/nlp/corpora/names/'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the file ids in the names corpus"
      ],
      "metadata": {
        "id": "4AXgfnTxdMcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "names.fileids()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BelKDAvbqAsW",
        "outputId": "3590da9a-20f8-4356-8431-a17f77384776"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['female.txt', 'male.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the first five words in the female text file in corpus"
      ],
      "metadata": {
        "id": "9kXia0eWdPpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "names.words('female.txt')[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhCJ43SgqOjE",
        "outputId": "9e52ecdd-7fe0-4c9a-b5c4-8e83fa7dce8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Abagael', 'Abagail', 'Abbe', 'Abbey', 'Abbi']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To build the classifier, we need to prepare a list of examples and corresponding class labels."
      ],
      "metadata": {
        "id": "S7rXA_R8qXtO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create list of labeled names where names in female.tx file are labeled female and male.txt names labeled male, print first five in labeled names list"
      ],
      "metadata": {
        "id": "8SvHdppddQl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_names = ([(name, 'female') for name in names.words('female.txt')] + [(name, 'male') for name in names.words('male.txt')])\n",
        "labeled_names[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSNbIqwdqX2n",
        "outputId": "a7c20f2d-f9ae-4a67-a919-4049811da94d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Abagael', 'female'),\n",
              " ('Abagail', 'female'),\n",
              " ('Abbe', 'female'),\n",
              " ('Abbey', 'female'),\n",
              " ('Abbi', 'female')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We shuffle the data so that we can split it by index into training and test data.\n"
      ],
      "metadata": {
        "id": "Sw_OLvZPdUlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.shuffle(labeled_names) \n",
        "labeled_names[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkSwSWzyqpKL",
        "outputId": "20a5c4fc-e953-43c6-d3c0-c5a11afd40b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Norbert', 'male'),\n",
              " ('Stoddard', 'female'),\n",
              " ('Silvan', 'male'),\n",
              " ('Joete', 'female'),\n",
              " ('Nance', 'female')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create list of the last letter of each name in labeled names and corresponding gender, print first five\n"
      ],
      "metadata": {
        "id": "bVhfWK-sdW3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "featuresets = [(gender_features(n), gender) for (n, gender) in labeled_names]\n",
        "featuresets[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqfCS2dkqpUF",
        "outputId": "933d0fee-579a-4754-baa0-76da69afe2dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7944"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "print length of feature sets"
      ],
      "metadata": {
        "id": "XrW7PvG3daCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(featuresets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzZdjFioq-rQ",
        "outputId": "e526d11f-7d4d-43e6-aa0a-3771075cc295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7944"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We split the data into a training (80%) and test (20%) set:\n"
      ],
      "metadata": {
        "id": "ns6lv6wDdb7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import NaiveBayesClassifier\n",
        "\n",
        "TRAIN_SET_SIZE = round(len(featuresets) * .8)\n",
        "train_set, test_set = featuresets[:TRAIN_SET_SIZE], featuresets[TRAIN_SET_SIZE:]"
      ],
      "metadata": {
        "id": "kLKnVG7ddcC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also get the names in the test set, to be used later:"
      ],
      "metadata": {
        "id": "pjw4FYd0diEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_names = labeled_names[TRAIN_SET_SIZE:]"
      ],
      "metadata": {
        "id": "uJTvQ3KtdiMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define classifier"
      ],
      "metadata": {
        "id": "kwfV5lswdmbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = NaiveBayesClassifier.train(train_set)"
      ],
      "metadata": {
        "id": "rcr_L4I2rER0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " When working with large corpora, constructing a single list that contains the features of every instance can use up a large amount of memory. \n",
        " \n",
        "In these cases, use the function nltk.classify.apply_features, which returns an object that acts like a list but does not store all the feature sets in memory: \n",
        "\n",
        "from nltk.classify import apply_features\n",
        "\n",
        "train_names, test_names = labeled_names[:round(len(featuresets) * .8)], labeled_names[round(len(featuresets) * .8):]\n",
        "\n",
        "train_set = apply_features(gender_features, labeled_names[500:])\n",
        "\n",
        "test_set = apply_features(gender_features, labeled_names[:500])"
      ],
      "metadata": {
        "id": "jCbc5okldrYx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prints likelihood ratios for most informative features"
      ],
      "metadata": {
        "id": "mmoCXBsxdx9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.show_most_informative_features(10) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQd5cG2urOdY",
        "outputId": "42041e7a-e4d9-4418-95c4-909ea418bd0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n",
            "             last_letter = 'a'            female : male   =     31.8 : 1.0\n",
            "             last_letter = 'k'              male : female =     27.6 : 1.0\n",
            "             last_letter = 'v'              male : female =     10.4 : 1.0\n",
            "             last_letter = 'p'              male : female =      9.7 : 1.0\n",
            "             last_letter = 'd'              male : female =      8.8 : 1.0\n",
            "             last_letter = 'o'              male : female =      8.6 : 1.0\n",
            "             last_letter = 'm'              male : female =      7.6 : 1.0\n",
            "             last_letter = 'r'              male : female =      6.9 : 1.0\n",
            "             last_letter = 'g'              male : female =      4.9 : 1.0\n",
            "             last_letter = 'z'              male : female =      4.6 : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the classifer:"
      ],
      "metadata": {
        "id": "Kg01BMFurNoA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get labels from classifer"
      ],
      "metadata": {
        "id": "FMohaVH-d1B8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.labels()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8p3CeEXBrXee",
        "outputId": "ada7c6e4-9681-4ea4-b646-89373dfa17dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['male', 'female']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get accuracy of classifer"
      ],
      "metadata": {
        "id": "HiJODipHd3C1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.classify import accuracy\n",
        "\n",
        "round(accuracy(classifier, test_set), 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__oCJGdvreVQ",
        "outputId": "83f1d1b3-9965-43d7-bff9-b8805aabff73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.76"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test classifier on female name based on last letter of name"
      ],
      "metadata": {
        "id": "aOd8Gxoqd6JR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.classify(gender_features('Aphrodite'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "58-rmN-1rjCS",
        "outputId": "6b20805c-bd0f-4e58-9399-d604d5571c6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'female'"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test classifier on male name based on last letter of name"
      ],
      "metadata": {
        "id": "vb2nJFHpd71Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.classify(gender_features('Zeus'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cWgeoyThroGP",
        "outputId": "68120fdf-4d2f-42df-8315-0a9888eb8289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'male'"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building a classifier with more features:"
      ],
      "metadata": {
        "id": "W_2a5I9rrtNF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a classifier which lowercases first and last letter of word and identifies which letters are contained in word and at what frequency"
      ],
      "metadata": {
        "id": "PYKrKTtEd9Vd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gender_features2(name):\n",
        "    features = {}\n",
        "    features[\"first_letter\"] = name[0].lower()\n",
        "    features[\"last_letter\"] = name[-1].lower()\n",
        "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
        "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
        "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
        "    return features\n",
        "\n",
        "#gender_features2('John')"
      ],
      "metadata": {
        "id": "RXkJ422iryOb"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get features above for list of gendered names and put in list, print first item in list\n"
      ],
      "metadata": {
        "id": "l6b9sS6ueEMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "featuresets2 = [(gender_features2(n), gender) for (n, gender) in labeled_names]\n",
        "#featuresets2[0]"
      ],
      "metadata": {
        "id": "bcpKrKMfsb5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train new classifier on same set of male and female names above and get accuracy\n"
      ],
      "metadata": {
        "id": "HMwva_UUeGW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set2, test_set2 = featuresets2[:TRAIN_SET_SIZE], featuresets2[TRAIN_SET_SIZE:]\n",
        "classifier2 = NaiveBayesClassifier.train(train_set2)\n",
        "round(accuracy(classifier2, test_set2), 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZkjXjtusOtF",
        "outputId": "cec67aab-abb9-4cd3-cfbc-2c50ce02ed35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.79"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We would have expected that having too many specific features on a small dataset would lead to overfitting, but it seems the classifier was good at avoiding that since its performance is slightly better.\n",
        "\n"
      ],
      "metadata": {
        "id": "Gz97mbUDs1xy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show the most informative features for the new classifer\n"
      ],
      "metadata": {
        "id": "Ht57QYjHeHq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier2.show_most_informative_features(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SIJEN7Gs1RQ",
        "outputId": "91b512e5-35c4-4165-c03c-103191270cc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n",
            "             last_letter = 'a'            female : male   =     31.8 : 1.0\n",
            "             last_letter = 'k'              male : female =     27.6 : 1.0\n",
            "             last_letter = 'v'              male : female =     10.4 : 1.0\n",
            "             last_letter = 'p'              male : female =      9.7 : 1.0\n",
            "                count(v) = 2              female : male   =      8.9 : 1.0\n",
            "             last_letter = 'd'              male : female =      8.8 : 1.0\n",
            "             last_letter = 'o'              male : female =      8.6 : 1.0\n",
            "             last_letter = 'm'              male : female =      7.6 : 1.0\n",
            "             last_letter = 'r'              male : female =      6.9 : 1.0\n",
            "            first_letter = 'w'              male : female =      4.9 : 1.0\n",
            "             last_letter = 'g'              male : female =      4.9 : 1.0\n",
            "             last_letter = 'z'              male : female =      4.6 : 1.0\n",
            "             last_letter = 'b'              male : female =      4.4 : 1.0\n",
            "                count(a) = 3              female : male   =      4.3 : 1.0\n",
            "                count(w) = 1                male : female =      4.2 : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indeed, it seems the classifier is mainly using the last letter, along with some other features that happen to improve the accuracy."
      ],
      "metadata": {
        "id": "BBBM_QCLtlnP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Comparing the two classifiers using nltk.metrics***"
      ],
      "metadata": {
        "id": "Dqz0WE4Ctq2I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we start, here's a useful function for comparing strings:\n",
        "\n",
        "Edit distance is the number of characters that need to be substituted, inserted, or deleted, to transform s1 into s2.\n"
      ],
      "metadata": {
        "id": "HF6jWhBfuBDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.metrics import edit_distance\n",
        "\n",
        "edit_distance(\"John\", \"Joan\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQeLK08TtqFb",
        "outputId": "376cc7db-5091-4baf-a42e-71f2881be112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The NLTK metrics module provides functions for calculating metrics beyond mere accuracy. But in order to do so, we need to build 2 sets for each classification label: a reference set of correct values, and a test set of observed values."
      ],
      "metadata": {
        "id": "7HxTDP7it2QE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "# Classifier 1\n",
        "refsets = collections.defaultdict(set) # For what this is: https://stackoverflow.com/questions/5900578/how-does-collections-defaultdict-work\n",
        "testsets = collections.defaultdict(set)\n",
        "\n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refsets[label].add(i)\n",
        "    observed = classifier.classify(feats)\n",
        "    testsets[observed].add(i)\n",
        "    \n",
        "# Classifier 2\n",
        "refsets2 = collections.defaultdict(set)\n",
        "testsets2 = collections.defaultdict(set)\n",
        "\n",
        "for i, (feats, label) in enumerate(test_set2):\n",
        "    refsets2[label].add(i)\n",
        "    observed = classifier2.classify(feats)\n",
        "    testsets2[observed].add(i)"
      ],
      "metadata": {
        "id": "5cGcq6DAt1r6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "refsets"
      ],
      "metadata": {
        "id": "1IanDshYuWW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testsets"
      ],
      "metadata": {
        "id": "trsn3MnvuZ_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can proceed to print the metrics for each classifier. \n",
        "\n",
        "However, we cannot get the accuracy in this manner because nltk.metrics.scores.accuracy(reference, test) works by comparing test[i] == reference[i] and our reference and test are not formatted in a way that allows for this.\n",
        "\n",
        "It's the same for the confusion matrix."
      ],
      "metadata": {
        "id": "FRlJlHvjeREN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.metrics.scores import (precision, recall, f_measure)\n",
        "\n",
        "args = (\n",
        "    round(precision(refsets['female'], testsets['female']), 2),\n",
        "    round(precision(refsets['male'], testsets['male']), 2),\n",
        "    round(recall(refsets['female'], testsets['female']), 2),\n",
        "    round(recall(refsets['male'], testsets['male']), 2),\n",
        "    round(f_measure(refsets['female'], testsets['female']), 2),\n",
        "    round(f_measure(refsets['male'], testsets['male']), 2)\n",
        ")\n",
        "\n",
        "args2 = (\n",
        "    round(precision(refsets2['female'], testsets2['female']), 2),\n",
        "    round(precision(refsets2['male'], testsets2['male']), 2),\n",
        "    round(recall(refsets2['female'], testsets2['female']), 2),\n",
        "    round(recall(refsets2['male'], testsets2['male']), 2),\n",
        "    round(f_measure(refsets2['female'], testsets2['female']), 2),\n",
        "    round(f_measure(refsets2['male'], testsets2['male']), 2)\n",
        ")\n",
        "\n",
        "print('''\n",
        "CLASSIFIER 1\n",
        "------------ \n",
        "Female precision: {0}\n",
        "Male precision: {1}\n",
        "Female recall: {2}\n",
        "Male recall: {3}\n",
        "Female F1 score: {4}\n",
        "Male F1 score: {5}\n",
        "\n",
        "CLASSIFIER 2\n",
        "------------ \n",
        "Female precision: {6}\n",
        "Male precision: {7}\n",
        "Female recall: {8}\n",
        "Male recall: {9}\n",
        "Female F1 score: {10}\n",
        "Male F1 score: {11}\n",
        "'''.format(*args, *args2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyRlMKCzuwdk",
        "outputId": "6722874a-caf4-4a7e-c320-e0f56db2b15e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CLASSIFIER 1\n",
            "------------ \n",
            "Female precision: 0.81\n",
            "Male precision: 0.67\n",
            "Female recall: 0.82\n",
            "Male recall: 0.66\n",
            "Female F1 score: 0.81\n",
            "Male F1 score: 0.67\n",
            "\n",
            "CLASSIFIER 2\n",
            "------------ \n",
            "Female precision: 0.83\n",
            "Male precision: 0.72\n",
            "Female recall: 0.85\n",
            "Male recall: 0.68\n",
            "Female F1 score: 0.84\n",
            "Male F1 score: 0.7\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Error analysis:*** Investigating errors of classifier (names whose gender was misclassified)"
      ],
      "metadata": {
        "id": "MHJ7NzkUvAqh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make list for errors and load in classifications where guess does not equal gender tag, print first five\n"
      ],
      "metadata": {
        "id": "I6IQErZleWNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "errors = []\n",
        "for (name, tag) in test_names:\n",
        "    guess = classifier2.classify(gender_features(name))\n",
        "    if guess != tag:\n",
        "        errors.append((tag, guess, name))\n",
        "\n",
        "errors[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SW13TLBvAQO",
        "outputId": "144d923b-9d28-434e-c161-f6e4a1767ea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('female', 'male', 'Christean'),\n",
              " ('female', 'male', 'Charis'),\n",
              " ('male', 'female', 'Cody'),\n",
              " ('male', 'female', 'Micah'),\n",
              " ('male', 'female', 'Tracie')]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print three columns (correct gender of name, guessed gender, and name itself)"
      ],
      "metadata": {
        "id": "VIWGyka0eY_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for (tag, guess, name) in sorted(errors):\n",
        "    #print('Correct = {:8} guess = {:8} name = {}'.format(tag, guess, name)) # :8 creates spaces between columns."
      ],
      "metadata": {
        "id": "3_uC-MRLvo8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking through this list of errors, it seems that some suffixes that are more than one letter long can be indicative of name genders. For example, names ending in yn appear to be predominantly female, despite the fact that names ending in n tend to be male; and names ending in ch are usually male, even though names that end in h tend to be female."
      ],
      "metadata": {
        "id": "vaLHTKNOv5yT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building a classifier with even more features in response to errors"
      ],
      "metadata": {
        "id": "nshIowSTwFH0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define new classifier which counts first letter and last two letters of word"
      ],
      "metadata": {
        "id": "DHM_oE0eegu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gender_features3(name):\n",
        "    features = {}\n",
        "    features[\"first_letter\"] = name[0].lower()\n",
        "    features[\"suffix1\"] = name[-1].lower()\n",
        "    features[\"suffix2\"] = name[-2:].lower()\n",
        "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
        "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
        "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
        "    return features\n",
        "\n",
        "#gender_features3('John')"
      ],
      "metadata": {
        "id": "GVSb4Hj9wCRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get features above for list of gendered names and put in list, print first item in list\n"
      ],
      "metadata": {
        "id": "6o_JeX8PesM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "featuresets3 = [(gender_features3(n), gender) for (n, gender) in labeled_names]\n",
        "featuresets3[0]"
      ],
      "metadata": {
        "id": "MSc2YjOzwj2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train new classifier on same set of male and female names above and get accuracy\n"
      ],
      "metadata": {
        "id": "IUDZtxgFey7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set3, test_set3 = featuresets3[:TRAIN_SET_SIZE], featuresets3[TRAIN_SET_SIZE:]\n",
        "classifier3 = NaiveBayesClassifier.train(train_set3)\n",
        "round(accuracy(classifier3, test_set3), 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKXAflRsw3jt",
        "outputId": "63854065-c214-44b4-d05c-1171f96ea916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get 15 most informative features for classifier3"
      ],
      "metadata": {
        "id": "o_5k6q5We1OU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier3.show_most_informative_features(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2j_6qzxw-JC",
        "outputId": "7bb9396b-f956-425f-9290-edc577b7d96b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n",
            "                 suffix2 = 'na'           female : male   =     84.0 : 1.0\n",
            "                 suffix2 = 'la'           female : male   =     67.8 : 1.0\n",
            "                 suffix2 = 'ra'           female : male   =     53.7 : 1.0\n",
            "                 suffix2 = 'ia'           female : male   =     49.4 : 1.0\n",
            "                 suffix2 = 'us'             male : female =     33.3 : 1.0\n",
            "                 suffix1 = 'a'            female : male   =     31.8 : 1.0\n",
            "                 suffix2 = 'rd'             male : female =     29.9 : 1.0\n",
            "                 suffix1 = 'k'              male : female =     27.6 : 1.0\n",
            "                 suffix2 = 'sa'           female : male   =     27.3 : 1.0\n",
            "                 suffix2 = 'ta'           female : male   =     21.9 : 1.0\n",
            "                 suffix2 = 'do'             male : female =     21.4 : 1.0\n",
            "                 suffix2 = 'ld'             male : female =     20.7 : 1.0\n",
            "                 suffix2 = 'rt'             male : female =     16.7 : 1.0\n",
            "                 suffix2 = 'ka'           female : male   =     14.8 : 1.0\n",
            "                 suffix2 = 'io'             male : female =     13.5 : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Maximum entropy classifier:*** The principle of maximum entropy states that the probability distribution which best represents the current state of knowledge is the one with largest entropy.\n",
        "\n",
        "The principle of maximum entropy is invoked when we have some piece(s) of information about a probability distribution, but not enough to characterize it completely—likely because we do not have the means or resources to do so. As an example, if all we know about a distribution is its average, we can imagine infinite shapes that yield a particular average. The principle of maximum entropy says that we should humbly choose the distribution that maximizes the amount of unpredictability contained in the distribution.\n",
        "\n",
        "Taking the idea to the extreme, it wouldn’t be scientific to choose a distribution that simply yields the average value 100% of the time.\n",
        "\n",
        "From all the models that fit our training data, the Maximum Entropy classifier selects the one which has the largest entropy. Due to the minimum assumptions that the Maximum Entropy classifier makes, it is usually used when we don’t know anything about the prior distributions and when it is unsafe to make any assumptions. Also, the maximum entropy classifier is used when we can’t assume the conditional independence of the features."
      ],
      "metadata": {
        "id": "S2mZgGDBxKTL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, the performance in terms of accuracy on the test set starts significantly improving beyond the previous model's at around 25 iterations.\n"
      ],
      "metadata": {
        "id": "3KYdrUoZe5VU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import MaxentClassifier\n",
        "\n",
        "# max_iter has default value 100. \n",
        "me_classifier = MaxentClassifier.train(train_set3, max_iter=25) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvjL3c6ExigH",
        "outputId": "6359fa6b-f6a4-41ae-ae2e-5f48204c8960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ==> Training (25 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -0.69315        0.373\n",
            "             2          -0.60435        0.627\n",
            "             3          -0.58273        0.627\n",
            "             4          -0.56287        0.633\n",
            "             5          -0.54470        0.668\n",
            "             6          -0.52810        0.703\n",
            "             7          -0.51296        0.730\n",
            "             8          -0.49913        0.752\n",
            "             9          -0.48651        0.767\n",
            "            10          -0.47497        0.779\n",
            "            11          -0.46440        0.787\n",
            "            12          -0.45471        0.792\n",
            "            13          -0.44580        0.795\n",
            "            14          -0.43760        0.795\n",
            "            15          -0.43004        0.798\n",
            "            16          -0.42304        0.799\n",
            "            17          -0.41656        0.801\n",
            "            18          -0.41055        0.802\n",
            "            19          -0.40495        0.805\n",
            "            20          -0.39974        0.806\n",
            "            21          -0.39487        0.807\n",
            "            22          -0.39032        0.808\n",
            "            23          -0.38606        0.809\n",
            "            24          -0.38206        0.810\n",
            "         Final          -0.37830        0.811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the accuracy of the me classifier. The accuracies above were on the training set so this is what matters.\n"
      ],
      "metadata": {
        "id": "AAlYbod-e7vw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "round(accuracy(me_classifier, test_set3), 2) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTpysUsvx-AR",
        "outputId": "9a63df04-bb25-4410-c831-2086b05165c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.81"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get 10 most informative features for me classifier\n"
      ],
      "metadata": {
        "id": "6lo8Bt0Be9p6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "me_classifier.show_most_informative_features(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s-6k6FJyKtC",
        "outputId": "42281ea8-b053-4281-dc92-8458a2ff0bfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -1.938 suffix2=='na' and label is 'male'\n",
            "  -1.922 suffix2=='la' and label is 'male'\n",
            "  -1.886 suffix2=='ra' and label is 'male'\n",
            "  -1.658 suffix2=='ia' and label is 'male'\n",
            "  -1.430 suffix2=='sa' and label is 'male'\n",
            "  -1.387 suffix1=='a' and label is 'male'\n",
            "  -1.346 suffix2=='us' and label is 'female'\n",
            "  -1.277 suffix1=='k' and label is 'female'\n",
            "  -1.217 suffix2=='ta' and label is 'male'\n",
            "  -1.213 suffix2=='rd' and label is 'female'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***More Classifiers:***\n",
        "Scikit-learn (sklearn) is a popular library which features various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN.\n",
        "\n",
        "NLTK provides an API to quickly use sklearn classifiers in nltk.classify.scikitlearn. The other option is to import and use sklearn directly.\n",
        "\n",
        "For an example of integrating sklearn with NLTK, you can check out [this notebook on Kaggle.](https://www.kaggle.com/alvations/basic-nlp-with-nltk) Kaggle is a great website for NLP and machine learning in general, creating an account is highly recommended."
      ],
      "metadata": {
        "id": "kLwG96ZHyTp7"
      }
    }
  ]
}
