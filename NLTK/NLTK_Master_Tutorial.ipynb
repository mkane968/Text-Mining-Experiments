{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLTK Master Tutorial.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMyHhlsSEdu7lRQuMYDvPrj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkane968/Text-Mining-Experiments/blob/main/NLTK/NLTK_Master_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NLTK Master Tutorial"
      ],
      "metadata": {
        "id": "DvUDzDlniodd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxO-w8foNimC"
      },
      "source": [
        "## Tutorial 1: Library Imports and NLTK.text Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P9as4d4O1SR"
      },
      "source": [
        "###***Downloading Libraries and Testing That They Are Working***\n",
        "\n",
        "Install and import necessary libraries to prepare for text analysis (need to run ! pip install for those not in Colab by default)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUjQB9_ZNeTS"
      },
      "source": [
        "import nltk # https://www.nltk.org/install.html\n",
        "import numpy # https://www.scipy.org/install.html\n",
        "import matplotlib.pyplot # https://matplotlib.org/downloads.html\n",
        "import tweepy # https://github.com/tweepy/tweepy\n",
        "!pip install TwitterSearch\n",
        "import TwitterSearch # https://github.com/ckoepp/TwitterSearch\n",
        "!pip install unidecode\n",
        "import unidecode # https://pypi.python.org/pypi/Unidecode\n",
        "!pip install langdetect\n",
        "import langdetect # https://pypi.python.org/pypi/langdetect\n",
        "!pip install langid\n",
        "import langid # https://github.com/saffsd/langid.py\n",
        "import gensim # https://radimrehurek.com/gensim/install.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download NLTK packages including punkt and stopwords "
      ],
      "metadata": {
        "id": "QgpYFCv0lqw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.text import Text\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('reuters')"
      ],
      "metadata": {
        "id": "aY5Bm7YflpAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import and unzip Reuters corpus"
      ],
      "metadata": {
        "id": "f5QY5vcBmrdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import reuters\n",
        "nltk.download('reuters')\n",
        "!unzip /root/nltk_data/corpora/reuters.zip -d /root/nltk_data/corpora/."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AR16bNaOmrln",
        "outputId": "903793a0-6b88-4532-e320-f484c547790c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n",
            "Archive:  /root/nltk_data/corpora/reuters.zip\n",
            "replace /root/nltk_data/corpora/./reuters/cats.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMVw3A92Pe2H"
      },
      "source": [
        "### ***Text Analysis Using NLTK***\n",
        "\n",
        "Conduct basic tokenization and text analysis using NLTK.text module (concordancing, collocations, counting and indexing, distributional similarity, dispersion plot, plot, vocab, common contexts)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split string into tokens"
      ],
      "metadata": {
        "id": "dK8CVFsIlx-b"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guuFNSF8Pt1k",
        "outputId": "473b7f69-d077-43fe-9943-54d4dce1da92"
      },
      "source": [
        "my_string = \"Two plus two is four, minus one that's three — quick maths. Every day man's on the block. Smoke trees. See your girl in the park, that girl is an uckers. When the thing went quack quack quack, your men were ducking! Hold tight Asznee, my brother. He's got a pumpy. Hold tight my man, my guy. He's got a frisbee. I trap, trap, trap on the phone. Moving that cornflakes, rice crispies. Hold tight my girl Whitney.\"\n",
        "tokens = word_tokenize(my_string)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['two', 'plus', 'two', 'is', 'four']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lowercase tokens, then print first five tokens"
      ],
      "metadata": {
        "id": "JtIP4-74rEKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = [word.lower() for word in tokens]\n",
        "tokens[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cpM626lrEYj",
        "outputId": "b4a548f1-0a39-415e-b37c-01d7ef4f2137"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['two', 'plus', 'two', 'is', 'four']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assign text of tokens to variable t"
      ],
      "metadata": {
        "id": "f6HOF6pml27G"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItLI4yBZQJ4G",
        "outputId": "ed52f048-e758-46e3-a31a-ffd23011026f"
      },
      "source": [
        "t = Text(tokens)\n",
        "t"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Text: two plus two is four , minus one...>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOQ9TwmCQQ4y"
      },
      "source": [
        "This method of converting raw strings to NLTK Text instances can be used when reading text from a file. For instance: f = open('my-file.txt','rU') \n",
        "\n",
        "Opening a file with the mode 'U' or 'rU' will open a file for reading in universal newline mode. All three line ending conventions will be translated to a \"\\n\"\n",
        "\n",
        "raw = f.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jgKl9qmSjon"
      },
      "source": [
        "####***Get Concordances*** \n",
        "Concordance() is a method of the Text class of NLTK. It finds words and displays a context window. Word matching is not case-sensitive.\n",
        "\n",
        "`Concordance() `is defined as follows: concordance(self, word, width=79, lines=25). Note default values for optional params."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lE23TQbQOuP",
        "outputId": "63773599-ae58-4320-8079-42b5f1267202"
      },
      "source": [
        "t.concordance('uckers')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying 1 of 1 matches:\n",
            " girl in the park , that girl is an uckers . when the thing went quack quack q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYtLx_RpTAVW"
      },
      "source": [
        "####***Get Collocations*** \n",
        "Find multiple words which commonly co-occur\n",
        "\n",
        "def collocations(self, num=20, window_size=2). num is the max no. of collocations to print."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QO1vS3I5RhYt",
        "outputId": "89ae7528-6a4d-40c4-8842-3806cdc09833"
      },
      "source": [
        "t.collocations() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hold tight; quack quack\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNB-d6iiU0nT"
      },
      "source": [
        "####***Get Count*** \n",
        "Find frequency of word appearance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYWbp36ZTqWJ",
        "outputId": "dc27bb93-94a8-4489-9ebb-41832622f316"
      },
      "source": [
        "t.count('quack')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####***Get Index*** \n",
        "Find position of word in text"
      ],
      "metadata": {
        "id": "swMoLQARmXLt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3px_kHdUVEmd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ca22b7d-8d81-4432-a50e-0e7ead171c5c"
      },
      "source": [
        "t.index('two')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHFfz7UfTmRM"
      },
      "source": [
        "#### ***Get Distributional Similarity*** \n",
        "Find other words which appear in the same contexts as the specified word; list most similar words first.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhGnuWmvTlY8",
        "outputId": "a6978b86-7fb0-45e8-ccdf-203f90afca25"
      },
      "source": [
        "t.similar('brother') #similar(self, word, num=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drw2k8x0VXkV"
      },
      "source": [
        "####***Make Dispersion Plot*** \n",
        "Find and plot instances of word(s) as distributed across text. Reveals patterns in word positions. Each stripe represents an instance of a word, and each row represents the entire text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Sx3zdwgfVwCI",
        "outputId": "d2dcfb99-00bb-443f-dad1-7696f60efedd"
      },
      "source": [
        "t.dispersion_plot(['man', 'thing', 'quack']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBOtNw-1WMQY"
      },
      "source": [
        "####***Make Frequency Plot*** \n",
        "Find and plot specified number of most common tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "4SInmqqkWJ7s",
        "outputId": "faf56498-4df0-442b-adb9-0c80cc24318a"
      },
      "source": [
        "t.plot(20) # plots 20 most common tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQRXrFITWqTX"
      },
      "source": [
        "####***Get Most Frequent Vocab*** \n",
        "Find frequency of each token in text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSg-mOdaWmLw",
        "outputId": "8d966b51-08e3-42d1-c0f1-f4ce395c4f3b"
      },
      "source": [
        "t.vocab()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'!': 1,\n",
              "          \"'s\": 4,\n",
              "          ',': 8,\n",
              "          '.': 11,\n",
              "          'a': 2,\n",
              "          'an': 1,\n",
              "          'asznee': 1,\n",
              "          'block': 1,\n",
              "          'brother': 1,\n",
              "          'cornflakes': 1,\n",
              "          'crispies': 1,\n",
              "          'day': 1,\n",
              "          'ducking': 1,\n",
              "          'every': 1,\n",
              "          'four': 1,\n",
              "          'frisbee': 1,\n",
              "          'girl': 3,\n",
              "          'got': 2,\n",
              "          'guy': 1,\n",
              "          'he': 2,\n",
              "          'hold': 3,\n",
              "          'i': 1,\n",
              "          'in': 1,\n",
              "          'is': 2,\n",
              "          'man': 2,\n",
              "          'maths': 1,\n",
              "          'men': 1,\n",
              "          'minus': 1,\n",
              "          'moving': 1,\n",
              "          'my': 4,\n",
              "          'on': 2,\n",
              "          'one': 1,\n",
              "          'park': 1,\n",
              "          'phone': 1,\n",
              "          'plus': 1,\n",
              "          'pumpy': 1,\n",
              "          'quack': 3,\n",
              "          'quick': 1,\n",
              "          'rice': 1,\n",
              "          'see': 1,\n",
              "          'smoke': 1,\n",
              "          'that': 3,\n",
              "          'the': 4,\n",
              "          'thing': 1,\n",
              "          'three': 1,\n",
              "          'tight': 3,\n",
              "          'trap': 3,\n",
              "          'trees': 1,\n",
              "          'two': 2,\n",
              "          'uckers': 1,\n",
              "          'went': 1,\n",
              "          'were': 1,\n",
              "          'when': 1,\n",
              "          'whitney': 1,\n",
              "          'your': 2,\n",
              "          '—': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXRsbd08YbEJ"
      },
      "source": [
        "####***Get Common Contexts*** \n",
        "Given two words used similarly, displays where in the text they were used similarly\n",
        "\n",
        "Our text is too small, so we will use a bigger one.\n",
        "\n",
        "NLTK comes with several interesting corpora, which are large collections of text. You can check out what kinds of corpora are found at http://www.nltk.org/nltk_data/ \n",
        "\n",
        "reuters is a corpus of news documents. More specifically, reuters is a corpus reader for the Reuters corpus which provides us with methods to access the corpus:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iyxa6vLW1Oh",
        "outputId": "3e7904fc-b0d4-48ea-8dc2-fa6ef81c0a4d"
      },
      "source": [
        "text = Text(reuters.words()) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in_1986 and_and by_. begins_1 paid_1986 in_, early_. or_, /_shipment\n",
            "of_. last_. for_shipment for_to on_3 on_12 on_19 last_when in_.\n",
            "in_1987 -_.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems that .common_contexts() takes 2 words which are used similarly and displays where they are used similarly. It also seems that '_' indicates where the words would be in the text.\n"
      ],
      "metadata": {
        "id": "6bQXcSrsm5X8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text.common_contexts(['August', 'June']) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-D24KAPRm5et",
        "outputId": "c76577c5-1653-44e4-b74c-43a5ec1f97d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in_1986 and_and by_. begins_1 paid_1986 in_, early_. or_, /_shipment\n",
            "of_. last_. for_shipment for_to on_3 on_12 on_19 last_when in_.\n",
            "in_1987 -_.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tutorial 2: Methods of Language Identification \n",
        "### (N-Gram, Stopword and Word Bigram Analysis)"
      ],
      "metadata": {
        "id": "9pJU0rMMcGtD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tutorial 2.1: Deriving N-Grams from Text**\n",
        "\n",
        "Based on [N-Gram-Based Text Categorization: Categorizing Text With Python by Alejandro Nolla](http://blog.alejandronolla.com/2013/05/20/n-gram-based-text-categorization-categorizing-text-with-python/)\n",
        "\n",
        "What are n-grams? See [here](https://cloudmark.github.io/Language-Detection/)."
      ],
      "metadata": {
        "id": "GTJI2-ALU05f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Tokenization:*** Divides strings of text into substrings of letters and apostrophes ONLY to prepare for n-gram analysis"
      ],
      "metadata": {
        "id": "RjaYkNAEVDOJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLZvk_4ZUu1H"
      },
      "outputs": [],
      "source": [
        "#Lowercase text in string\n",
        "s = \"Le temps est un grand maître, dit-on, le malheur est qu'il tue ses élèves.\"\n",
        "s = s.lower()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import regular expressions tokenizer and tokenize string\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "tokenizer = RegexpTokenizer(\"[a-zA-Z'`éèî]+\")\n",
        "s_tokenized = tokenizer.tokenize(s)\n",
        "s_tokenized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVBiQkhpVdzt",
        "outputId": "ad660060-b35e-43b9-c7f7-27d546ef1d5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['le',\n",
              " 'temps',\n",
              " 'est',\n",
              " 'un',\n",
              " 'grand',\n",
              " 'maître',\n",
              " 'dit',\n",
              " 'on',\n",
              " 'le',\n",
              " 'malheur',\n",
              " 'est',\n",
              " \"qu'il\",\n",
              " 'tue',\n",
              " 'ses',\n",
              " 'élèves']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Generating N-Grams:*** Finds n-length slices of a longer string, typically overlapping/in sequence; can be used for language detection"
      ],
      "metadata": {
        "id": "wkuxxJDxVwuF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import ngrams module and create list for generated ngrams"
      ],
      "metadata": {
        "id": "88NcW0AfVKlO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import ngrams\n",
        "generated_4grams = []\n",
        "\n"
      ],
      "metadata": {
        "id": "8MozGI4aV3LF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate ngram for each word in tokenized string"
      ],
      "metadata": {
        "id": "ydXRLBwXVU_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for word in s_tokenized:\n",
        "    generated_4grams.append(list(ngrams(word, 4, pad_left=True, pad_right=True, left_pad_symbol='_', right_pad_symbol='_'))) # n = 4.\n",
        "#generated_4grams"
      ],
      "metadata": {
        "id": "8QgaST1fVVgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems that generated_4grams needs flattening since it's supposed to be a list of 4-grams:"
      ],
      "metadata": {
        "id": "YfeR9ZBqV2l3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generated_4grams = [word for sublist in generated_4grams for word in sublist]\n",
        "#generated_4grams[:10]"
      ],
      "metadata": {
        "id": "DTqLwYALY84E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtaining n-grams (n = 4)\n",
        "Join 4grams into list of strings"
      ],
      "metadata": {
        "id": "-8lnKPwzaOGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ng_list_4grams = generated_4grams\n",
        "for idx, val in enumerate(generated_4grams):\n",
        "    ng_list_4grams[idx] = ''.join(val)\n",
        "#ng_list_4grams"
      ],
      "metadata": {
        "id": "N3540KisaNMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sort n-grams by how frequently they appear within the text. First, create list for n-grams sorted by frequency, iterate through ngrams and add to freq_4grams list as many times as appearing in list of strings"
      ],
      "metadata": {
        "id": "--vvU1CZavQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "freq_4grams = {}\n",
        "\n",
        "for ngram in ng_list_4grams:\n",
        "    if ngram not in freq_4grams:\n",
        "        freq_4grams.update({ngram: 1})\n",
        "    else:\n",
        "        ngram_occurrences = freq_4grams[ngram]\n",
        "        freq_4grams.update({ngram: ngram_occurrences + 1})\n",
        "      "
      ],
      "metadata": {
        "id": "FIvRnUepavYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The operator module exports a set of efficient functions corresponding to the intrinsic operators of Python. For example, operator.add(x, y) is equivalent to the expression x + y.\n"
      ],
      "metadata": {
        "id": "nF5zfRXzVrFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter "
      ],
      "metadata": {
        "id": "qoQ3-OUzVrM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We only keep the 300 most popular n-grams. This was suggested in the original paper written about n-grams."
      ],
      "metadata": {
        "id": "jytGIHefVve2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "freq_4grams_sorted = sorted(freq_4grams.items(), key=itemgetter(1), reverse=True)[0:300] \n",
        "#freq_4grams_sorted"
      ],
      "metadata": {
        "id": "hZWLI1QAVvl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtain n-grams for multiple values of n (n = 1, 2, 3, 4)\n",
        "For the code below we need the raw sentence as opposed to the tokens."
      ],
      "metadata": {
        "id": "dPt3vftZbO3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import everygrams\n",
        "\n",
        "s_clean = ' '.join(s_tokenized) \n",
        "s_clean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PcvlXoFtbWk2",
        "outputId": "dba35f82-1848-41b7-b916-932677ab5feb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"le temps est un grand maître dit on le malheur est qu'il tue ses élèves\""
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define ngram extractor generating uni-grams, bigrams, trigrams and 4-grams of string (range set to 1-4)"
      ],
      "metadata": {
        "id": "oRg1ND0AV2Q-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ngram_extractor(sent):\n",
        "    return [''.join(ng) for ng in everygrams(sent.replace(' ', '_ _'), 1, 4) \n",
        "            if ' ' not in ng and '\\n' not in ng and ng != ('_',)]\n",
        "\n",
        "#ngram_extractor(s_clean)"
      ],
      "metadata": {
        "id": "imOf0UoEbrEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tutorial 2.2: Detecting Text Language by Counting Stopwords** \n",
        "\n",
        "Based on [Detecting Text Language With Python and NLTK by Alejandro Nolla](http://blog.alejandronolla.com/2013/05/15/detecting-text-language-with-python-and-nltk/)\n",
        "\n",
        "Stop words are words which are filtered out before processing because they are mostly grammatical as opposed to semantic in nature (e.g. search engines remove words like 'want')"
      ],
      "metadata": {
        "id": "gvbJKxQRdPrG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize text, regex-based tokenizer splitting text on whitespace and punctuation (except for underscore)"
      ],
      "metadata": {
        "id": "L2mKS4JtV_vQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Yo man, it's time for you to shut yo' mouth! I ain't even messin' dawg.\"\n",
        "import sys\n",
        "\n",
        "try:\n",
        "    from nltk.tokenize import wordpunct_tokenize \n",
        "except ImportError:\n",
        "    print('[!] You need to install nltk (http://nltk.org/index.html)')\n",
        "test_tokens = wordpunct_tokenize(text)\n",
        "#test_tokens"
      ],
      "metadata": {
        "id": "2-ImW1h0dPNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are other tokenizers e.g. RegexpTokenizer where you can enter your own regexp, WhitespaceTokenizer (similar to Python's string.split()) and BlanklineTokenizer."
      ],
      "metadata": {
        "id": "_D-Ytvpy1v8S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exploring NLTK Stopword Corpus** \n",
        "\n",
        "NLTK comes with a corpus of stop words in various languages."
      ],
      "metadata": {
        "id": "kl9cLYTb11Gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvpqeg0R2DJr",
        "outputId": "333562cd-daf7-4291-cf94-e2199437f37f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since this is raw text, we need to replace \\n's with spaces for it to be readable."
      ],
      "metadata": {
        "id": "dRvoXtmrWDAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.readme().replace('\\n', ' ') "
      ],
      "metadata": {
        "id": "6aDusZWzWDsV",
        "outputId": "6705e81d-886b-4de8-d983-2c297b4a4383",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Stopwords Corpus  This corpus contains lists of stop words for several languages.  These are high-frequency grammatical words which are usually ignored in text retrieval applications.  They were obtained from: http://anoncvs.postgresql.org/cvsweb.cgi/pgsql/src/backend/snowball/stopwords/  The stop words for the Romanian language were obtained from: http://arlc.ro/resources/  The English list has been augmented https://github.com/nltk/nltk_data/issues/22  The German list has been corrected https://github.com/nltk/nltk_data/pull/49  A Kazakh list has been added https://github.com/nltk/nltk_data/pull/52  A Nepali list has been added https://github.com/nltk/nltk_data/pull/83  An Azerbaijani list has been added https://github.com/nltk/nltk_data/pull/100  A Greek list has been added https://github.com/nltk/nltk_data/pull/103  An Indonesian list has been added https://github.com/nltk/nltk_data/pull/112 '"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most corpora consist of a set of files, each containing a piece of text. A list of identifiers for these files is accessed via fileids(). Here you can see the list of languages the corpus contains\n"
      ],
      "metadata": {
        "id": "zH7JF7EjWD79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.fileids() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RzNbpi72VQD",
        "outputId": "09875aac-0235-432e-95f8-41aff1ce6ec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['arabic',\n",
              " 'azerbaijani',\n",
              " 'bengali',\n",
              " 'danish',\n",
              " 'dutch',\n",
              " 'english',\n",
              " 'finnish',\n",
              " 'french',\n",
              " 'german',\n",
              " 'greek',\n",
              " 'hungarian',\n",
              " 'indonesian',\n",
              " 'italian',\n",
              " 'kazakh',\n",
              " 'nepali',\n",
              " 'norwegian',\n",
              " 'portuguese',\n",
              " 'romanian',\n",
              " 'russian',\n",
              " 'slovene',\n",
              " 'spanish',\n",
              " 'swedish',\n",
              " 'tajik',\n",
              " 'turkish']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explore raw corpus of Greek stopwords "
      ],
      "metadata": {
        "id": "1FOltxeUWLpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.raw('greek')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "Fy_-YGTs2wSi",
        "outputId": "ea20997c-fe77-4596-bcb2-37b6a7b625cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"αλλα\\nαν\\nαντι\\nαπο\\nαυτα\\nαυτεσ\\nαυτη\\nαυτο\\nαυτοι\\nαυτοσ\\nαυτουσ\\nαυτων\\nαἱ\\nαἳ\\nαἵ\\nαὐτόσ\\nαὐτὸς\\nαὖ\\nγάρ\\nγα\\nγα^\\nγε\\nγια\\nγοῦν\\nγὰρ\\nδ'\\nδέ\\nδή\\nδαί\\nδαίσ\\nδαὶ\\nδαὶς\\nδε\\nδεν\\nδι'\\nδιά\\nδιὰ\\nδὲ\\nδὴ\\nδ’\\nεαν\\nειμαι\\nειμαστε\\nειναι\\nεισαι\\nειστε\\nεκεινα\\nεκεινεσ\\nεκεινη\\nεκεινο\\nεκεινοι\\nεκεινοσ\\nεκεινουσ\\nεκεινων\\nενω\\nεπ\\nεπι\\nεἰ\\nεἰμί\\nεἰμὶ\\nεἰς\\nεἰσ\\nεἴ\\nεἴμι\\nεἴτε\\nη\\nθα\\nισωσ\\nκ\\nκαί\\nκαίτοι\\nκαθ\\nκαι\\nκατ\\nκατά\\nκατα\\nκατὰ\\nκαὶ\\nκι\\nκἀν\\nκἂν\\nμέν\\nμή\\nμήτε\\nμα\\nμε\\nμεθ\\nμετ\\nμετά\\nμετα\\nμετὰ\\nμη\\nμην\\nμἐν\\nμὲν\\nμὴ\\nμὴν\\nνα\\nο\\nοι\\nομωσ\\nοπωσ\\nοσο\\nοτι\\nοἱ\\nοἳ\\nοἷς\\nοὐ\\nοὐδ\\nοὐδέ\\nοὐδείσ\\nοὐδεὶς\\nοὐδὲ\\nοὐδὲν\\nοὐκ\\nοὐχ\\nοὐχὶ\\nοὓς\\nοὔτε\\nοὕτω\\nοὕτως\\nοὕτωσ\\nοὖν\\nοὗ\\nοὗτος\\nοὗτοσ\\nπαρ\\nπαρά\\nπαρα\\nπαρὰ\\nπερί\\nπερὶ\\nποια\\nποιεσ\\nποιο\\nποιοι\\nποιοσ\\nποιουσ\\nποιων\\nποτε\\nπου\\nποῦ\\nπρο\\nπροσ\\nπρόσ\\nπρὸ\\nπρὸς\\nπως\\nπωσ\\nσε\\nστη\\nστην\\nστο\\nστον\\nσόσ\\nσύ\\nσύν\\nσὸς\\nσὺ\\nσὺν\\nτά\\nτήν\\nτί\\nτίς\\nτίσ\\nτα\\nταῖς\\nτε\\nτην\\nτησ\\nτι\\nτινα\\nτις\\nτισ\\nτο\\nτοί\\nτοι\\nτοιοῦτος\\nτοιοῦτοσ\\nτον\\nτοτε\\nτου\\nτούσ\\nτοὺς\\nτοῖς\\nτοῦ\\nτων\\nτό\\nτόν\\nτότε\\nτὰ\\nτὰς\\nτὴν\\nτὸ\\nτὸν\\nτῆς\\nτῆσ\\nτῇ\\nτῶν\\nτῷ\\nωσ\\nἀλλ'\\nἀλλά\\nἀλλὰ\\nἀλλ’\\nἀπ\\nἀπό\\nἀπὸ\\nἀφ\\nἂν\\nἃ\\nἄλλος\\nἄλλοσ\\nἄν\\nἄρα\\nἅμα\\nἐάν\\nἐγώ\\nἐγὼ\\nἐκ\\nἐμόσ\\nἐμὸς\\nἐν\\nἐξ\\nἐπί\\nἐπεὶ\\nἐπὶ\\nἐστι\\nἐφ\\nἐὰν\\nἑαυτοῦ\\nἔτι\\nἡ\\nἢ\\nἣ\\nἤ\\nἥ\\nἧς\\nἵνα\\nὁ\\nὃ\\nὃν\\nὃς\\nὅ\\nὅδε\\nὅθεν\\nὅπερ\\nὅς\\nὅσ\\nὅστις\\nὅστισ\\nὅτε\\nὅτι\\nὑμόσ\\nὑπ\\nὑπέρ\\nὑπό\\nὑπὲρ\\nὑπὸ\\nὡς\\nὡσ\\nὥς\\nὥστε\\nὦ\\nᾧ\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean Greek stopwards by \\n with space"
      ],
      "metadata": {
        "id": "SSY_fJzTWUJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.raw('greek').replace('\\n', ' ') # Better"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "vb2e4r3f21zI",
        "outputId": "d7c945e0-b46d-4ab1-99b1-088b895cc0c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"αλλα αν αντι απο αυτα αυτεσ αυτη αυτο αυτοι αυτοσ αυτουσ αυτων αἱ αἳ αἵ αὐτόσ αὐτὸς αὖ γάρ γα γα^ γε για γοῦν γὰρ δ' δέ δή δαί δαίσ δαὶ δαὶς δε δεν δι' διά διὰ δὲ δὴ δ’ εαν ειμαι ειμαστε ειναι εισαι ειστε εκεινα εκεινεσ εκεινη εκεινο εκεινοι εκεινοσ εκεινουσ εκεινων ενω επ επι εἰ εἰμί εἰμὶ εἰς εἰσ εἴ εἴμι εἴτε η θα ισωσ κ καί καίτοι καθ και κατ κατά κατα κατὰ καὶ κι κἀν κἂν μέν μή μήτε μα με μεθ μετ μετά μετα μετὰ μη μην μἐν μὲν μὴ μὴν να ο οι ομωσ οπωσ οσο οτι οἱ οἳ οἷς οὐ οὐδ οὐδέ οὐδείσ οὐδεὶς οὐδὲ οὐδὲν οὐκ οὐχ οὐχὶ οὓς οὔτε οὕτω οὕτως οὕτωσ οὖν οὗ οὗτος οὗτοσ παρ παρά παρα παρὰ περί περὶ ποια ποιεσ ποιο ποιοι ποιοσ ποιουσ ποιων ποτε που ποῦ προ προσ πρόσ πρὸ πρὸς πως πωσ σε στη στην στο στον σόσ σύ σύν σὸς σὺ σὺν τά τήν τί τίς τίσ τα ταῖς τε την τησ τι τινα τις τισ το τοί τοι τοιοῦτος τοιοῦτοσ τον τοτε του τούσ τοὺς τοῖς τοῦ των τό τόν τότε τὰ τὰς τὴν τὸ τὸν τῆς τῆσ τῇ τῶν τῷ ωσ ἀλλ' ἀλλά ἀλλὰ ἀλλ’ ἀπ ἀπό ἀπὸ ἀφ ἂν ἃ ἄλλος ἄλλοσ ἄν ἄρα ἅμα ἐάν ἐγώ ἐγὼ ἐκ ἐμόσ ἐμὸς ἐν ἐξ ἐπί ἐπεὶ ἐπὶ ἐστι ἐφ ἐὰν ἑαυτοῦ ἔτι ἡ ἢ ἣ ἤ ἥ ἧς ἵνα ὁ ὃ ὃν ὃς ὅ ὅδε ὅθεν ὅπερ ὅς ὅσ ὅστις ὅστισ ὅτε ὅτι ὑμόσ ὑπ ὑπέρ ὑπό ὑπὲρ ὑπὸ ὡς ὡσ ὥς ὥστε ὦ ᾧ \""
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "List first 10 English stopwords"
      ],
      "metadata": {
        "id": "fmS3fvg5WWsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.words('english')[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URw5kJmJ29sW",
        "outputId": "b31ec8e2-bdeb-4bef-eb4b-cc8cadc8fba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also use .sents() which returns sentences. However, in our particular case, this will cause an error:"
      ],
      "metadata": {
        "id": "SwhMC1Lt3Gr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.sents('greek')"
      ],
      "metadata": {
        "id": "62ANltCg3D7D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "d8a479ae-582f-4d59-c506-9da9fa585425"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-e1185800ddd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'greek'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'WordListCorpusReader' object has no attribute 'sents'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The error is because the stopwords corpus reader is of type WordListCorpusReader so there are no sentences. It's the same for .paras()."
      ],
      "metadata": {
        "id": "XYocPA8t3mdf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count number of stopwords in English and Greek. There is a total of 444 Greek and English stop words"
      ],
      "metadata": {
        "id": "_9aZ5uAPWbEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(stopwords.words(['english', 'greek'])) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bnkkt54N3rG3",
        "outputId": "89c4bc8c-03b5-4f37-93dc-72bac1edbb04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "444"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Classifying texts based on stopwords:*** Loop through the list of stop words in all languages and check how many stop words our test text contains in each language. The text is then classified to be in the language in which it has the most stop words"
      ],
      "metadata": {
        "id": "1cf_06_2303X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create empty list to store ratio of stopwords in each language"
      ],
      "metadata": {
        "id": "BWwnZmjWWe2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "language_ratios = {}"
      ],
      "metadata": {
        "id": "ZCgtM_MoWfXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lowercase all tokens in test_tokens (\"Yo man, it's time for you to shut yo' mouth! I ain't even messin' dawg.\")\n"
      ],
      "metadata": {
        "id": "rsthknqHWfhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_words = [word.lower() for word in test_tokens] \n",
        "test_words_set = set(test_words)"
      ],
      "metadata": {
        "id": "xnpXtfAsWfoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iterate through test_tokens and output number of stopwords in each language the string contains\n"
      ],
      "metadata": {
        "id": "WuE8uZ3ZWmZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for language in stopwords.fileids():\n",
        "    stopwords_set = set(stopwords.words(language)) # For some languages eg. Russian, it would be a wise idea to tokenize the stop words by punctuation too.\n",
        "    common_elements = test_words_set.intersection(stopwords_set)\n",
        "    language_ratios[language] = len(common_elements) # language \"score\"\n",
        "    \n",
        "language_ratios"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7GSjR5-32Kg",
        "outputId": "ee5289f2-ab79-48a1-be67-09b0980eb881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'arabic': 0,\n",
              " 'azerbaijani': 0,\n",
              " 'bengali': 0,\n",
              " 'danish': 3,\n",
              " 'dutch': 0,\n",
              " 'english': 8,\n",
              " 'finnish': 0,\n",
              " 'french': 2,\n",
              " 'german': 1,\n",
              " 'greek': 0,\n",
              " 'hungarian': 1,\n",
              " 'indonesian': 0,\n",
              " 'italian': 1,\n",
              " 'kazakh': 0,\n",
              " 'nepali': 0,\n",
              " 'norwegian': 3,\n",
              " 'portuguese': 1,\n",
              " 'romanian': 2,\n",
              " 'russian': 0,\n",
              " 'slovene': 2,\n",
              " 'spanish': 1,\n",
              " 'swedish': 2,\n",
              " 'tajik': 0,\n",
              " 'turkish': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are determining the language for which the most stopwords were found in the string\n",
        "The key parameter to the max() function is a function that computes a key. \n",
        "In our case, we already have a key so we set key to languages_ratios.get which actually returns the key."
      ],
      "metadata": {
        "id": "hH19CSVkWrjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "most_rated_language = max(language_ratios, key=language_ratios.get) \n",
        "most_rated_language"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LmpdSKIo5QUa",
        "outputId": "4bffffca-5de8-4872-b670-0bfbb906d686"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'english'"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print stopwords in most rated language appearing in string (here it's English)\n"
      ],
      "metadata": {
        "id": "-HRTayK4WwzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_words_set.intersection(set(stopwords.words(most_rated_language)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNeSJ2wj5Ca7",
        "outputId": "72233302-f95b-4e11-8b3c-1e3be845c20b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ain', 'for', 'i', 'it', 's', 't', 'to', 'you'}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tutorial 2.3: Language Identifier Using Word Bigrams** \n",
        "\n",
        "Based on [this language identifier program on Github.](https://github.com/asif31iqbal/language-identifier)"
      ],
      "metadata": {
        "id": "3m6tGv3l6DrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries "
      ],
      "metadata": {
        "id": "C4vn5zXCW4Pj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import string\n",
        "import os\n",
        "from nltk import ngrams, FreqDist, word_tokenize\n",
        "nltk.download('punkt')\n",
        "from numpy import arange\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmzBMGUK6jSP",
        "outputId": "d1458af7-a5ee-4e3f-9e4c-bae990beaeed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create tokenizer method"
      ],
      "metadata": {
        "id": "6mArteQzXANa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ultimate_tokenize(sentence):\n",
        "    # Remove punctuation and digits\n",
        "    sentence = sentence.translate(str.maketrans('', '', string.punctuation + string.digits))\n",
        "    return word_tokenize(sentence.lower())"
      ],
      "metadata": {
        "id": "Fxxv1z-9W32C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Generating Word Tokens:*** Divide text into one-word slices; typically followed by frequency calcuations to determine language of origin"
      ],
      "metadata": {
        "id": "TAmj_wzw72OX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate word tokens from sample string"
      ],
      "metadata": {
        "id": "xEB_UT_OXGHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_example_text = 'Oh, then, I see Queen Mab hath been with you.'\n",
        "\n",
        "simple_example_tokens_words = ultimate_tokenize(simple_example_text)\n",
        "simple_example_tokens_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qb5qEsaK61As",
        "outputId": "a1a47799-6801-4082-c981-1a9b437dd6c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['oh', 'then', 'i', 'see', 'queen', 'mab', 'hath', 'been', 'with', 'you']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Break word token into characters and print characters in word token in position 0\n"
      ],
      "metadata": {
        "id": "VaQay3ljXJr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_example_tokens_chars = list(simple_example_tokens_words[0])\n",
        "simple_example_tokens_chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3C-wd5Cm7G4s",
        "outputId": "5eee92e7-dcdf-448e-f84b-d87d612accd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['o', 'h']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate and print list of 1-word word tokens (unigrams)"
      ],
      "metadata": {
        "id": "U4mVgNiEXMFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_example_tokens_words_unigrams = list(ngrams(simple_example_tokens_words, 1))\n",
        "simple_example_tokens_words_unigrams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVsn48ad7PNP",
        "outputId": "7327ef47-dc56-407d-850e-3af1343a04fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('oh',),\n",
              " ('then',),\n",
              " ('i',),\n",
              " ('see',),\n",
              " ('queen',),\n",
              " ('mab',),\n",
              " ('hath',),\n",
              " ('been',),\n",
              " ('with',),\n",
              " ('you',)]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate and print list of 2-word word tokens (word bigrams)"
      ],
      "metadata": {
        "id": "-tKPFpexXOwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_example_tokens_words_bigrams = list(ngrams(simple_example_tokens_words, 2, pad_left=True, pad_right=True, left_pad_symbol='_', right_pad_symbol='_'))\n",
        "simple_example_tokens_words_bigrams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJy9tj8t7fOP",
        "outputId": "128e9631-e0cc-4b57-9e9b-d87429c37910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('_', 'oh'),\n",
              " ('oh', 'then'),\n",
              " ('then', 'i'),\n",
              " ('i', 'see'),\n",
              " ('see', 'queen'),\n",
              " ('queen', 'mab'),\n",
              " ('mab', 'hath'),\n",
              " ('hath', 'been'),\n",
              " ('been', 'with'),\n",
              " ('with', 'you'),\n",
              " ('you', '_')]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create frequency distribution of word token unigrams"
      ],
      "metadata": {
        "id": "o6Q7sI24XWGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fdist = FreqDist(simple_example_tokens_words_unigrams)\n",
        "fdist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zNCVNOk8RvU",
        "outputId": "d81d6c42-ff46-4136-dfad-124d6fa43d1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({('been',): 1,\n",
              "          ('hath',): 1,\n",
              "          ('i',): 1,\n",
              "          ('mab',): 1,\n",
              "          ('oh',): 1,\n",
              "          ('queen',): 1,\n",
              "          ('see',): 1,\n",
              "          ('then',): 1,\n",
              "          ('with',): 1,\n",
              "          ('you',): 1})"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a dictionary for the unigrams; keys = word tokens, values = frequency counts"
      ],
      "metadata": {
        "id": "gmLuEvK1XYwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unigram_dict = dict()\n",
        "for k, v in fdist.items():\n",
        "        unigram_dict[' '.join(k)] = v\n",
        "unigram_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-KpM5A48f9c",
        "outputId": "93b55c92-4a61-4912-c9ec-c5cb6d1519ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'been': 1,\n",
              " 'hath': 1,\n",
              " 'i': 1,\n",
              " 'mab': 1,\n",
              " 'oh': 1,\n",
              " 'queen': 1,\n",
              " 'see': 1,\n",
              " 'then': 1,\n",
              " 'with': 1,\n",
              " 'you': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Open file (uploaded to Drive) and lowercase, replace \\n with spaces and list first 100 characters. File is sample document for training, comprised of transcript from meeting of Parliament (?).\n",
        "Make sure notebook is permitted to access google drive folders.\n",
        "\n",
        "file = 'https://raw.githubusercontent.com/hb20007/hands-on-nltk-tutorial/master/ngram_langid_files/LangId.train.English.txt'"
      ],
      "metadata": {
        "id": "VbOJQbfgXbMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file = '/content/drive/MyDrive/hm3_files/LangId.train.English'\n",
        "with open(file, encoding='utf8') as f:\n",
        "        content = f.read().lower()\n",
        "content.replace('\\n', '')[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "TfQH3LkV94A0",
        "outputId": "79e51428-60f6-4e24-b4f8-17c929af7286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-398bfe66c9ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/hm3_files/LangId.train.English'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/hm3_files/LangId.train.English'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Open file containing English unigrams of LangId file (uploaded to Drive), unpickle it (read binary file back into python) and assign its contents to new dictionary\n"
      ],
      "metadata": {
        "id": "tjf5FeTeXn0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file = '/content/drive/MyDrive/hm3_files/English.unigram.pickle'\n",
        "with open(file, 'rb') as handle:\n",
        "    unigram_english_dict = pickle.load(handle)\n",
        "unigram_english_dict"
      ],
      "metadata": {
        "id": "zEL8tw6D9_La",
        "outputId": "5e2a2308-7e55-41d5-a638-95829ee37a05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-9481e48f1fd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://github.com/hb20007/hands-on-nltk-tutorial/blob/master/ngram_langid_files/English.unigram.pickle'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#file = '/content/drive/MyDrive/hm3_files/English.unigram.pickle'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0munigram_english_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0munigram_english_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://github.com/hb20007/hands-on-nltk-tutorial/blob/master/ngram_langid_files/English.unigram.pickle'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Open file containing English bigrams of LangId file (uploaded to Drive), unpickle it (read binary file back into python) and assign its contents to new dictionary\n"
      ],
      "metadata": {
        "id": "6KZdqoS3Xst0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/hm3_files/English.bigram.pickle', 'rb') as handle:\n",
        "    bigram_english_dict = pickle.load(handle)\n",
        "bigram_english_dict"
      ],
      "metadata": {
        "id": "CmF90L4j-Ecq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count frequency of phrase in bigram english dictionary file"
      ],
      "metadata": {
        "id": "1ruQp7WCXw7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_english_dict.get('of the')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LS6_3qDA-KXT",
        "outputId": "4848edc8-16c7-4bcf-a7fa-54d29103609a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "904"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import operator and sort unigram frequencies from highest to lowest in unpickled dictionary, list top 10 \n"
      ],
      "metadata": {
        "id": "DP8Vg_zyX1HU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "english_unigram_freqs = sorted(unigram_english_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
        "english_unigram_freqs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxsd6SPT-QaA",
        "outputId": "df0e3532-5dde-4d56-f451-0dd5cf1cfc68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 5698),\n",
              " (',', 3853),\n",
              " ('.', 2829),\n",
              " ('of', 2769),\n",
              " ('to', 2490),\n",
              " ('and', 2040),\n",
              " ('in', 1668),\n",
              " ('is', 1303),\n",
              " ('a', 1301),\n",
              " ('that', 1205)]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create histogram of top 10 English word unigrams in unpickled dictionary"
      ],
      "metadata": {
        "id": "J3vTuX7b9-iz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set lables and values as corresponding to top ten most frequent English unigrams\n",
        "#Arrange indexes by length of labels and set height\n",
        "labels, values = zip(*english_unigram_freqs[:10])\n",
        "indexes = arange(len(labels))\n",
        "width = 0.8 # width = 1 would give bars that overlap because they are too close.\n",
        "\n",
        "#Size plot, axes and bars\n",
        "fig = plt.figure(figsize=(10,7))                                                               \n",
        "ax = fig.gca() # Get current axis\n",
        "rects = ax.bar(indexes, values, width)\n",
        "\n",
        "# Add title and axis labels\n",
        "fig.suptitle('Top 10 English word unigrams', fontsize=20)\n",
        "plt.xlabel('Word unigram', fontsize=14)\n",
        "plt.ylabel('Frequency', fontsize=14)\n",
        "\n",
        "# Display value of each bar on bar\n",
        "for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.text(rect.get_x() + rect.get_width() / 2., 50 + height, '%d' % int(height), ha='center', va='bottom') # Can also add color and fontweight arguments.\n",
        "\n",
        "# Remove the default x-axis tick numbers and use tick numbers of your own choosing:\n",
        "ax.set_xticks(indexes)\n",
        "# Replace the tick numbers with strings:\n",
        "ax.set_xticklabels(labels)\n",
        "\n",
        "plt.show()\n",
        "# plt.savefig('top10EnglishWordUnigrams.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "rq4j7gVm-TtN",
        "outputId": "f5ca3f46-a875-4810-cd0b-3aa8e16228a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating unigram and bigram frequencies for English, French and Italian from training files"
      ],
      "metadata": {
        "id": "B9L0PaTOD1Q-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function that gets ngram counts from file and returns counts in dictionary format\n",
        "def get_ngram_count_dict(tokens, n):\n",
        "    if n == 1:\n",
        "        n_grams = ngrams(tokens, n)\n",
        "    else:\n",
        "        n_grams = ngrams(tokens, n, pad_left=True, pad_right=True, left_pad_symbol='_', right_pad_symbol='_') \n",
        "# Fun fact: If I remove padding here and later when testing, and also remove the '_' from the unigram dicts, the accuracy rises slightly. \n",
        "# However, it's not statistically significant due to the small size of the data.\n",
        "    fdist = FreqDist(n_grams)\n",
        "    ngram_dict = dict()\n",
        "    for k,v in fdist.items():\n",
        "        ngram_dict[' '.join(k)] = v\n",
        "    return ngram_dict\n",
        "\n",
        "# Calls get_ngram_count_dict to get a unigram and bigram dict from file.\n",
        "def get_unigram_bigram_dicts(file):\n",
        "    with open(file, encoding='utf8') as f:\n",
        "        content = f.read()\n",
        "    tokens = ultimate_tokenize(content)\n",
        "    unigram_dict = get_ngram_count_dict(tokens, 1)     \n",
        "    bigram_dict = get_ngram_count_dict(tokens, 2)     \n",
        "    return (unigram_dict, bigram_dict)\n",
        "\n",
        "# Dumps unigram and bigram dictionary of training data of given language to .pickle files.\n",
        "def dump_pickle(language):\n",
        "    file = '/content/drive/MyDrive/hm3_files/LangId.train.' + language \n",
        "    unigram_dict, bigram_dict = get_unigram_bigram_dicts(file)\n",
        "    with open('/content/drive/MyDrive/hm3_files/' + language + '.unigram.pickle', 'wb') as handle:\n",
        "      # HIGHEST_PROTOCOL instructs pickle to use the highest protocol version available.\n",
        "        pickle.dump(unigram_dict, handle, protocol=pickle.HIGHEST_PROTOCOL) \n",
        "    with open('/content/drive/MyDrive/hm3_files/' + language + '.bigram.pickle', 'wb') as handle:\n",
        "        pickle.dump(bigram_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "        \n",
        "dump_pickle('English')\n",
        "dump_pickle('French')\n",
        "dump_pickle('Italian')"
      ],
      "metadata": {
        "id": "pUhFFiI_D6gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Later, it will also be required to know how many sentences there are in the training data for each language. This is because of the method used to calculate probabilities (incorporating the probability of the bigram among other bigrams starting with the same word) and the fact we use padding for our bigrams.\n",
        "\n",
        "In our training data each line is a sentence, which is very convenient for calculating the number of sentences.\n",
        "\n",
        "We go ahead and get the number of sentences (for more efficiency, the following code could be added to get_unigram_bigram_dicts):\n",
        "\n",
        "Calculate number of sentences in each file of training data\n"
      ],
      "metadata": {
        "id": "569OuqYJD_ET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/hm3_files/LangId.train.English', encoding='utf8') as f:\n",
        "    for i, l in enumerate(f):\n",
        "        pass\n",
        "number_of_sents_en = i + 1\n",
        "with open('/content/drive/MyDrive/hm3_files/LangId.train.French', encoding='utf8') as f:\n",
        "    for i, l in enumerate(f):\n",
        "        pass\n",
        "number_of_sents_fr = i + 1\n",
        "with open('/content/drive/MyDrive/hm3_files/LangId.train.Italian', encoding='utf8') as f:\n",
        "    for i, l in enumerate(f):\n",
        "        pass\n",
        "number_of_sents_it = i + 1\n",
        "\n",
        "print('NUMBER OF SENTENCES IN TRAINING DATA')\n",
        "print('English:', number_of_sents_en)\n",
        "print('French:', number_of_sents_fr)\n",
        "print('Italian:', number_of_sents_it)"
      ],
      "metadata": {
        "id": "1cMvu9SIEGfS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "259360c4-7e22-4bbc-aef9-b7fc2a54911b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NUMBER OF SENTENCES IN TRAINING DATA\n",
            "English: 2980\n",
            "French: 2980\n",
            "Italian: 2821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identifying language for each line of the test file using bigram probabilities"
      ],
      "metadata": {
        "id": "hBLLKszQEHz6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unpickle files listing unigrams and bigrams in each test file and load unigrams into dictionary, calculate total size of unigram dictionary\n"
      ],
      "metadata": {
        "id": "hKaGAK4FYB97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/hm3_files/English.unigram.pickle', 'rb') as handle:\n",
        "    unigram_english_dict = pickle.load(handle)\n",
        "    \n",
        "with open('/content/drive/MyDrive/hm3_files/English.bigram.pickle', 'rb') as handle:\n",
        "    bigram_english_dict = pickle.load(handle)\n",
        "    \n",
        "with open('/content/drive/MyDrive/hm3_files/French.unigram.pickle', 'rb') as handle:\n",
        "    unigram_french_dict = pickle.load(handle)\n",
        "    \n",
        "with open('/content/drive/MyDrive/hm3_files/French.bigram.pickle', 'rb') as handle:\n",
        "    bigram_french_dict = pickle.load(handle)\n",
        "    \n",
        "with open('/content/drive/MyDrive/hm3_files/Italian.unigram.pickle', 'rb') as handle:\n",
        "    unigram_italian_dict = pickle.load(handle)\n",
        "    \n",
        "with open('/content/drive/MyDrive/hm3_files/Italian.bigram.pickle', 'rb') as handle:\n",
        "    bigram_italian_dict = pickle.load(handle)\n",
        "    \n",
        "vocabulary_size = len(unigram_english_dict) + len(unigram_french_dict) + len(unigram_italian_dict)\n",
        "vocabulary_size"
      ],
      "metadata": {
        "id": "z9hQ0GJ-EKEs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdd1214d-699f-4f4d-d097-b7b0b5eca6f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22705"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get probability of given bigram belonging to the language which bigram_dict is in\n",
        "\n",
        "first_word is the first word of the word bigram."
      ],
      "metadata": {
        "id": "jCUi1GwPYJ-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bigram_probability(bigram, first_word, bigram_dict, first_word_dict): \n",
        "    bigram_count = bigram_dict.get(bigram)\n",
        "    if bigram_count is None:\n",
        "        bigram_count = 0\n",
        "    \n",
        "    first_word_count = first_word_dict.get(first_word)\n",
        "    if first_word_count is None:\n",
        "        first_word_count = 0\n",
        "    \n",
        "    return (bigram_count + 1) / (first_word_count + vocabulary_size)"
      ],
      "metadata": {
        "id": "jNgVfnw13TkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get the logic of the formula above, note how the proability is used in the function below. Without the + 1 in the Nr, if you find a bigram which is not in our known bigrams for a language, the probability of it being in that language would become 0. \n",
        "\n",
        "So we would like to assign a small probability of 1 / vocabulary_size in that case. \n",
        "\n",
        "Also note the arbitrariness of this 'probability'. We're saying \"Given a bigram and a language, what is the probability that the bigram is of that language?\" This is arbitrary because to get a meaningful probability we need to know which are the other languages considered and what their bigram frequencies are. \n",
        "\n",
        "That would be another way to do it, but arguably a worse one because it wouldn't be able to give a confidence score for a particular language. The formula just uses common sense to get to a number which works for the purposes. \n",
        "\n",
        "In the denominator, we have both first_word_count and vocabulary_size. Why? We have vocabulary_size for all langs in the denom because the larger this is, the less significant it is that for this particular language the bigram appears so many times. \n",
        "\n",
        "Could we have used a vocab_size of bigrams instead of unigrams? Sure, and the 'probabilities' would end up being much smaller numbers. \n",
        "\n",
        "What about first_word_count? This gives us a way to compare this bigram against other bigrams in this language starting with the same word. \n",
        "\n",
        "In general though, for a given bigram, it's more important to consider how many times it exists than to consider whether it is the usual bigram given a certain first word. The formula achieves that. \n",
        "\n",
        "Take the bigram 'le monseiur' and the English language. Let's say the bigram appears once and 'le' also appears once, while in French 'le monseiur' appears 100 times and le appears 100,000 times. Probability for English = (1 + 1) / (1 + 20,000) = 0.000099995. Probability for French = (100 + 1) / (100,000 + 20,000) = 0.00084166666. \n",
        "\n",
        "Note how the probability for French is still low because 100/100,000 is quite low and maybe it's not French after all if in French le is usually followed by other words. However, it's still significantly higher than the probability for English where both 'le' and 'le monseiur' only appear once.\n",
        "  "
      ],
      "metadata": {
        "id": "DAFhPDj-3Uas"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get probability of given bigram belonging to the language which bigram_dict is in\n",
        "first_word is the first word of the word bigram."
      ],
      "metadata": {
        "id": "9fIPwZS0YOds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bigram_probability(bigram, first_word, bigram_dict, first_word_dict): \n",
        "    bigram_count = bigram_dict.get(bigram)\n",
        "    if bigram_count is None:\n",
        "        bigram_count = 0\n",
        "    \n",
        "    first_word_count = first_word_dict.get(first_word)\n",
        "    if first_word_count is None:\n",
        "        first_word_count = 0\n",
        "    \n",
        "    return (bigram_count + 1) / (first_word_count + vocabulary_size) \n",
        "    # To get the logic of this formula, note how the proability is used in the function below. Without the + 1 in the Nr, if you find a bigram which is not in our known bigrams for a language, the probability of it being in that language would become 0. So we would like to assign a small probability of 1 / vocabulary_size in that case. Also note the arbitrariness of this 'probability'. We're saying \"Given a bigram and a language, what is the probability that the bigram is of that language?\" This is arbitrary because to get a meaningful probability we need to know which are the other languages considered and what their bigram frequencies are. That would be another way to do it, but arguable a worse one because it wouldn't be able to give a confidence score for a particular language. The formula just uses common sense to get to a number which works for the purposes. In the denominator, we have both first_word_count and vocabulary_size. Why? We have vocabulary_size for all langs in the denom because the larger this is, the less significant it is that for this particular language the bigram appears so many times. Could we have used a vocab_size of bigrams instead of unigrams? Sure, and the 'probabilities' would end up being much smaller numbers. What about first_word_count? This gives us a way to compare this bigram against other bigrams in this language starting with the same word. In general though, for a given bigram, it's more important to consider how many times it exists than to consider whether it is the usual bigram given a certain first word. The formula achieves that. Take the bigram 'le monseiur' and the English language. Let's say the bigram appears once and 'le' also appears once, while in French 'le monseiur' appears 100 times and le appears 100,000 times. Probability for English = (1 + 1) / (1 + 20,000) = 0.000099995. Probability for French = (100 + 1) / (100,000 + 20,000) = 0.00084166666. Note how the probability for French is still low because 100/100,000 is quite low and maybe it's not French after all if in French le is usually followed by other words. However, it's still significantly higher than the probability for English where both 'le' and 'le monseiur' only appear once."
      ],
      "metadata": {
        "id": "nifhpoxrER8n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "736f94d0-e6a3-4b22-932f-086e313fdef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 98.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get probability that a given bigram list is of a language (specified by its bigram_dict)\n"
      ],
      "metadata": {
        "id": "ezE7-moXYS-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_language_probability(bigram_list, first_words, bigram_dict, first_word_dict):\n",
        "    result = 1.0\n",
        "    index = 0\n",
        "    for bigram in bigram_list:\n",
        "        result *= get_bigram_probability(bigram, first_words[index], bigram_dict, first_word_dict)\n",
        "        index += 1\n",
        "    return result"
      ],
      "metadata": {
        "id": "74Ay-YHzYTFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load correct solutions"
      ],
      "metadata": {
        "id": "j8WAldKzYX-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "solution_dict = dict()\n",
        "with open('/content/drive/MyDrive/hm3_files/LangId.sol') as f:\n",
        "    for line in f:\n",
        "       (key, val) = line.split()\n",
        "       solution_dict[int(key)] = val\n",
        "        \n",
        "line_no = 1\n",
        "result_dict = dict()\n",
        "correct = 0\n",
        "incorrect_line_numbers = []"
      ],
      "metadata": {
        "id": "zP13dR_4YYGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This needs to be done because I'm using padding for bigrams \n",
        "So the unigram dicts in their raw forms can't be used in get_bigram_probability():"
      ],
      "metadata": {
        "id": "lllK4hyIYcEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unigram_english_dict['_'] = number_of_sents_en\n",
        "unigram_french_dict['_'] = number_of_sents_fr\n",
        "unigram_italian_dict['_'] = number_of_sents_it"
      ],
      "metadata": {
        "id": "UE_GR3DvYcKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/hm3_files/LangId.test', encoding='utf8') as f:\n",
        "    for line in f:\n",
        "        tokens = ultimate_tokenize(line)\n",
        "        bigrams = ngrams(tokens, 2, pad_left=True, pad_right=True, left_pad_symbol='_', right_pad_symbol='_')\n",
        "        # bigram_list will be exactly like bigrams but instead of [('_', 'this'), ...] it will be ['_ this', ...]. \n",
        "        #It is required because this is how bigrams are represented in the dictionary.\n",
        "        bigram_list = [] \n",
        "        # The first words of each bigram. This is the similar to making a unigram_list. \n",
        "        #We use it because we don't want something in the form [(this,), ...]. \n",
        "        #Also because we want this to include '_'. \n",
        "        #We want it to include '_' because we're not using the unigrams for classification but as part of a formula to judge bigram frequency based on the starting word.\n",
        "        first_words = [] \n",
        "        for b in bigrams:\n",
        "            bigram_list.append(' '.join(b))\n",
        "            first_words.append(b[0])\n",
        "        \n",
        "        english_prob = get_language_probability(bigram_list, first_words, bigram_english_dict, unigram_english_dict)\n",
        "        french_prob = get_language_probability(bigram_list, first_words, bigram_french_dict, unigram_french_dict)\n",
        "        italian_prob = get_language_probability(bigram_list, first_words, bigram_italian_dict, unigram_italian_dict)\n",
        "        \n",
        "        max_prob = max(english_prob, french_prob, italian_prob)\n",
        "        if max_prob == english_prob:\n",
        "            result_dict[line_no] = 'English'\n",
        "        elif max_prob == french_prob:\n",
        "            result_dict[line_no] = 'French'\n",
        "        else:\n",
        "            result_dict[line_no] = 'Italian'\n",
        "        \n",
        "        if solution_dict[line_no] == result_dict[line_no]:\n",
        "            correct += 1\n",
        "        else:\n",
        "            incorrect_line_numbers.append(line_no)\n",
        "            \n",
        "        line_no += 1"
      ],
      "metadata": {
        "id": "7O6DoCUFYfKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Storing results from result_dict to file:"
      ],
      "metadata": {
        "id": "QbtC-o8bYjbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/hm3_files/LangId.result', 'w') as f:\n",
        "    for (key, val) in result_dict.items():\n",
        "        f.write(' '.join([str(key), val]) + '\\n')\n",
        "        \n",
        "print('Accuracy: {:2.2f}%'.format(correct * 100 / len(solution_dict)))"
      ],
      "metadata": {
        "id": "li9aIhseYjkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Line numbers for incorrectly classified languages: {}'.format(str(incorrect_line_numbers)))"
      ],
      "metadata": {
        "id": "MYV1kZZqEZq4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f93fdc2d-3be8-47ea-cd5d-10a3c0bac2e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Line numbers for incorrectly classified languages: [24, 87, 187, 191, 247, 279]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing with our own sentence\n",
        "\n",
        "Load string as sentence and tokenize, get word token bigrams, create list for sentence bigrams and first words of bigrams, append bigrams/first words\n"
      ],
      "metadata": {
        "id": "K_7jANRoEaFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent = \"This is a sentence.\"\n",
        "sent_tokens = ultimate_tokenize(sent)\n",
        "sent_bigrams_pre = ngrams(sent_tokens, 2, pad_left=True, pad_right=True, left_pad_symbol='_', right_pad_symbol='_')\n",
        "sent_bigrams = []\n",
        "sent_bigrams_first_words = []\n",
        "for b in sent_bigrams_pre:\n",
        "    sent_bigrams.append(' '.join(b))\n",
        "    sent_bigrams_first_words.append(b[0])\n",
        "print('Sentence bigrams:', sent_bigrams)\n",
        "print('Sentence bigrams first words:', sent_bigrams_first_words)"
      ],
      "metadata": {
        "id": "C4FFMzrLEcdg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0183e896-2bc2-44e8-cfae-ba4fe0eb6b20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence bigrams: ['_ this', 'this is', 'is a', 'a sentence', 'sentence _']\n",
            "Sentence bigrams first words: ['_', 'this', 'is', 'a', 'sentence']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate probability that sentence belongs to each language based on bigram and first word lists, print probabilites of each\n"
      ],
      "metadata": {
        "id": "hUBTYDNYY565"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent_english_prob = get_language_probability(sent_bigrams, sent_bigrams_first_words, bigram_english_dict, unigram_english_dict)\n",
        "sent_french_prob = get_language_probability(sent_bigrams, sent_bigrams_first_words, bigram_french_dict, unigram_french_dict)\n",
        "sent_italian_prob = get_language_probability(sent_bigrams, sent_bigrams_first_words, bigram_italian_dict, unigram_italian_dict)\n",
        "print(\"RAW 'PROBABILITIES'\")\n",
        "print('English:', sent_english_prob)\n",
        "print('French:', sent_french_prob)\n",
        "print('Italian:', sent_italian_prob)"
      ],
      "metadata": {
        "id": "LTHcjjlUEfnD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "638586ed-9a0e-4a51-ecbd-79a04b06e68e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAW 'PROBABILITIES'\n",
            "English: 1.6907852103961136e-18\n",
            "French: 1.4294173998895933e-22\n",
            "Italian: 1.4086603160283195e-22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, these 'probabilities' are arbitrary. We can try to convert them to percentages since we are classifying only among these 3 languages:"
      ],
      "metadata": {
        "id": "S5ser00v5sTi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define function to normalize probabilites and use to convert to percentages\n"
      ],
      "metadata": {
        "id": "6JpjSpMfY8iy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_normalized_probabilities(list_of_probabilities):\n",
        "    sum_of_probabilities = sum(list_of_probabilities)\n",
        "    result = []\n",
        "    for probability in list_of_probabilities:\n",
        "        result.append(probability / sum_of_probabilities)\n",
        "    return result\n",
        "\n",
        "probabilities = [sent_english_prob, sent_french_prob, sent_italian_prob]\n",
        "normalized_probabilities = get_normalized_probabilities(probabilities)\n",
        "\n",
        "print('RELATIVE PROBABILITIES')\n",
        "# I use sep because I don't want a space before the % sign.\n",
        "print('English: ', round(normalized_probabilities[0] * 100, 2), '%', sep='') \n",
        "print('French: ', round(normalized_probabilities[1] * 100, 2), '%', sep='')\n",
        "print('Italian: ', round(normalized_probabilities[2] * 100, 2), '%', sep='')\n"
      ],
      "metadata": {
        "id": "DjN3HJfzEiGc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc5a9d80-bef9-404a-aa6c-30a577b47ee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RELATIVE PROBABILITIES\n",
            "English: 99.98%\n",
            "French: 0.01%\n",
            "Italian: 0.01%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PS: For a state-of-the-art Greek dialect classifier using n-grams, take a look at [Greek Dialect Classifier.](https://github.com/hb20007/greek-dialect-classifier)\n"
      ],
      "metadata": {
        "id": "Rx4rxAa6Ejwc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LYaShvzEitPO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tutorial 3: Bigram Stemming and Lemmatization"
      ],
      "metadata": {
        "id": "J_j8KgoL9Ewv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Begin by exploring reuters corpus by retrieving file ids and categories. Reuters is a corpus of news documents. More specifically, reuters is a corpus reader for the Reuters corpus which provides us with methods to access the corpus:"
      ],
      "metadata": {
        "id": "IMX1ry0n-Oh-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing and replace \\n with spaces in reuters corpus"
      ],
      "metadata": {
        "id": "ilZbXKygZQov"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "Sf1WY-d_80wj",
        "outputId": "a38fd45d-085c-4daa-f772-34f8d3110268"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-396dbc14499c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreuters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'reuters'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mreuters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadme\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nltk' is not defined"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import reuters\n",
        "nltk.download('reuters')\n",
        "\n",
        "reuters.readme().replace('\\n', ' ')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieve file ids in reuter's corpus"
      ],
      "metadata": {
        "id": "ru3rCBW0ZT1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reuters.fileids()"
      ],
      "metadata": {
        "id": "ZStmIYoe-SuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieve file id in specific position in reuters corpus"
      ],
      "metadata": {
        "id": "yU9L6izPZWgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reuters.fileids()[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GhVXa_4p-XaO",
        "outputId": "e3551c54-a11c-499b-dbf8-65812cec33cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'training/9995'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get length of files ids (number of files) in reuters corpus\n"
      ],
      "metadata": {
        "id": "YGHnnaU8ZZph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(reuters.fileids())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otaOaV9n-YK0",
        "outputId": "c582b450-2e5b-45bf-87a7-2b21733cc4d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10788"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieve reuters categories"
      ],
      "metadata": {
        "id": "mUhmysDQZb8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reuters.categories()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ANjRxx6-7b6",
        "outputId": "804cc6e6-2142-4d67-b7fa-cea804ab4254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['acq',\n",
              " 'alum',\n",
              " 'barley',\n",
              " 'bop',\n",
              " 'carcass',\n",
              " 'castor-oil',\n",
              " 'cocoa',\n",
              " 'coconut',\n",
              " 'coconut-oil',\n",
              " 'coffee',\n",
              " 'copper',\n",
              " 'copra-cake',\n",
              " 'corn',\n",
              " 'cotton',\n",
              " 'cotton-oil',\n",
              " 'cpi',\n",
              " 'cpu',\n",
              " 'crude',\n",
              " 'dfl',\n",
              " 'dlr',\n",
              " 'dmk',\n",
              " 'earn',\n",
              " 'fuel',\n",
              " 'gas',\n",
              " 'gnp',\n",
              " 'gold',\n",
              " 'grain',\n",
              " 'groundnut',\n",
              " 'groundnut-oil',\n",
              " 'heat',\n",
              " 'hog',\n",
              " 'housing',\n",
              " 'income',\n",
              " 'instal-debt',\n",
              " 'interest',\n",
              " 'ipi',\n",
              " 'iron-steel',\n",
              " 'jet',\n",
              " 'jobs',\n",
              " 'l-cattle',\n",
              " 'lead',\n",
              " 'lei',\n",
              " 'lin-oil',\n",
              " 'livestock',\n",
              " 'lumber',\n",
              " 'meal-feed',\n",
              " 'money-fx',\n",
              " 'money-supply',\n",
              " 'naphtha',\n",
              " 'nat-gas',\n",
              " 'nickel',\n",
              " 'nkr',\n",
              " 'nzdlr',\n",
              " 'oat',\n",
              " 'oilseed',\n",
              " 'orange',\n",
              " 'palladium',\n",
              " 'palm-oil',\n",
              " 'palmkernel',\n",
              " 'pet-chem',\n",
              " 'platinum',\n",
              " 'potato',\n",
              " 'propane',\n",
              " 'rand',\n",
              " 'rape-oil',\n",
              " 'rapeseed',\n",
              " 'reserves',\n",
              " 'retail',\n",
              " 'rice',\n",
              " 'rubber',\n",
              " 'rye',\n",
              " 'ship',\n",
              " 'silver',\n",
              " 'sorghum',\n",
              " 'soy-meal',\n",
              " 'soy-oil',\n",
              " 'soybean',\n",
              " 'strategic-metal',\n",
              " 'sugar',\n",
              " 'sun-meal',\n",
              " 'sun-oil',\n",
              " 'sunseed',\n",
              " 'tea',\n",
              " 'tin',\n",
              " 'trade',\n",
              " 'veg-oil',\n",
              " 'wheat',\n",
              " 'wpi',\n",
              " 'yen',\n",
              " 'zinc']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieve sentences in specific file in reuters corpus"
      ],
      "metadata": {
        "id": "xFRA1zfTZeIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "reuters.sents('test/14826')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34dV_5P-_wuC",
        "outputId": "3ec6d4da-af28-4b2a-8476-877cbc30499d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['ASIAN', 'EXPORTERS', 'FEAR', 'DAMAGE', 'FROM', 'U', '.', 'S', '.-', 'JAPAN', 'RIFT', 'Mounting', 'trade', 'friction', 'between', 'the', 'U', '.', 'S', '.', 'And', 'Japan', 'has', 'raised', 'fears', 'among', 'many', 'of', 'Asia', \"'\", 's', 'exporting', 'nations', 'that', 'the', 'row', 'could', 'inflict', 'far', '-', 'reaching', 'economic', 'damage', ',', 'businessmen', 'and', 'officials', 'said', '.'], ['They', 'told', 'Reuter', 'correspondents', 'in', 'Asian', 'capitals', 'a', 'U', '.', 'S', '.', 'Move', 'against', 'Japan', 'might', 'boost', 'protectionist', 'sentiment', 'in', 'the', 'U', '.', 'S', '.', 'And', 'lead', 'to', 'curbs', 'on', 'American', 'imports', 'of', 'their', 'products', '.'], ...]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieving bigrams from files in Reuters corpus\n",
        "\n",
        "Load words in files under \"trade\" category into new variable and get length"
      ],
      "metadata": {
        "id": "mBskuQeI-dzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trade_words = reuters.words(categories='trade')\n",
        "len(trade_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2peV1kswAOf4",
        "outputId": "bd9e3dcd-a92b-4392-c893-b58629152291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "142723"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Put first 100 trade words in new variable"
      ],
      "metadata": {
        "id": "5SDRpX6HZj5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trade_words_condensed = trade_words[:100]\n",
        "trade_words_condensed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xxgd0e3jAec8",
        "outputId": "5f2967f1-21fe-42a8-d2b3-513380b73590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ASIAN', 'EXPORTERS', 'FEAR', 'DAMAGE', 'FROM', 'U', ...]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download and import stopwords from nltk\n",
        "\n",
        "Remove stopwords from trade_words_condensed and lower case it"
      ],
      "metadata": {
        "id": "vKBsgd3OZrse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "trade_words_condensed = [w.lower() for w in trade_words_condensed if w.lower() not in stopwords.words('english')]\n",
        "trade_words_condensed[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIRwerRrAl7V",
        "outputId": "2faed043-3328-4de4-a83f-7754d26289c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['asian',\n",
              " 'exporters',\n",
              " 'fear',\n",
              " 'damage',\n",
              " 'u',\n",
              " '.',\n",
              " '.-',\n",
              " 'japan',\n",
              " 'rift',\n",
              " 'mounting']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove punctuation"
      ],
      "metadata": {
        "id": "FHhRk5vtZxZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string \n",
        "# Contains string constants eg. ascii_lowercase which is 'a...z', string formatting functions, other string functions like .capwords() and .translate().\n",
        "\n",
        "# trade_words_condensed = [w for w in trade_words_condensed if w not in string.punctuation]\n",
        "punct_combo = [c + \"\\\"\" for c in string.punctuation ] + [\"\\\"\" + c for c in string.punctuation] + [\".-\", \":-\", \"..\", \"...\"]\n",
        "trade_words_condensed = [w for w in trade_words_condensed if w not in string.punctuation and w not in punct_combo]\n",
        "trade_words_condensed\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HOYcJ3UA1IU",
        "outputId": "16b50f18-675e-4be9-a96d-ecec439d754a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['asian',\n",
              " 'exporters',\n",
              " 'fear',\n",
              " 'damage',\n",
              " 'u',\n",
              " 'japan',\n",
              " 'rift',\n",
              " 'mounting',\n",
              " 'trade',\n",
              " 'friction',\n",
              " 'u',\n",
              " 'japan',\n",
              " 'raised',\n",
              " 'fears',\n",
              " 'among',\n",
              " 'many',\n",
              " 'asia',\n",
              " 'exporting',\n",
              " 'nations',\n",
              " 'row',\n",
              " 'could',\n",
              " 'inflict',\n",
              " 'far',\n",
              " 'reaching',\n",
              " 'economic',\n",
              " 'damage',\n",
              " 'businessmen',\n",
              " 'officials',\n",
              " 'said',\n",
              " 'told',\n",
              " 'reuter',\n",
              " 'correspondents',\n",
              " 'asian',\n",
              " 'capitals',\n",
              " 'u',\n",
              " 'move',\n",
              " 'japan',\n",
              " 'might',\n",
              " 'boost',\n",
              " 'protectionist',\n",
              " 'sentiment',\n",
              " 'u',\n",
              " 'lead',\n",
              " 'curbs',\n",
              " 'american',\n",
              " 'imports',\n",
              " 'products',\n",
              " 'exporters',\n",
              " 'said',\n",
              " 'conflict',\n",
              " 'would',\n",
              " 'hurt',\n",
              " 'long']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get bigrams for words in cleaned trade word list"
      ],
      "metadata": {
        "id": "4xILoihvZz9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import bigrams\n",
        "\n",
        "bi_trade_words_condensed = list(bigrams(trade_words_condensed))\n",
        "bi_trade_words_condensed[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qL-UjECA8g8",
        "outputId": "191446de-497d-4597-9f80-abbda226c701"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('asian', 'exporters'),\n",
              " ('exporters', 'fear'),\n",
              " ('fear', 'damage'),\n",
              " ('damage', 'u'),\n",
              " ('u', 'japan')]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create frequency distribution for bigrams in trade word list\n",
        "\n",
        "Print frequency of each word bigram"
      ],
      "metadata": {
        "id": "_5lXC4dgBMUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import FreqDist\n",
        "\n",
        "bi_fdist = FreqDist(bi_trade_words_condensed)\n",
        "\n",
        "for word, frequency in bi_fdist.most_common(3):\n",
        "    print(word, frequency)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUInWWtrBPun",
        "outputId": "57821105-5399-4822-eb88-b3b3e17f30e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('u', 'japan') 2\n",
            "('asian', 'exporters') 1\n",
            "('exporters', 'fear') 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot frequency distribution of word bigrams"
      ],
      "metadata": {
        "id": "AfUn5bY5Z4qJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bi_fdist.plot(3, cumulative=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "Hq1yxG8ICRf2",
        "outputId": "b90388bd-6abd-46a0-dcaa-c9080be28d9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Stemming:*** Reducing inflected words to their stem, based on root form \n",
        "\n",
        "Load each stemmer as variable and specify language\n",
        "\n",
        "Test how each imported stemmer stems sample text"
      ],
      "metadata": {
        "id": "BpDW257HCnPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import (PorterStemmer, LancasterStemmer)\n",
        "from nltk.stem.snowball import SnowballStemmer # This is \"Porter 2\" and is considered the optimal stemmer.\n",
        "\n",
        "porter = PorterStemmer()\n",
        "lancaster = LancasterStemmer()\n",
        "snowball = SnowballStemmer(\"english\")\n",
        "\n",
        "print(porter.stem('Re-testing'), lancaster.stem('Re-testing'), snowball.stem('Re-testing'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCZx2vf1CuJ3",
        "outputId": "e979ca15-5f54-4020-b5c9-e02a2d6a7019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "re-test re-testing re-test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fun fact: SnowballStemmer can stem several other languages beside English.\n",
        "\n",
        "To make, for instance, a French stemmer, we can do the following: french_stemmer = SnowballStemmer('french')"
      ],
      "metadata": {
        "id": "Wu4ss5fzaDjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SnowballStemmer.languages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rr2SjWOFDU_k",
        "outputId": "fbd954ce-4ced-4150-b010-17ab71f8dd5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('arabic',\n",
              " 'danish',\n",
              " 'dutch',\n",
              " 'english',\n",
              " 'finnish',\n",
              " 'french',\n",
              " 'german',\n",
              " 'hungarian',\n",
              " 'italian',\n",
              " 'norwegian',\n",
              " 'porter',\n",
              " 'portuguese',\n",
              " 'romanian',\n",
              " 'russian',\n",
              " 'spanish',\n",
              " 'swedish')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is an alternative that creates a dictionary mapping of every character from string.punctuation to None (this will also work but creates a whole dictionary so is slower)\n",
        "\n",
        "This uses the 3-argument version of str.maketrans with arguments (x, y, z) where 'x' and 'y' must be equal-length strings and characters in 'x' are replaced by characters in 'y'. 'z' is a string (string.punctuation here) where each character in the string is mapped to None"
      ],
      "metadata": {
        "id": "R_PFrLVfaH-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#translator = str.maketrans(dict.fromkeys(string.punctuation)\n",
        "from nltk import word_tokenize\n",
        "\n",
        "sentence = \"So, we'll go no more a-roving. So late into the night, Though the heart be still as loving, And the moon be still as bright.\"\n",
        "\n",
        "translator = str.maketrans('', '', string.punctuation)\n",
        "translator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYcPq_9WDYf0",
        "outputId": "88065ea3-febb-499b-dc79-a27af8d4b204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{33: None,\n",
              " 34: None,\n",
              " 35: None,\n",
              " 36: None,\n",
              " 37: None,\n",
              " 38: None,\n",
              " 39: None,\n",
              " 40: None,\n",
              " 41: None,\n",
              " 42: None,\n",
              " 43: None,\n",
              " 44: None,\n",
              " 45: None,\n",
              " 46: None,\n",
              " 47: None,\n",
              " 58: None,\n",
              " 59: None,\n",
              " 60: None,\n",
              " 61: None,\n",
              " 62: None,\n",
              " 63: None,\n",
              " 64: None,\n",
              " 91: None,\n",
              " 92: None,\n",
              " 93: None,\n",
              " 94: None,\n",
              " 95: None,\n",
              " 96: None,\n",
              " 123: None,\n",
              " 124: None,\n",
              " 125: None,\n",
              " 126: None}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(sentence.translate(translator))\n",
        "tokens[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ke4-zZ4NDviB",
        "outputId": "a37bdd14-6cd1-4404-d466-85a4f9cc6016"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['So', 'well', 'go']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for stemmer in [porter, lancaster, snowball]:\n",
        "    print([stemmer.stem(t) for t in tokens])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ni08n2GdDzEV",
        "outputId": "71bc2a55-f021-4f7b-e72b-038fd6c89cb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['So', 'well', 'go', 'no', 'more', 'arov', 'So', 'late', 'into', 'the', 'night', 'though', 'the', 'heart', 'be', 'still', 'as', 'love', 'and', 'the', 'moon', 'be', 'still', 'as', 'bright']\n",
            "['so', 'wel', 'go', 'no', 'mor', 'arov', 'so', 'lat', 'into', 'the', 'night', 'though', 'the', 'heart', 'be', 'stil', 'as', 'lov', 'and', 'the', 'moon', 'be', 'stil', 'as', 'bright']\n",
            "['so', 'well', 'go', 'no', 'more', 'arov', 'so', 'late', 'into', 'the', 'night', 'though', 'the', 'heart', 'be', 'still', 'as', 'love', 'and', 'the', 'moon', 'be', 'still', 'as', 'bright']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Lemmatization:*** Aims to achieve a similar base \"stem\" for a word, but aims to derive the genuine dictionary root word, not just a truncated version of the word."
      ],
      "metadata": {
        "id": "ogFONe2bD3-H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The default lemmatization method with the Python NLTK is the WordNet lemmatizer.\n"
      ],
      "metadata": {
        "id": "PkEcBVv2aO0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "from nltk import WordNetLemmatizer\n",
        "\n",
        "wnl = WordNetLemmatizer()\n",
        "\n",
        "print(wnl.lemmatize('brightening'), wnl.lemmatize('boxes'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEGjqDUBEIVQ",
        "outputId": "aed6011c-0172-4ba2-a6f3-1f3368732a7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "brightening box\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we saw above, sometimes, if we try to lemmatize a word, it will end up with the same word. This is because the default part of speech is nouns.\n"
      ],
      "metadata": {
        "id": "tTT6WwHDaQvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wnl.lemmatize('brightening', pos='v')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fkBbTEAUEO0X",
        "outputId": "887d431f-4a3a-42fb-c159-fd1b36daa3c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'brighten'"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tutorial 4: Finding Unusual Words in a Given Language"
      ],
      "metadata": {
        "id": "Wb-djpkr37F_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create string, import tokenizer, and tokenize and lowercase string"
      ],
      "metadata": {
        "id": "_J33FZWyawaE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kjsh10X3zHm",
        "outputId": "a1cd04cd-9b9d-4509-e909-76c36aeae5dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['truly',\n",
              " 'kryptic',\n",
              " 'is',\n",
              " 'the',\n",
              " 'best',\n",
              " 'puzzle',\n",
              " 'game',\n",
              " '.',\n",
              " 'it',\n",
              " \"'s\",\n",
              " 'browser-based',\n",
              " 'and',\n",
              " 'free',\n",
              " '.',\n",
              " 'google',\n",
              " 'it',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "text = \"Truly Kryptic is the best puzzle game. It's browser-based and free. Google it.\"\n",
        "\n",
        "from nltk import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "text_tokenized = word_tokenize(text.lower())\n",
        "text_tokenized"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import and explore the words corpus"
      ],
      "metadata": {
        "id": "DHEeEcbta2JR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('words')\n",
        "from nltk.corpus import words\n",
        "words.readme().replace('\\n', ' ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "3ovxQeUE4sLF",
        "outputId": "32ad8576-501a-4faf-fe69-85c9e3b94669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Wordlists  en: English, http://en.wikipedia.org/wiki/Words_(Unix) en-basic: 850 English words: C.K. Ogden in The ABC of Basic English (1932) '"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "List path name of words corpus"
      ],
      "metadata": {
        "id": "tiuXCayGa4NE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNd1E4YR41lZ",
        "outputId": "c7c88833-94db-410b-d01e-965c33171ab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<WordListCorpusReader in '/root/nltk_data/corpora/words'>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get file ids in words corpus"
      ],
      "metadata": {
        "id": "j3ZarXy9a6dU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words.fileids()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kowa3VY744Ex",
        "outputId": "cb6470ff-01e8-47dc-db04-950a219dae9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['en', 'en-basic']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get first ten words in en corpus"
      ],
      "metadata": {
        "id": "XkoQvHosa8TS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words.words('en')[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oK6ORciz47pK",
        "outputId": "7edd51cc-eea7-430f-c027-f9c82e6d5c8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A',\n",
              " 'a',\n",
              " 'aa',\n",
              " 'aal',\n",
              " 'aalii',\n",
              " 'aam',\n",
              " 'Aani',\n",
              " 'aardvark',\n",
              " 'aardwolf',\n",
              " 'Aaron']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get first 10 words in en-basic corpus"
      ],
      "metadata": {
        "id": "8YLCuroea-qV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words.words('en-basic')[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "talSusAt49be",
        "outputId": "db58f809-b152-4d6c-f601-79072a967271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I',\n",
              " 'a',\n",
              " 'able',\n",
              " 'about',\n",
              " 'account',\n",
              " 'acid',\n",
              " 'across',\n",
              " 'act',\n",
              " 'addition',\n",
              " 'adjustment']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get length of words in en corpus"
      ],
      "metadata": {
        "id": "5CsXy3FlbBC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(words.words('en'))"
      ],
      "metadata": {
        "id": "43ikDlZK5Apd",
        "outputId": "b7f467e4-8f6c-4178-a584-d80bc041fe6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235886"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get length of words in en-basic corpus"
      ],
      "metadata": {
        "id": "nghPi4vObDm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(words.words('en-basic'))"
      ],
      "metadata": {
        "id": "47gOM6qn5CdF",
        "outputId": "f2a5431e-b781-42d6-8d69-ae212b3fec24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "850"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find unusual words in given language"
      ],
      "metadata": {
        "id": "zID177O9bGfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "english_vocab = set(w.lower() for w in words.words())\n",
        "text_vocab = set(w.lower() for w in text_tokenized if w.isalpha()) # Note .isalpha() removes punctuation tokens. However, tokens with a hyphen like 'browser-based' are totally skipped over because .isalpha() would be false.\n",
        "unusual = text_vocab.difference(english_vocab)\n",
        "unusual"
      ],
      "metadata": {
        "id": "XKD3rjHC5EI6",
        "outputId": "0316d6ac-5287-4ef7-8cab-d11dd70c0786",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'google'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tutorial 5: Part of Speech Taggers and Named Entity Recognition"
      ],
      "metadata": {
        "id": "OjaJkuTM7U1i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Creating a POS Tagger:*** Create a tagger that will identify parts of speech in a given sentence. \n",
        "\n",
        "Train a classifier to work out which suffixes are most informative for POS tagging. \n",
        "\n",
        "We can begin by finding out what the most common suffixes are"
      ],
      "metadata": {
        "id": "KMvKHMH378LB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import brown corpus and frequency distribution module"
      ],
      "metadata": {
        "id": "RRZIYzBTbVGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('brown')\n",
        "from nltk.corpus import brown\n",
        "from nltk import FreqDist"
      ],
      "metadata": {
        "id": "poVKLWHW7TwA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e817620-840c-489e-804f-8bc36b93d532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Determine most frequent suffixes in brown corpus (frequency of last 1, 2, 3 characters in words in brown corpus)\n"
      ],
      "metadata": {
        "id": "bcI9GhaJbX1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "suffix_fdist = FreqDist()\n",
        "for word in brown.words():\n",
        "    word = word.lower()\n",
        "    suffix_fdist[word[-1:]] += 1\n",
        "    suffix_fdist[word[-2:]] += 1\n",
        "    suffix_fdist[word[-3:]] += 1\n",
        "    \n",
        "#suffix_fdist"
      ],
      "metadata": {
        "id": "jZsVGg25bX92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Put 100 most common suffixes into list and print the top 10\n"
      ],
      "metadata": {
        "id": "-RmDnvTgbb7Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxGLoBgc7Fc2",
        "outputId": "e1421228-8c6f-420c-b9fd-75d6c2384159"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['e', ',', '.', 's', 'd', 't', 'he', 'n', 'a', 'of']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "common_suffixes = [suffix for (suffix, count) in suffix_fdist.most_common(100)]\n",
        "common_suffixes[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll define a feature extractor function which checks a given word for these suffixes:"
      ],
      "metadata": {
        "id": "KlGFqYd3-M0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pos_features(word):\n",
        "    features = {}\n",
        "    for suffix in common_suffixes:\n",
        "        features['endswith({})'.format(suffix)] = word.lower().endswith(suffix)\n",
        "    return features\n",
        "\n",
        "#pos_features('test')"
      ],
      "metadata": {
        "id": "9o4K50Cm-PfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we've defined our feature extractor, we can use it to train a new decision tree classifier:"
      ],
      "metadata": {
        "id": "eOnbZVJ5-nuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_words = brown.tagged_words(categories='news')\n",
        "featuresets = [(pos_features(n), g) for (n,g) in tagged_words]\n",
        "#featuresets[0]"
      ],
      "metadata": {
        "id": "1x2mgkFt-ogI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import decision tree classifier and accuracy"
      ],
      "metadata": {
        "id": "JEySyouhbmmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import DecisionTreeClassifier\n",
        "from nltk.classify import accuracy"
      ],
      "metadata": {
        "id": "iTYi2mDW--3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set cutoff limit for classifier and training and test set variables"
      ],
      "metadata": {
        "id": "u6LCjvE7bpDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cutoff = int(len(featuresets) * 0.1)\n",
        "train_set, test_set = featuresets[cutoff:], featuresets[:cutoff]"
      ],
      "metadata": {
        "id": "4WPChi4mbpK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run classifer on training set\n",
        "\n",
        "NLTK is a teaching toolkit which is not really optimized for speed.\n",
        "\n",
        "Therefore, this may take forever. For speed, use scikit-learn for the classifiers."
      ],
      "metadata": {
        "id": "qQd68DaFbsHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = DecisionTreeClassifier.train(train_set) "
      ],
      "metadata": {
        "id": "7mXC0-ml_U2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "rLYIzFZn_wHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy(classifier, test_set)"
      ],
      "metadata": {
        "id": "bhJbLlax_hW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.classify(pos_features('cats'))"
      ],
      "metadata": {
        "id": "VW9J9lMz_lBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.pseudocode(depth=4)"
      ],
      "metadata": {
        "id": "_AEN3dGkAgYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To improve the classifier, we can add contextual features:\n",
        "\n",
        "def pos_features(sentence, i): [1]\n",
        "    features = {\"suffix(1)\": sentence[i][-1:],\n",
        "                \"suffix(2)\": sentence[i][-2:],\n",
        "                \"suffix(3)\": sentence[i][-3:]}\n",
        "    if i == 0:\n",
        "        features[\"prev-word\"] = \"<START>\"\n",
        "    else:\n",
        "        features[\"prev-word\"] = sentence[i-1]\n",
        "    return features\n",
        "Then, instead of working with tagged words, we work with tagged sentences:\n",
        "\n",
        "tagged_sents = brown.tagged_sents(categories='news')\n",
        "We can then improve this further by adding more features such as prev-tag etc."
      ],
      "metadata": {
        "id": "IMtv_V1-AlEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Parts of Speech and Meaning (English Only)***"
      ],
      "metadata": {
        "id": "W3EF0gKkAuiS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create string, import word tokenizer, tokenize words in t and print tokens in second sentence"
      ],
      "metadata": {
        "id": "tq5yjRexb0w4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = \"Cyprus, officially the Republic of Cyprus, is an island country in the Eastern Mediterranean and the third largest and third most populous island in the Mediterranean. Cyprus is located south of Turkey, west of Syria and Lebanon, northwest of Israel, north of Egypt, and southeast of Greece. Cyprus is a major tourist destination in the Mediterranean. With an advanced, high-income economy and a very high Human Development Index, the Republic of Cyprus has been a member of the Commonwealth since 1961 and was a founding member of the Non-Aligned Movement until it joined the European Union on 1 May 2004. On 1 January 2008, the Republic of Cyprus joined the eurozone.\"\n",
        "\n",
        "nltk.download('punkt')\n",
        "from nltk import sent_tokenize, word_tokenize\n",
        "sentences = sent_tokenize(t.lower())\n",
        "sentences\n",
        "\n",
        "tokens = word_tokenize(sentences[2])\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOZRzfGgBC-X",
        "outputId": "7fd0a043-027c-4777-8d17-a233d49578cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cyprus',\n",
              " 'is',\n",
              " 'a',\n",
              " 'major',\n",
              " 'tourist',\n",
              " 'destination',\n",
              " 'in',\n",
              " 'the',\n",
              " 'mediterranean',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import part of speech tagger from nltk and tag tokens in string t "
      ],
      "metadata": {
        "id": "Ryr_Jvtbb7Pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "tags = pos_tag(tokens)\n",
        "tags"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfGq1L7nB5lZ",
        "outputId": "3ba14aa8-0dfa-4759-a979-de3e8c1ea08e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('cyprus', 'NN'),\n",
              " ('is', 'VBZ'),\n",
              " ('a', 'DT'),\n",
              " ('major', 'JJ'),\n",
              " ('tourist', 'NN'),\n",
              " ('destination', 'NN'),\n",
              " ('in', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('mediterranean', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Access documentation for tags, for example for NN:"
      ],
      "metadata": {
        "id": "NdJQ-w1hb9Og"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk.help\n",
        "nltk.download('tagsets')\n",
        "nltk.help.upenn_tagset('NN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhEmLVvQCUQK",
        "outputId": "f8bf6243-ff8c-4dc5-b876-168d31f9e19e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Unzipping help/tagsets.zip.\n",
            "NN: noun, common, singular or mass\n",
            "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
            "    investment slide humour falloff slick wind hyena override subhumanity\n",
            "    machinist ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Word senses for homonyms***\n",
        "\n",
        "WordNet is a lexical database for the English language in the form of a semantic graph.\n",
        "\n",
        "WordNet groups English words into sets of synonyms called synsets, provides short definitions and usage examples, and records a number of relations among these synonym sets or their members.\n",
        "\n",
        "NLTK provides an interface to the WordNet API."
      ],
      "metadata": {
        "id": "0KvtmtcUHVOu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download wordnet and list set of synonyms (synset) for \"human\""
      ],
      "metadata": {
        "id": "7epspJ1pb_kw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet as wn\n",
        "wn.synsets('human')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcL1dW76HUsH",
        "outputId": "e97d8f25-2333-4765-edd8-c9f62353ef61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('homo.n.02'),\n",
              " Synset('human.a.01'),\n",
              " Synset('human.a.02'),\n",
              " Synset('human.a.03')]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get first definition human from synset"
      ],
      "metadata": {
        "id": "9Jd-5F1bcDJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synsets('human')[0].definition()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "exkSfSrhH3RX",
        "outputId": "06ecb9db-912a-433d-9a7f-988dc0c1011f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'any living or extinct member of the family Hominidae characterized by superior intelligence, articulate speech, and erect carriage'"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get second definition human from synset"
      ],
      "metadata": {
        "id": "SAXOy5dycHZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synsets('human')[1].definition()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AaQEs8rRH6Ot",
        "outputId": "96ccc1ba-fea9-4be7-dc7a-7e9e71bac23f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'characteristic of humanity'"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define variable \"human\" as \"human\" in synset"
      ],
      "metadata": {
        "id": "tIMtWLndcKFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "human = wn.synsets('Human', pos=wn.NOUN)[0]\n",
        "human"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqYmIyitIJ_j",
        "outputId": "b5e1b951-29bb-4e1a-90d9-68b5305f4858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Synset('homo.n.02')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A hypernym is a word with a broad meaning constituting a category into which words with more specific meanings fall a superordinate. \n"
      ],
      "metadata": {
        "id": "Uh7DqNYXcPtV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For example, colour is a hypernym of red.\n",
        "human.hypernyms() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFs0JpDnIe04",
        "outputId": "aad37ba5-e0c2-4398-9764-1eab1c35992a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('hominid.n.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "human.hyponyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4qvPPzKImG_",
        "outputId": "db30bf24-797e-4587-d66c-d73cdeaafb48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('homo_erectus.n.01'),\n",
              " Synset('homo_habilis.n.01'),\n",
              " Synset('homo_sapiens.n.01'),\n",
              " Synset('homo_soloensis.n.01'),\n",
              " Synset('neandertal_man.n.01'),\n",
              " Synset('rhodesian_man.n.01'),\n",
              " Synset('world.n.08')]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bike = wn.synsets('bicycle')[0]\n",
        "bike"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Wt79NhtIonc",
        "outputId": "f3591326-5e20-4a0b-a825-0a7fef92be5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Synset('bicycle.n.01')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "girl = wn.synsets('girl')[1]\n",
        "girl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9wnUKrvIqWG",
        "outputId": "8e5f2eff-c0d5-4ef2-f8eb-e256921832cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Synset('female_child.n.01')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Wu-Palmer metric (WUP) is a measure of similarity based on distance in the graph. There are many other metrics too.\n",
        "\n",
        "Get similarity between bike and human"
      ],
      "metadata": {
        "id": "gog72RtIcVYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bike.wup_similarity(human) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-d3aVqvIrCY",
        "outputId": "8ebe1005-f01d-46d0-9fd7-bcaf8a685569"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.34782608695652173"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get similarity between girl and human"
      ],
      "metadata": {
        "id": "NvCG8oYjcbNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "girl.wup_similarity(human)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZzN1zVHIwI8",
        "outputId": "19925ac5-a3e2-4de0-bbbc-74648878492f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5217391304347826"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get synonyms for 'girl'"
      ],
      "metadata": {
        "id": "gaM5vkXfcicS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "synonyms = []\n",
        "for syn in wn.synsets('girl'):\n",
        "    # A lemma is basically the dictionary form or base form of a word, as opposed to the various inflected forms of a word. \n",
        "    for lemma in syn.lemmas():\n",
        "        synonyms.append(lemma.name())\n",
        "synonyms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J28Jh2dEI5CN",
        "outputId": "fa3e7049-a0ff-44d2-a2a7-ad7087c2a562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['girl',\n",
              " 'miss',\n",
              " 'missy',\n",
              " 'young_lady',\n",
              " 'young_woman',\n",
              " 'fille',\n",
              " 'female_child',\n",
              " 'girl',\n",
              " 'little_girl',\n",
              " 'daughter',\n",
              " 'girl',\n",
              " 'girlfriend',\n",
              " 'girl',\n",
              " 'lady_friend',\n",
              " 'girl']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get antonyms for 'girl'"
      ],
      "metadata": {
        "id": "B5X3WtNYckLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "antonyms = []\n",
        "for syn in wn.synsets(\"girl\"):\n",
        "    for l in syn.lemmas():\n",
        "        if l.antonyms():\n",
        "            antonyms.append(l.antonyms()[0].name())\n",
        "antonyms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwW28ifjI99E",
        "outputId": "9e0b9a69-0cc5-42e1-904d-7a6c3dc7ed05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['male_child', 'boy', 'son', 'boy']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Chunking and Entity Recognition:***\n",
        "\n",
        "**Chunking:** Divide a sentence into chunks. Usually each chunk contains a head and (optionally) additional words and modifiers. Examples of chunks include noun groups and verb groups.\n",
        "\n"
      ],
      "metadata": {
        "id": "Q20lcuLPJK0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.chunk import RegexpParser"
      ],
      "metadata": {
        "id": "mbvgaxULL9Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to create a chunker, we need to first define a chunk grammar, consisting of rules that indicate how sentences should be chunked.\n",
        "\n",
        "We can define a simple grammar for a noun phrase (NP) chunker with a single regular-expression rule. This rule says that an NP chunk should be formed whenever the chunker finds an optional determiner (DT) followed by any number of adjectives (JJ) and then a noun (NN).\n",
        "\n",
        "Note how grammatical structures which are not noun phrases are not chunked, which is totally fine:"
      ],
      "metadata": {
        "id": "i4ascxpKMDV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')"
      ],
      "metadata": {
        "id": "wcem0OCoMLT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###DOES NOT WORK: no display name and no $DISPLAY environment variable\n",
        "\n",
        "chunker = RegexpParser(grammar)\n",
        "result = chunker.parse(tags)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "xVtdsAj6MMEx",
        "outputId": "018486a5-5923-426a-9d47-dd0d7be0f72c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TclError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/tree.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCanvasFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfind_binary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m         \u001b[0m_canvas_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCanvasFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m         \u001b[0mwidget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_to_treesegment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_canvas_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0m_canvas_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_widget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/draw/util.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parent, **kw)\u001b[0m\n\u001b[1;32m   1651\u001b[0m         \u001b[0;31m# If no parent was given, set up a top-level window.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1653\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1654\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NLTK'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<Control-p>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/tkinter/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, screenName, baseName, className, useTk, sync, use)\u001b[0m\n\u001b[1;32m   2021\u001b[0m                 \u001b[0mbaseName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2022\u001b[0m         \u001b[0minteractive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2023\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreenName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwantobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2024\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2025\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loadtk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTclError\u001b[0m: no display name and no $DISPLAY environment variable"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tree('S', [Tree('NP', [('cyprus', 'NN')]), ('is', 'VBZ'), Tree('NP', [('a', 'DT'), ('major', 'JJ'), ('tourist', 'NN')]), Tree('NP', [('destination', 'NN')]), ('in', 'IN'), Tree('NP', [('the', 'DT'), ('mediterranean', 'NN')]), ('.', '.')])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Entity Recognition:*** The goal of entity recogintion is to detect entities such as Person, Location, Time, etc."
      ],
      "metadata": {
        "id": "__WOUL17Mjv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###DOES NOT WORK: no display name and no $DISPLAY environment variable\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "from nltk.chunk import ne_chunk # ne = named entity\n",
        "ne_chunk(tags)"
      ],
      "metadata": {
        "id": "UTqRaDP0Mj6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note ne_chunk was unable to detect any entities in our sentence. That is because it is quite limited, being able to recognize only the following entities:\n",
        "\n",
        "FACILITY, GPE (Geo-Political Entity), GSP (Geo-Socio-Political group), LOCATION, ORGANIZATION, PERSON"
      ],
      "metadata": {
        "id": "aG1DariZNEhQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tutorial 6: Name Gender Identifier"
      ],
      "metadata": {
        "id": "vMmbC3Fdpft9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Building a feature extractor***\n",
        "\n",
        "An idea is to use the last letter of the name to predict the gender. For instance, names ending in a, e and i are likely to be female, while names ending in k, o, r, s and t are likely to be male."
      ],
      "metadata": {
        "id": "NO4My2LJplDG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature extractor which returns the last letter of a word"
      ],
      "metadata": {
        "id": "f7rtv2SrdFPr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyRo-wL0pLUE",
        "outputId": "1667aac4-7361-493e-af5d-53d93e83fcde"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'last_letter': 'n'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "def gender_features(word):\n",
        "    return {'last_letter': word[-1]}\n",
        "\n",
        "gender_features('John')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The returned dictionary is known as a feature set."
      ],
      "metadata": {
        "id": "H3Q1nzabpzwg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import and open the names corpus"
      ],
      "metadata": {
        "id": "EVBqXON8dI9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('names')\n",
        "from nltk.corpus import names\n",
        "\n",
        "names.readme().replace('\\n', ' ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "0wEXt9xCpy5P",
        "outputId": "85536762-e9ed-4807-fbf6-e50429163c6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/names.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Names Corpus, Version 1.3 (1994-03-29) Copyright (C) 1991 Mark Kantrowitz Additions by Bill Ross  This corpus contains 5001 female names and 2943 male names, sorted alphabetically, one per line.  You may use the lists of names for any purpose, so long as credit is given in any published work. You may also redistribute the list if you provide the recipients with a copy of this README file. The lists are not in the public domain (I retain the copyright on the lists) but are freely redistributable.  If you have any additions to the lists of names, I would appreciate receiving them.  Mark Kantrowitz <mkant+@cs.cmu.edu> http://www-2.cs.cmu.edu/afs/cs/project/ai-repository/ai/areas/nlp/corpora/names/'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the file ids in the names corpus"
      ],
      "metadata": {
        "id": "4AXgfnTxdMcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "names.fileids()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BelKDAvbqAsW",
        "outputId": "3590da9a-20f8-4356-8431-a17f77384776"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['female.txt', 'male.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the first five words in the female text file in corpus"
      ],
      "metadata": {
        "id": "9kXia0eWdPpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "names.words('female.txt')[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhCJ43SgqOjE",
        "outputId": "9e52ecdd-7fe0-4c9a-b5c4-8e83fa7dce8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Abagael', 'Abagail', 'Abbe', 'Abbey', 'Abbi']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To build the classifier, we need to prepare a list of examples and corresponding class labels."
      ],
      "metadata": {
        "id": "S7rXA_R8qXtO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create list of labeled names where names in female.tx file are labeled female and male.txt names labeled male, print first five in labeled names list"
      ],
      "metadata": {
        "id": "8SvHdppddQl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_names = ([(name, 'female') for name in names.words('female.txt')] + [(name, 'male') for name in names.words('male.txt')])\n",
        "labeled_names[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSNbIqwdqX2n",
        "outputId": "a7c20f2d-f9ae-4a67-a919-4049811da94d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Abagael', 'female'),\n",
              " ('Abagail', 'female'),\n",
              " ('Abbe', 'female'),\n",
              " ('Abbey', 'female'),\n",
              " ('Abbi', 'female')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We shuffle the data so that we can split it by index into training and test data.\n"
      ],
      "metadata": {
        "id": "Sw_OLvZPdUlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.shuffle(labeled_names) \n",
        "labeled_names[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkSwSWzyqpKL",
        "outputId": "20a5c4fc-e953-43c6-d3c0-c5a11afd40b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Norbert', 'male'),\n",
              " ('Stoddard', 'female'),\n",
              " ('Silvan', 'male'),\n",
              " ('Joete', 'female'),\n",
              " ('Nance', 'female')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create list of the last letter of each name in labeled names and corresponding gender, print first five\n"
      ],
      "metadata": {
        "id": "bVhfWK-sdW3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "featuresets = [(gender_features(n), gender) for (n, gender) in labeled_names]\n",
        "featuresets[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqfCS2dkqpUF",
        "outputId": "933d0fee-579a-4754-baa0-76da69afe2dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7944"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "print length of feature sets"
      ],
      "metadata": {
        "id": "XrW7PvG3daCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(featuresets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzZdjFioq-rQ",
        "outputId": "e526d11f-7d4d-43e6-aa0a-3771075cc295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7944"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We split the data into a training (80%) and test (20%) set:\n"
      ],
      "metadata": {
        "id": "ns6lv6wDdb7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import NaiveBayesClassifier\n",
        "\n",
        "TRAIN_SET_SIZE = round(len(featuresets) * .8)\n",
        "train_set, test_set = featuresets[:TRAIN_SET_SIZE], featuresets[TRAIN_SET_SIZE:]"
      ],
      "metadata": {
        "id": "kLKnVG7ddcC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also get the names in the test set, to be used later:"
      ],
      "metadata": {
        "id": "pjw4FYd0diEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_names = labeled_names[TRAIN_SET_SIZE:]"
      ],
      "metadata": {
        "id": "uJTvQ3KtdiMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define classifier"
      ],
      "metadata": {
        "id": "kwfV5lswdmbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = NaiveBayesClassifier.train(train_set)"
      ],
      "metadata": {
        "id": "rcr_L4I2rER0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " When working with large corpora, constructing a single list that contains the features of every instance can use up a large amount of memory. \n",
        " \n",
        "In these cases, use the function nltk.classify.apply_features, which returns an object that acts like a list but does not store all the feature sets in memory: \n",
        "\n",
        "from nltk.classify import apply_features\n",
        "\n",
        "train_names, test_names = labeled_names[:round(len(featuresets) * .8)], labeled_names[round(len(featuresets) * .8):]\n",
        "\n",
        "train_set = apply_features(gender_features, labeled_names[500:])\n",
        "\n",
        "test_set = apply_features(gender_features, labeled_names[:500])"
      ],
      "metadata": {
        "id": "jCbc5okldrYx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prints likelihood ratios for most informative features"
      ],
      "metadata": {
        "id": "mmoCXBsxdx9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.show_most_informative_features(10) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQd5cG2urOdY",
        "outputId": "42041e7a-e4d9-4418-95c4-909ea418bd0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n",
            "             last_letter = 'a'            female : male   =     31.8 : 1.0\n",
            "             last_letter = 'k'              male : female =     27.6 : 1.0\n",
            "             last_letter = 'v'              male : female =     10.4 : 1.0\n",
            "             last_letter = 'p'              male : female =      9.7 : 1.0\n",
            "             last_letter = 'd'              male : female =      8.8 : 1.0\n",
            "             last_letter = 'o'              male : female =      8.6 : 1.0\n",
            "             last_letter = 'm'              male : female =      7.6 : 1.0\n",
            "             last_letter = 'r'              male : female =      6.9 : 1.0\n",
            "             last_letter = 'g'              male : female =      4.9 : 1.0\n",
            "             last_letter = 'z'              male : female =      4.6 : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the classifer:"
      ],
      "metadata": {
        "id": "Kg01BMFurNoA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get labels from classifer"
      ],
      "metadata": {
        "id": "FMohaVH-d1B8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.labels()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8p3CeEXBrXee",
        "outputId": "ada7c6e4-9681-4ea4-b646-89373dfa17dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['male', 'female']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get accuracy of classifer"
      ],
      "metadata": {
        "id": "HiJODipHd3C1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.classify import accuracy\n",
        "\n",
        "round(accuracy(classifier, test_set), 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__oCJGdvreVQ",
        "outputId": "83f1d1b3-9965-43d7-bff9-b8805aabff73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.76"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test classifier on female name based on last letter of name"
      ],
      "metadata": {
        "id": "aOd8Gxoqd6JR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.classify(gender_features('Aphrodite'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "58-rmN-1rjCS",
        "outputId": "6b20805c-bd0f-4e58-9399-d604d5571c6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'female'"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test classifier on male name based on last letter of name"
      ],
      "metadata": {
        "id": "vb2nJFHpd71Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.classify(gender_features('Zeus'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cWgeoyThroGP",
        "outputId": "68120fdf-4d2f-42df-8315-0a9888eb8289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'male'"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building a classifier with more features:"
      ],
      "metadata": {
        "id": "W_2a5I9rrtNF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a classifier which lowercases first and last letter of word and identifies which letters are contained in word and at what frequency"
      ],
      "metadata": {
        "id": "PYKrKTtEd9Vd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gender_features2(name):\n",
        "    features = {}\n",
        "    features[\"first_letter\"] = name[0].lower()\n",
        "    features[\"last_letter\"] = name[-1].lower()\n",
        "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
        "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
        "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
        "    return features\n",
        "\n",
        "#gender_features2('John')"
      ],
      "metadata": {
        "id": "RXkJ422iryOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get features above for list of gendered names and put in list, print first item in list\n"
      ],
      "metadata": {
        "id": "l6b9sS6ueEMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "featuresets2 = [(gender_features2(n), gender) for (n, gender) in labeled_names]\n",
        "#featuresets2[0]"
      ],
      "metadata": {
        "id": "bcpKrKMfsb5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train new classifier on same set of male and female names above and get accuracy\n"
      ],
      "metadata": {
        "id": "HMwva_UUeGW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set2, test_set2 = featuresets2[:TRAIN_SET_SIZE], featuresets2[TRAIN_SET_SIZE:]\n",
        "classifier2 = NaiveBayesClassifier.train(train_set2)\n",
        "round(accuracy(classifier2, test_set2), 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZkjXjtusOtF",
        "outputId": "cec67aab-abb9-4cd3-cfbc-2c50ce02ed35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.79"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We would have expected that having too many specific features on a small dataset would lead to overfitting, but it seems the classifier was good at avoiding that since its performance is slightly better.\n",
        "\n"
      ],
      "metadata": {
        "id": "Gz97mbUDs1xy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show the most informative features for the new classifer\n"
      ],
      "metadata": {
        "id": "Ht57QYjHeHq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier2.show_most_informative_features(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SIJEN7Gs1RQ",
        "outputId": "91b512e5-35c4-4165-c03c-103191270cc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n",
            "             last_letter = 'a'            female : male   =     31.8 : 1.0\n",
            "             last_letter = 'k'              male : female =     27.6 : 1.0\n",
            "             last_letter = 'v'              male : female =     10.4 : 1.0\n",
            "             last_letter = 'p'              male : female =      9.7 : 1.0\n",
            "                count(v) = 2              female : male   =      8.9 : 1.0\n",
            "             last_letter = 'd'              male : female =      8.8 : 1.0\n",
            "             last_letter = 'o'              male : female =      8.6 : 1.0\n",
            "             last_letter = 'm'              male : female =      7.6 : 1.0\n",
            "             last_letter = 'r'              male : female =      6.9 : 1.0\n",
            "            first_letter = 'w'              male : female =      4.9 : 1.0\n",
            "             last_letter = 'g'              male : female =      4.9 : 1.0\n",
            "             last_letter = 'z'              male : female =      4.6 : 1.0\n",
            "             last_letter = 'b'              male : female =      4.4 : 1.0\n",
            "                count(a) = 3              female : male   =      4.3 : 1.0\n",
            "                count(w) = 1                male : female =      4.2 : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indeed, it seems the classifier is mainly using the last letter, along with some other features that happen to improve the accuracy."
      ],
      "metadata": {
        "id": "BBBM_QCLtlnP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Comparing the two classifiers using nltk.metrics***"
      ],
      "metadata": {
        "id": "Dqz0WE4Ctq2I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we start, here's a useful function for comparing strings:\n",
        "\n",
        "Edit distance is the number of characters that need to be substituted, inserted, or deleted, to transform s1 into s2.\n"
      ],
      "metadata": {
        "id": "HF6jWhBfuBDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.metrics import edit_distance\n",
        "\n",
        "edit_distance(\"John\", \"Joan\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQeLK08TtqFb",
        "outputId": "376cc7db-5091-4baf-a42e-71f2881be112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The NLTK metrics module provides functions for calculating metrics beyond mere accuracy. But in order to do so, we need to build 2 sets for each classification label: a reference set of correct values, and a test set of observed values."
      ],
      "metadata": {
        "id": "7HxTDP7it2QE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "# Classifier 1\n",
        "refsets = collections.defaultdict(set) # For what this is: https://stackoverflow.com/questions/5900578/how-does-collections-defaultdict-work\n",
        "testsets = collections.defaultdict(set)\n",
        "\n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refsets[label].add(i)\n",
        "    observed = classifier.classify(feats)\n",
        "    testsets[observed].add(i)\n",
        "    \n",
        "# Classifier 2\n",
        "refsets2 = collections.defaultdict(set)\n",
        "testsets2 = collections.defaultdict(set)\n",
        "\n",
        "for i, (feats, label) in enumerate(test_set2):\n",
        "    refsets2[label].add(i)\n",
        "    observed = classifier2.classify(feats)\n",
        "    testsets2[observed].add(i)"
      ],
      "metadata": {
        "id": "5cGcq6DAt1r6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "refsets"
      ],
      "metadata": {
        "id": "1IanDshYuWW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testsets"
      ],
      "metadata": {
        "id": "trsn3MnvuZ_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can proceed to print the metrics for each classifier. \n",
        "\n",
        "However, we cannot get the accuracy in this manner because nltk.metrics.scores.accuracy(reference, test) works by comparing test[i] == reference[i] and our reference and test are not formatted in a way that allows for this.\n",
        "\n",
        "It's the same for the confusion matrix."
      ],
      "metadata": {
        "id": "FRlJlHvjeREN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.metrics.scores import (precision, recall, f_measure)\n",
        "\n",
        "args = (\n",
        "    round(precision(refsets['female'], testsets['female']), 2),\n",
        "    round(precision(refsets['male'], testsets['male']), 2),\n",
        "    round(recall(refsets['female'], testsets['female']), 2),\n",
        "    round(recall(refsets['male'], testsets['male']), 2),\n",
        "    round(f_measure(refsets['female'], testsets['female']), 2),\n",
        "    round(f_measure(refsets['male'], testsets['male']), 2)\n",
        ")\n",
        "\n",
        "args2 = (\n",
        "    round(precision(refsets2['female'], testsets2['female']), 2),\n",
        "    round(precision(refsets2['male'], testsets2['male']), 2),\n",
        "    round(recall(refsets2['female'], testsets2['female']), 2),\n",
        "    round(recall(refsets2['male'], testsets2['male']), 2),\n",
        "    round(f_measure(refsets2['female'], testsets2['female']), 2),\n",
        "    round(f_measure(refsets2['male'], testsets2['male']), 2)\n",
        ")\n",
        "\n",
        "print('''\n",
        "CLASSIFIER 1\n",
        "------------ \n",
        "Female precision: {0}\n",
        "Male precision: {1}\n",
        "Female recall: {2}\n",
        "Male recall: {3}\n",
        "Female F1 score: {4}\n",
        "Male F1 score: {5}\n",
        "\n",
        "CLASSIFIER 2\n",
        "------------ \n",
        "Female precision: {6}\n",
        "Male precision: {7}\n",
        "Female recall: {8}\n",
        "Male recall: {9}\n",
        "Female F1 score: {10}\n",
        "Male F1 score: {11}\n",
        "'''.format(*args, *args2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyRlMKCzuwdk",
        "outputId": "6722874a-caf4-4a7e-c320-e0f56db2b15e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CLASSIFIER 1\n",
            "------------ \n",
            "Female precision: 0.81\n",
            "Male precision: 0.67\n",
            "Female recall: 0.82\n",
            "Male recall: 0.66\n",
            "Female F1 score: 0.81\n",
            "Male F1 score: 0.67\n",
            "\n",
            "CLASSIFIER 2\n",
            "------------ \n",
            "Female precision: 0.83\n",
            "Male precision: 0.72\n",
            "Female recall: 0.85\n",
            "Male recall: 0.68\n",
            "Female F1 score: 0.84\n",
            "Male F1 score: 0.7\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Error analysis:*** Investigating errors of classifier (names whose gender was misclassified)"
      ],
      "metadata": {
        "id": "MHJ7NzkUvAqh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make list for errors and load in classifications where guess does not equal gender tag, print first five\n"
      ],
      "metadata": {
        "id": "I6IQErZleWNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "errors = []\n",
        "for (name, tag) in test_names:\n",
        "    guess = classifier2.classify(gender_features(name))\n",
        "    if guess != tag:\n",
        "        errors.append((tag, guess, name))\n",
        "\n",
        "errors[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SW13TLBvAQO",
        "outputId": "144d923b-9d28-434e-c161-f6e4a1767ea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('female', 'male', 'Christean'),\n",
              " ('female', 'male', 'Charis'),\n",
              " ('male', 'female', 'Cody'),\n",
              " ('male', 'female', 'Micah'),\n",
              " ('male', 'female', 'Tracie')]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print three columns (correct gender of name, guessed gender, and name itself)"
      ],
      "metadata": {
        "id": "VIWGyka0eY_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for (tag, guess, name) in sorted(errors):\n",
        "    #print('Correct = {:8} guess = {:8} name = {}'.format(tag, guess, name)) # :8 creates spaces between columns."
      ],
      "metadata": {
        "id": "3_uC-MRLvo8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking through this list of errors, it seems that some suffixes that are more than one letter long can be indicative of name genders. For example, names ending in yn appear to be predominantly female, despite the fact that names ending in n tend to be male; and names ending in ch are usually male, even though names that end in h tend to be female."
      ],
      "metadata": {
        "id": "vaLHTKNOv5yT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building a classifier with even more features in response to errors"
      ],
      "metadata": {
        "id": "nshIowSTwFH0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define new classifier which counts first letter and last two letters of word"
      ],
      "metadata": {
        "id": "DHM_oE0eegu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gender_features3(name):\n",
        "    features = {}\n",
        "    features[\"first_letter\"] = name[0].lower()\n",
        "    features[\"suffix1\"] = name[-1].lower()\n",
        "    features[\"suffix2\"] = name[-2:].lower()\n",
        "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
        "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
        "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
        "    return features\n",
        "\n",
        "#gender_features3('John')"
      ],
      "metadata": {
        "id": "GVSb4Hj9wCRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get features above for list of gendered names and put in list, print first item in list\n"
      ],
      "metadata": {
        "id": "6o_JeX8PesM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "featuresets3 = [(gender_features3(n), gender) for (n, gender) in labeled_names]\n",
        "featuresets3[0]"
      ],
      "metadata": {
        "id": "MSc2YjOzwj2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train new classifier on same set of male and female names above and get accuracy\n"
      ],
      "metadata": {
        "id": "IUDZtxgFey7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set3, test_set3 = featuresets3[:TRAIN_SET_SIZE], featuresets3[TRAIN_SET_SIZE:]\n",
        "classifier3 = NaiveBayesClassifier.train(train_set3)\n",
        "round(accuracy(classifier3, test_set3), 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKXAflRsw3jt",
        "outputId": "63854065-c214-44b4-d05c-1171f96ea916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get 15 most informative features for classifier3"
      ],
      "metadata": {
        "id": "o_5k6q5We1OU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier3.show_most_informative_features(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2j_6qzxw-JC",
        "outputId": "7bb9396b-f956-425f-9290-edc577b7d96b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n",
            "                 suffix2 = 'na'           female : male   =     84.0 : 1.0\n",
            "                 suffix2 = 'la'           female : male   =     67.8 : 1.0\n",
            "                 suffix2 = 'ra'           female : male   =     53.7 : 1.0\n",
            "                 suffix2 = 'ia'           female : male   =     49.4 : 1.0\n",
            "                 suffix2 = 'us'             male : female =     33.3 : 1.0\n",
            "                 suffix1 = 'a'            female : male   =     31.8 : 1.0\n",
            "                 suffix2 = 'rd'             male : female =     29.9 : 1.0\n",
            "                 suffix1 = 'k'              male : female =     27.6 : 1.0\n",
            "                 suffix2 = 'sa'           female : male   =     27.3 : 1.0\n",
            "                 suffix2 = 'ta'           female : male   =     21.9 : 1.0\n",
            "                 suffix2 = 'do'             male : female =     21.4 : 1.0\n",
            "                 suffix2 = 'ld'             male : female =     20.7 : 1.0\n",
            "                 suffix2 = 'rt'             male : female =     16.7 : 1.0\n",
            "                 suffix2 = 'ka'           female : male   =     14.8 : 1.0\n",
            "                 suffix2 = 'io'             male : female =     13.5 : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Maximum entropy classifier:*** The principle of maximum entropy states that the probability distribution which best represents the current state of knowledge is the one with largest entropy.\n",
        "\n",
        "The principle of maximum entropy is invoked when we have some piece(s) of information about a probability distribution, but not enough to characterize it completely—likely because we do not have the means or resources to do so. As an example, if all we know about a distribution is its average, we can imagine infinite shapes that yield a particular average. The principle of maximum entropy says that we should humbly choose the distribution that maximizes the amount of unpredictability contained in the distribution.\n",
        "\n",
        "Taking the idea to the extreme, it wouldn’t be scientific to choose a distribution that simply yields the average value 100% of the time.\n",
        "\n",
        "From all the models that fit our training data, the Maximum Entropy classifier selects the one which has the largest entropy. Due to the minimum assumptions that the Maximum Entropy classifier makes, it is usually used when we don’t know anything about the prior distributions and when it is unsafe to make any assumptions. Also, the maximum entropy classifier is used when we can’t assume the conditional independence of the features."
      ],
      "metadata": {
        "id": "S2mZgGDBxKTL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, the performance in terms of accuracy on the test set starts significantly improving beyond the previous model's at around 25 iterations.\n"
      ],
      "metadata": {
        "id": "3KYdrUoZe5VU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import MaxentClassifier\n",
        "\n",
        "# max_iter has default value 100. \n",
        "me_classifier = MaxentClassifier.train(train_set3, max_iter=25) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvjL3c6ExigH",
        "outputId": "6359fa6b-f6a4-41ae-ae2e-5f48204c8960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ==> Training (25 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -0.69315        0.373\n",
            "             2          -0.60435        0.627\n",
            "             3          -0.58273        0.627\n",
            "             4          -0.56287        0.633\n",
            "             5          -0.54470        0.668\n",
            "             6          -0.52810        0.703\n",
            "             7          -0.51296        0.730\n",
            "             8          -0.49913        0.752\n",
            "             9          -0.48651        0.767\n",
            "            10          -0.47497        0.779\n",
            "            11          -0.46440        0.787\n",
            "            12          -0.45471        0.792\n",
            "            13          -0.44580        0.795\n",
            "            14          -0.43760        0.795\n",
            "            15          -0.43004        0.798\n",
            "            16          -0.42304        0.799\n",
            "            17          -0.41656        0.801\n",
            "            18          -0.41055        0.802\n",
            "            19          -0.40495        0.805\n",
            "            20          -0.39974        0.806\n",
            "            21          -0.39487        0.807\n",
            "            22          -0.39032        0.808\n",
            "            23          -0.38606        0.809\n",
            "            24          -0.38206        0.810\n",
            "         Final          -0.37830        0.811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the accuracy of the me classifier. The accuracies above were on the training set so this is what matters.\n"
      ],
      "metadata": {
        "id": "AAlYbod-e7vw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "round(accuracy(me_classifier, test_set3), 2) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTpysUsvx-AR",
        "outputId": "9a63df04-bb25-4410-c831-2086b05165c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.81"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get 10 most informative features for me classifier\n"
      ],
      "metadata": {
        "id": "6lo8Bt0Be9p6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "me_classifier.show_most_informative_features(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s-6k6FJyKtC",
        "outputId": "42281ea8-b053-4281-dc92-8458a2ff0bfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -1.938 suffix2=='na' and label is 'male'\n",
            "  -1.922 suffix2=='la' and label is 'male'\n",
            "  -1.886 suffix2=='ra' and label is 'male'\n",
            "  -1.658 suffix2=='ia' and label is 'male'\n",
            "  -1.430 suffix2=='sa' and label is 'male'\n",
            "  -1.387 suffix1=='a' and label is 'male'\n",
            "  -1.346 suffix2=='us' and label is 'female'\n",
            "  -1.277 suffix1=='k' and label is 'female'\n",
            "  -1.217 suffix2=='ta' and label is 'male'\n",
            "  -1.213 suffix2=='rd' and label is 'female'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***More Classifiers:***\n",
        "Scikit-learn (sklearn) is a popular library which features various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN.\n",
        "\n",
        "NLTK provides an API to quickly use sklearn classifiers in nltk.classify.scikitlearn. The other option is to import and use sklearn directly.\n",
        "\n",
        "For an example of integrating sklearn with NLTK, you can check out [this notebook on Kaggle.](https://www.kaggle.com/alvations/basic-nlp-with-nltk) Kaggle is a great website for NLP and machine learning in general, creating an account is highly recommended."
      ],
      "metadata": {
        "id": "kLwG96ZHyTp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tutorial 7: Classifying News Documents into Categories\n",
        "\n",
        "Based on Another Excercise: Classifying News Documents in Categories: sport, humor, adventure, science fiction, etc... in [Natural Language Processing with Python/NLTK by Luciano M. Guasco](https://github.com/luchux/ipython-notebook-nltk/blob/master/NLP%20-%20MelbDjango.ipynb)"
      ],
      "metadata": {
        "id": "lKOqWc42zipI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exploring the Brown corpus**\n",
        "\n",
        "The Corpus consists of 500 samples, distributed across 15 genres. Each sample began at a random sentence-boundary in the article or other unit chosen, and continued up to the first sentence boundary after 2,000 words.\n",
        "\n",
        "A. PRESS: Reportage (44 texts)\n",
        "\n",
        "B. PRESS: Editorial (27 texts)\n",
        "\n",
        "C. PRESS: Reviews (17 texts)\n",
        "\n",
        "D. RELIGION (17 texts)\n",
        "\n",
        "E. SKILL AND HOBBIES (36 texts)\n",
        "\n",
        "F. POPULAR LORE (48 texts)\n",
        "\n",
        "G. BELLES-LETTRES - Biography, Memoirs, etc. (75 texts)\n",
        "\n",
        "H. MISCELLANEOUS: US Government & House Organs (30 texts)\n",
        "\n",
        "J. LEARNED - Natural sciences, Medicine, Mathematics, etc. (80 texts)\n",
        "\n",
        "K. FICTION: General (29 texts)\n",
        "\n",
        "L. FICTION: Mystery and Detective Fiction (24 texts)\n",
        "\n",
        "M. FICTION: Science (6 texts)\n",
        "\n",
        "N. FICTION: Adventure and Western (29 texts)\n",
        "\n",
        "P. FICTION: Romance and Love Story (29 texts)\n",
        "\n",
        "R. HUMOR (9 texts)"
      ],
      "metadata": {
        "id": "GKj3q9-Dz852"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download brown corpus and clean spacing"
      ],
      "metadata": {
        "id": "fn__CLdFfKjs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "M0YDRqAazEh1",
        "outputId": "5ca5a9e3-1ea5-40c6-e81d-f70a3aa4e796"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'BROWN CORPUS  A Standard Corpus of Present-Day Edited American English, for use with Digital Computers.  by W. N. Francis and H. Kucera (1964) Department of Linguistics, Brown University Providence, Rhode Island, USA  Revised 1971, Revised and Amplified 1979  http://www.hit.uib.no/icame/brown/bcm.html  Distributed with the permission of the copyright holder, redistribution permitted. '"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('brown')\n",
        "\n",
        "from nltk.corpus import brown\n",
        "\n",
        "brown.readme().replace('\\n', ' ')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print file ids in Brown corpus"
      ],
      "metadata": {
        "id": "h4L0dUWRfM8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "brown.fileids()"
      ],
      "metadata": {
        "id": "VE3wqzpj0i9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get categories (genres of text) in Brown corpus"
      ],
      "metadata": {
        "id": "RYliITtefPV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "brown.categories()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IEyOteC0rkD",
        "outputId": "e97f59e3-5d8c-4b7f-c35c-47ccbc847e36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['adventure',\n",
              " 'belles_lettres',\n",
              " 'editorial',\n",
              " 'fiction',\n",
              " 'government',\n",
              " 'hobbies',\n",
              " 'humor',\n",
              " 'learned',\n",
              " 'lore',\n",
              " 'mystery',\n",
              " 'news',\n",
              " 'religion',\n",
              " 'reviews',\n",
              " 'romance',\n",
              " 'science_fiction']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print first sentence in specified file of brown corpus"
      ],
      "metadata": {
        "id": "82yw2YGmfXJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "brown.sents('ca01')[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atzpifoH0t73",
        "outputId": "c6f2f94a-99b2-4417-d2f4-da52a3bcc6ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'Fulton',\n",
              " 'County',\n",
              " 'Grand',\n",
              " 'Jury',\n",
              " 'said',\n",
              " 'Friday',\n",
              " 'an',\n",
              " 'investigation',\n",
              " 'of',\n",
              " \"Atlanta's\",\n",
              " 'recent',\n",
              " 'primary',\n",
              " 'election',\n",
              " 'produced',\n",
              " '``',\n",
              " 'no',\n",
              " 'evidence',\n",
              " \"''\",\n",
              " 'that',\n",
              " 'any',\n",
              " 'irregularities',\n",
              " 'took',\n",
              " 'place',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile a list of most popular words in the corpus\n",
        "\n",
        "Takes a bunch of tokens and returns the frequencies of all unique cases."
      ],
      "metadata": {
        "id": "c1rg4JBW020n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import FreqDist \n",
        "# Check if the word is alphabetical avoids including stuff like `` and '' which are actually pretty common. \n",
        "# Note that it also omits words such as 1 (very common), aug., 1913, $30, 13th, over-all etc. Another option would have been .isalnum().\n",
        "words_in_corpora = FreqDist(w.lower() for w in brown.words() if w.isalpha()) \n",
        "#words_in_corpora"
      ],
      "metadata": {
        "id": "B6fiKm5u047P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use this instead of sorted() to sort dictionary into a (mutable) list in order to delete the second column as opposed to into a tuple (immutable).\n"
      ],
      "metadata": {
        "id": "QcxK8N3Bffnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_corpora_freq_sorted = list(map(list, words_in_corpora.items()))\n",
        "#words_in_corpora_freq_sorted"
      ],
      "metadata": {
        "id": "mZJxzbwW1FpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sort words in corpus based on frequency"
      ],
      "metadata": {
        "id": "phNhzkhDfjUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_corpora_freq_sorted.sort(key=lambda x: x[1], reverse=True) # Using a lambda function is an alternative to using the operator library.\n",
        "words_in_corpora_freq_sorted"
      ],
      "metadata": {
        "id": "sYXSGlC71Si1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Put 1500 most frequent words in list into variable and delete word count (list item 1)\n"
      ],
      "metadata": {
        "id": "YsKiguyaflUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best1500 = words_in_corpora_freq_sorted[:1500]\n",
        "\n",
        "for list_item in best1500:\n",
        "    del list_item[1]\n",
        "\n",
        "#best1500"
      ],
      "metadata": {
        "id": "E4PU67jv1XVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since best1500 is now a list of words, it should be flattened. \n",
        "\n",
        "Break down the list into its individual sublists and then chain them. \n",
        "\n",
        "Chain further breaks down each sublist into its individual components so this approach can be used to flatten any list of lists."
      ],
      "metadata": {
        "id": "1BbKRgcRfyK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "chain = itertools.chain(*best1500) \n",
        "best1500 = list(chain) # chain is of type itertools.chain so we need the cast\n",
        "#best1500"
      ],
      "metadata": {
        "id": "EFAxauxc1ioy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Receives a list of words and removes stop words from list"
      ],
      "metadata": {
        "id": "qVwANZqhf7dI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stopw = stopwords.words('english')\n",
        "\n",
        "def nonstop(listwords):\n",
        "    return [word for word in listwords if word not in stopw]\n",
        "\n",
        "best1500_words_corpora = nonstop(best1500) # Note how this will probably contain less than 1500 words.\n",
        "#best1500_words_corpora"
      ],
      "metadata": {
        "id": "j096l7hX1uFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Converting corpus to form suitable for classification:*** Each file in the corpus will eventually be represented by a dictionary showing the presence of the corpus’ most popular words in the particular file."
      ],
      "metadata": {
        "id": "OV9lfJZL13cB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# documents = [(nonstop(brown.words(fileid)), category) for category in brown.categories() for fileid in brown.fileids(category)]\n",
        "# documents # Note how documents is a list of tuples.\n",
        "\n",
        "# The code above generates a representation of the corpus but without removing punctuation. This is better:\n",
        "documents = [([item.lower() for item in nonstop(brown.words(fileid)) if item.isalpha()], category)\n",
        "             for category in brown.categories()\n",
        "             for fileid in brown.fileids(category)]\n",
        "documents # Note how documents is a list of tuples."
      ],
      "metadata": {
        "id": "ZTPt6D6312cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shuffle items in list of tuples"
      ],
      "metadata": {
        "id": "UzCvFVuhgBIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from random import shuffle\n",
        "\n",
        "shuffle(documents)\n",
        "documents"
      ],
      "metadata": {
        "id": "GfZ4KzwM2KWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given a document extract features (the presence or not of the 1500 most frequent words of the corpus)"
      ],
      "metadata": {
        "id": "U-_m2i9ygCQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def document_features(doc):\n",
        "    doc_set_words = set(doc) # Checking whether a word occurs in a set is much faster than checking whether it occurs in a list.\n",
        "    features_dic = {} # Features is a dictionary\n",
        "    for word in best1500_words_corpora:\n",
        "        features_dic['has(%s)' % word] = (word in doc_set_words)\n",
        "    return features_dic\n",
        "\n",
        "doc_features_set = [(document_features(d),c) for (d,c) in documents]\n",
        "doc_features_set[0]"
      ],
      "metadata": {
        "id": "b94GlVcq2TFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now build the classifer to determine what category documents fall into based on most frequent words"
      ],
      "metadata": {
        "id": "UoJRCaGG2gXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import NaiveBayesClassifier\n",
        "\n",
        "train_set = doc_features_set[:350] # Since the total is 500\n",
        "test_set  = doc_features_set[150:]\n",
        "\n",
        "classifier = NaiveBayesClassifier.train(train_set)\n",
        "classifier.show_most_informative_features(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIDW05Zx2oS0",
        "outputId": "0e060bbe-975c-43e9-e9a1-8d4ea07da3a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n",
            "             has(walked) = True           myster : learne =     29.7 : 1.0\n",
            "              has(music) = True           review : learne =     28.9 : 1.0\n",
            "                has(ran) = True           advent : learne =     28.5 : 1.0\n",
            "          has(afternoon) = True           fictio : learne =     27.2 : 1.0\n",
            "               has(road) = True           myster : learne =     27.1 : 1.0\n",
            "            has(playing) = True           review : learne =     26.2 : 1.0\n",
            "                has(god) = True           religi : learne =     25.8 : 1.0\n",
            "                has(car) = True            humor : learne =     25.3 : 1.0\n",
            "               has(hair) = True           romanc : learne =     23.8 : 1.0\n",
            "              has(maybe) = True           romanc : learne =     23.8 : 1.0\n",
            "            has(watched) = True           advent : learne =     22.6 : 1.0\n",
            "            has(kitchen) = True            humor : belles =     22.4 : 1.0\n",
            "          has(communism) = True           editor : learne =     22.1 : 1.0\n",
            "             has(berlin) = True           editor : learne =     22.1 : 1.0\n",
            "           has(watching) = True           romanc : learne =     21.7 : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get accuracy of classifier"
      ],
      "metadata": {
        "id": "UW1mLxb1gE8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.classify import accuracy\n",
        "\n",
        "print(accuracy(classifier, test_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nzpfE_12uL8",
        "outputId": "42a60d0b-5964-4208-ff7f-50e4874263bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7371428571428571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test classification of documet 'ca01' (it is under the 'news' category)"
      ],
      "metadata": {
        "id": "lYGTeBoLgGqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.classify(document_features(brown.words('ca01')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kr1sLuUo20TW",
        "outputId": "780afe3a-af05-4be4-f98d-22b220fc3271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'news'"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "# The test text needs to be long enough in order to contain a significant amount of the 1500 most common words in our training corpus.\n",
        "text = \"1 God, infinitely perfect and blessed in himself, in a plan of sheer goodness freely created man to make him share in his own blessed life. For this reason, at every time and in every place, God draws close to man. He calls man to seek him, to know him, to love him with all his strength. He calls together all men, scattered and divided by sin, into the unity of his family, the Church. To accomplish this, when the fullness of time had come, God sent his Son as Redeemer and Saviour. In his Son and through him, he invites men to become, in the Holy Spirit, his adopted children and thus heirs of his blessed life. 2 So that this call should resound throughout the world, Christ sent forth the apostles he had chosen, commissioning them to proclaim the gospel: \\\"Go therefore and make disciples of all nations, baptizing them in the name of the Father and of the Son and of the Holy Spirit, teaching them to observe all that I have commanded you; and lo, I am with you always, to the close of the age.\\\"4 Strengthened by this mission, the apostles \\\"went forth and preached everywhere, while the Lord worked with them and confirmed the message by the signs that attended it.\\\" 3 Those who with God's help have welcomed Christ's call and freely responded to it are urged on by love of Christ to proclaim the Good News everywhere in the world. This treasure, received from the apostles, has been faithfully guarded by their successors. All Christ's faithful are called to hand it on from generation to generation, by professing the faith, by living it in fraternal sharing, and by celebrating it in liturgy and prayer. 4 Quite early on, the name catechesis was given to the totality of the Church's efforts to make disciples, to help men believe that Jesus is the Son of God so that believing they might have life in his name, and to educate and instruct them in this life, thus building up the body of Christ. Catechesis is an education in the faith of children, young people and adults which includes especially the teaching of Christian doctrine imparted, generally speaking, in an organic and systematic way, with a view to initiating the hearers into the fullness of Christian life. While not being formally identified with them, catechesis is built on a certain number of elements of the Church's pastoral mission which have a catechetical aspect, that prepare for catechesis, or spring from it. They are: the initial proclamation of the Gospel or missionary preaching to arouse faith; examination of the reasons for belief; experience of Christian living; celebration of the sacraments; integration into the ecclesial community; and apostolic and missionary witness. Catechesis is intimately bound up with the whole of the Church's life. Not only her geographical extension and numerical increase, but even more her inner growth and correspondence with God's plan depend essentially on catechesis. Periods of renewal in the Church are also intense moments of catechesis. In the great era of the Fathers of the Church, saintly bishops devoted an important part of their ministry to catechesis. St. Cyril of Jerusalem and St. John Chrysostom, St. Ambrose and St. Augustine, and many other Fathers wrote catechetical works that remain models for us. The ministry of catechesis draws ever fresh energy from the councils. the Council of Trent is a noteworthy example of this. It gave catechesis priority in its constitutions and decrees. It lies at the origin of the Roman Catechism, which is also known by the name of that council and which is a work of the first rank as a summary of Christian teaching. The Council of Trent initiated a remarkable organization of the Church's catechesis. Thanks to the work of holy bishops and theologians such as St. Peter Canisius, St. Charles Borromeo, St. Turibius of Mongrovejo or St. Robert Bellarmine, it occasioned the publication of numerous catechisms. It is therefore no surprise that catechesis in the Church has again attracted attention in the wake of the Second Vatican Council, which Pope Paul Vl considered the great catechism of modern times. the General Catechetical Directory (1971) the sessions of the Synod of Bishops devoted to evangelization (1974) and catechesis (1977), the apostolic exhortations Evangelii nuntiandi (1975) and Catechesi tradendae (1979), attest to this. the Extraordinary Synod of Bishops in 1985 asked that a catechism or compendium of all Catholic doctrine regarding both faith and morals be composed. The Holy Father, Pope John Paul II, made the Synod's wish his own, acknowledging that this desire wholly corresponds to a real need of the universal Church and of the particular Churches. He set in motion everything needed to carry out the Synod Fathers' wish.\"\n",
        "\n",
        "tokenizer = RegexpTokenizer(r'\\w+') # Picks out sequences of alphanumeric characters as tokens and drops everything else\n",
        "text_tokens = nonstop(tokenizer.tokenize(text.lower()))\n",
        "text_tokens = [w for w in text_tokens if w.isalpha()]\n",
        "#text_tokens"
      ],
      "metadata": {
        "id": "M-EMaQVd270T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Determine whether list of tokens contain most frequent words set above"
      ],
      "metadata": {
        "id": "ZlOQHMLAgTNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_features = document_features(text_tokens)\n",
        "#text_features"
      ],
      "metadata": {
        "id": "IzMMcZ9T3CBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classifies new document based on presence of frequent words in brown corpus categories"
      ],
      "metadata": {
        "id": "aD_NtICOgV1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.classify(document_features(text_tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JcWp17aY3LzC",
        "outputId": "ec23b1fe-2215-4643-ec91-e72dc8334177"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'belles_lettres'"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tutorial 8: Intro to Sentiment Analysis"
      ],
      "metadata": {
        "id": "Bbr0cfEraN10"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment analysis is the practice of using algorithms to classify various samples of related text into overall positive and negative categories. With NLTK, you can employ these algorithms through powerful built-in machine learning operations to obtain insights from linguistic data.\n",
        "\n",
        "Based on [Exercise B: Sentiment Analysis in Natural Language Processing with Python/NLTK by Luciano M. Guasco](https://github.com/luchux/ipython-notebook-nltk/blob/master/NLP%20-%20MelbDjango.ipynb)"
      ],
      "metadata": {
        "id": "NyovRjxyaevV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Step 1: Explore the movie_reviews corpus*** "
      ],
      "metadata": {
        "id": "DvYftuKwaxDd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import movie_reviews from nltk and clean spacing"
      ],
      "metadata": {
        "id": "V0Nx_mEsbVKb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "X3Qsvmn0aGiT",
        "outputId": "066a5646-9e13-4ee8-c5d4-157ae2f74dfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Sentiment Polarity Dataset Version 2.0 Bo Pang and Lillian Lee  http://www.cs.cornell.edu/people/pabo/movie-review-data/  Distributed with NLTK with permission from the authors.  =======  Introduction  This README v2.0 (June, 2004) for the v2.0 polarity dataset comes from the URL http://www.cs.cornell.edu/people/pabo/movie-review-data .  =======  What\\'s New -- June, 2004  This dataset represents an enhancement of the review corpus v1.0 described in README v1.1: it contains more reviews, and labels were created with an improved rating-extraction system.  =======  Citation Info   This data was first used in Bo Pang and Lillian Lee, \"A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization  Based on Minimum Cuts\",  Proceedings of the ACL, 2004.  @InProceedings{Pang+Lee:04a,   author =       {Bo Pang and Lillian Lee},   title =        {A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts},   booktitle =    \"Proceedings of the ACL\",   year =         2004 }  =======  Data Format Summary   - review_polarity.tar.gz: contains this readme and  data used in   the experiments described in Pang/Lee ACL 2004.    Specifically:    Within the folder \"txt_sentoken\" are the 2000 processed down-cased   text files used in Pang/Lee ACL 2004; the names of the two   subdirectories in that folder, \"pos\" and \"neg\", indicate the true   classification (sentiment) of the component files according to our   automatic rating classifier (see section \"Rating Decision\" below).    File names consist of a cross-validation tag plus the name of the   original html file.  The ten folds used in the Pang/Lee ACL 2004 paper\\'s   experiments were:       fold 1: files tagged cv000 through cv099, in numerical order      fold 2: files tagged cv100 through cv199, in numerical order           ...      fold 10: files tagged cv900 through cv999, in numerical order    Hence, the file neg/cv114_19501.txt, for example, was labeled as   negative, served as a member of fold 2, and was extracted from the   file 19501.html in polarity_html.zip (see below).    Each line in each text file corresponds to a single sentence, as   determined by Adwait Ratnaparkhi\\'s sentence boundary detector   MXTERMINATOR.     Preliminary steps were taken to remove rating information from the   text files, but only the rating information upon which the rating   decision was based is guaranteed to have been removed. Thus, if the   original review contains several instances of rating information,   potentially given in different forms, those not recognized as valid   ratings remain part of the review text.  - polarity_html.zip: The original source files from which the   processed, labeled, and (randomly) selected data in   review_polarity.tar.gz was derived.    Specifically:      This data consists of unprocessed, unlabeled html files from the   IMDb archive of the rec.arts.movies.reviews newsgroup,   http://reviews.imdb.com/Reviews. The files in review_polarity.tar.gz   represent a processed subset of these files.   =======  Rating Decision (Appendix A)  This section describes how we determined whether a review was positive or negative.  The original html files do not have consistent formats -- a review may not have the author\\'s rating with it, and when it does, the rating can appear at different places in the file in different forms.  We only recognize some of the more explicit ratings, which are extracted via a set of ad-hoc rules.  In essence, a file\\'s classification is determined based on the first rating we were able to identify.   - In order to obtain more accurate rating decisions, the maximum rating must be specified explicitly, both for numerical ratings and star ratings.  (\"8/10\", \"four out of five\", and \"OUT OF ****: ***\" are examples of rating indications we recognize.)  - With a five-star system (or compatible number systems): three-and-a-half stars and up are considered positive,  two stars and below are considered negative. - With a four-star system (or compatible number system): three stars and up are considered positive,  one-and-a-half stars and below are considered negative.   - With a letter grade system: B or above is considered positive, C- or below is considered negative.  We attempted to recognize half stars, but they are specified in an especially free way, which makes them difficult to recognize.  Hence, we may lose a half star very occasionally; but this only results in 2.5 stars in five star system being categorized as negative, which is  still reasonable.   '"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('movie_reviews')\n",
        "from nltk.corpus import movie_reviews # These are movie reviews already separated as positive and negative.\n",
        "movie_reviews.readme().replace('\\n', ' ').replace('\\t', '').replace('``', '\"').replace(\"''\", '\"').replace('`', \"'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want, you can print the file ids from movie_reviews; it generates a very long list. But you can see the structure of the ids and how the label includes \"pos\" or \"neg\""
      ],
      "metadata": {
        "id": "Pr30athMbfr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#movie_reviews.fileids()"
      ],
      "metadata": {
        "id": "lUszG-ZZbgCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To determine how many movie reviews are in the corpus, print the length of the list of file ids"
      ],
      "metadata": {
        "id": "0ucelACgcPtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(movie_reviews.fileids())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6YFBq_EcVXu",
        "outputId": "946b0f23-d98e-485d-d25d-94f84862845c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's an additional cleaning trick to get rid of \\' in text - but only if there were no \" used. See how it works with just one file."
      ],
      "metadata": {
        "id": "Gzrs1XiCcaNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movie_reviews.raw(\"neg/cv000_29416.txt\").replace(\"\\n\", \"\").replace(\"'\", '\"').replace('\"', \"'\") "
      ],
      "metadata": {
        "id": "7atoJ3dEcYGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Step 2: Building and testing the classifier*** "
      ],
      "metadata": {
        "id": "LpekNwyLc55v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before building the classifier, you'll want to generate a list of stopwords which will NOT be considered when making lists of positive and negative words. We'll import English stopwords from NLTK and put them in \"stops,\" then add additional features we don't want to include in classification using stops.extend. To see check full list of stopwords, print stops."
      ],
      "metadata": {
        "id": "xDZrX3P9dSXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')  \n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stops = stopwords.words('english')\n",
        "stops.extend('.,[,],(,),;,/,-,\\',?,\",:,<,>,n\\'t,|,#,\\'s,\\\",\\'re,\\'ve,\\'ll,\\'d,\\'re'.split(','))\n",
        "stops.extend(',')\n",
        "#stops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7oDaru7dqA7",
        "outputId": "45042f4e-d5cf-4afc-ec73-9f4f5da859c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the NaiveBayes Classifier. Learn more about Naive Bayes [here](https://www.analyticsvidhya.com/blog/2021/01/a-guide-to-the-naive-bayes-algorithm/). "
      ],
      "metadata": {
        "id": "tVFeM1Azd7L3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.classify import NaiveBayesClassifier\n",
        "import nltk.classify.util # Utility functions and classes for classifiers. Contains functions such as accuracy(classifier, gold)"
      ],
      "metadata": {
        "id": "TNf4UEcWd7a6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a function which, given a word, returns a dict `{word: True}.` This will be our feature in the classifier. "
      ],
      "metadata": {
        "id": "Rv2kNMtEeWww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word_feats(words):\n",
        "    return dict([(word, True) for word in words if word not in stops and word.isalpha()])"
      ],
      "metadata": {
        "id": "tSikwcVCeWI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create new variables for all positive and all negative movie reviews and get combined length (should be same as  length of original file ids list)."
      ],
      "metadata": {
        "id": "RFhcNDA_e-4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos_ids = movie_reviews.fileids('pos')\n",
        "neg_ids = movie_reviews.fileids('neg')\n",
        "\n",
        "len(pos_ids) + len(neg_ids) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pcNw3kGe-gL",
        "outputId": "8593a121-3b63-4749-9e49-a83321d8b998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We take the positive/negative words, create the feature for such words, and store it in a positive/negative features list. You can print pos_feats to check list of words has loaded correctly; it will print VERY long list, since it will include words from every positive review.\n"
      ],
      "metadata": {
        "id": "IrrKfwbifS2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos_feats = [(word_feats(movie_reviews.words(fileids=[f])), 'pos') for f in pos_ids]\n",
        "neg_feats = [(word_feats(movie_reviews.words(fileids=[f])), 'neg') for f in neg_ids]\n",
        "\n",
        "#pos_feats"
      ],
      "metadata": {
        "id": "qZTBXV8vfTBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store 3/4 of features for training the classifier and check length of positive training features. "
      ],
      "metadata": {
        "id": "IMtJeNTjgNCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos_len_train = int(len(pos_feats) * 3 / 4)\n",
        "neg_len_train = int(len(neg_feats) * 3 / 4)\n",
        "\n",
        "pos_len_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_7g_OV6gOFl",
        "outputId": "6a312f4e-2cc8-4b54-b1f6-d0a06d4db5b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "750"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine positive and negative training features into one set and put the rest in \"test features\" "
      ],
      "metadata": {
        "id": "FvC41GKMgbXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_feats = neg_feats[:neg_len_train] + pos_feats[:pos_len_train]\n",
        "test_feats = neg_feats[neg_len_train:] + pos_feats[pos_len_train:]"
      ],
      "metadata": {
        "id": "cokZ_I7igacQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a NaiveBayesClassifier with our training feature words."
      ],
      "metadata": {
        "id": "TmfvBYSAgjkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = NaiveBayesClassifier.train(train_feats)"
      ],
      "metadata": {
        "id": "_ODzgc6cgjHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get accuracy of the classifier we have just trained."
      ],
      "metadata": {
        "id": "lBzproVxgonT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy: ', nltk.classify.util.accuracy(classifier, test_feats))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAnPOblEgovV",
        "outputId": "7f38200a-34ad-4c21-ae23-fbbea4a77499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see which words fit best in each class by getting the classifier's most informative features. "
      ],
      "metadata": {
        "id": "FQIFYUr_gu3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.show_most_informative_features()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0ZeR30Wgu9x",
        "outputId": "5fe079a8-a8d6-4c3c-9d09-d3de0023e694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n",
            "             magnificent = True              pos : neg    =     15.0 : 1.0\n",
            "             outstanding = True              pos : neg    =     13.6 : 1.0\n",
            "               insulting = True              neg : pos    =     13.0 : 1.0\n",
            "              vulnerable = True              pos : neg    =     12.3 : 1.0\n",
            "               ludicrous = True              neg : pos    =     11.8 : 1.0\n",
            "                  avoids = True              pos : neg    =     11.7 : 1.0\n",
            "             uninvolving = True              neg : pos    =     11.7 : 1.0\n",
            "              astounding = True              pos : neg    =     10.3 : 1.0\n",
            "             fascination = True              pos : neg    =     10.3 : 1.0\n",
            "                 idiotic = True              neg : pos    =      9.8 : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###***Step 3: Classifying new data***"
      ],
      "metadata": {
        "id": "OqYtDEXkg7MW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add a new sentence to test our classifier and tokenize it, adding features to tokens that are NOT in \"stops\" we defined above."
      ],
      "metadata": {
        "id": "QtIJfk7-hEU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize, pos_tag\n",
        "\n",
        "sentence = \"I feel so miserable, it makes me amazing\"\n",
        "tokens = [word for word in word_tokenize(sentence) if word not in stops]\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORWI_qhUhD3j",
        "outputId": "b08327f7-37c0-4f2a-eabf-06368ef195d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', 'feel', 'miserable', 'makes', 'amazing']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make tokens into features using word_feats function defined above."
      ],
      "metadata": {
        "id": "DnsXTKNPhZuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feats = word_feats(word for word in tokens)\n",
        "feats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obKYKmY1hZ1h",
        "outputId": "c297149d-1bad-43e5-e5ea-b752157e236a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'I': True, 'amazing': True, 'feel': True, 'makes': True, 'miserable': True}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use classifier to classify new sentence as either positive or negative. The result may not be what you expect!"
      ],
      "metadata": {
        "id": "wk-DyJoGhzsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.classify(feats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aYV-7yIZhy2l",
        "outputId": "195eb0bb-0d23-411c-ef45-ced21561f3f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'pos'"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try classifying another sentence - go through the same tokenizing process."
      ],
      "metadata": {
        "id": "7hyPwIASiAQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence2 = \"You are a pathetic fool, a terrible excuse for a human being.\"\n",
        "tokens2 = [word for word in word_tokenize(sentence2) if word not in stops]\n",
        "tokens2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8I3Ci43UiAah",
        "outputId": "222bf238-cfb5-49d4-feb7-f2d8763da2c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['You', 'pathetic', 'fool', 'terrible', 'excuse', 'human']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load tokens into new variable - instead of retaining all tokens, just capture the adjectives using `if pos[] == JJ`"
      ],
      "metadata": {
        "id": "NO2dphAviilC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "pos_tags2 = [pos for pos in pos_tag(tokens2) if pos[1] == 'JJ']\n",
        "pos_tags2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxAhIxPBiMXG",
        "outputId": "6ccb05f2-0955-4fae-baa8-9ba2c9667c9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('pathetic', 'JJ'), ('terrible', 'JJ')]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Put reduced list of tokens into variable for classificaiton"
      ],
      "metadata": {
        "id": "AoZcDaGqjEgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feats2 = word_feats([word for (word,_) in pos_tags2])\n",
        "feats2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDO4_fJcjFFo",
        "outputId": "98b3ea67-e9d2-4449-889e-aa67659a8877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pathetic': True, 'terrible': True}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use classifier to classify new sentence as either positive or negative."
      ],
      "metadata": {
        "id": "cc61rB-WiLYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.classify(feats2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OEAYqGgkjMb4",
        "outputId": "cc935e48-b730-4a34-da40-954588ee7ded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'neg'"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Step 4: Incorporating bigram features***\n",
        "In order to improve the classifier, bigram features can be examined using `nltk.util.ngrams`. This is because, for instance, 'not funny' is very different from 'funny'."
      ],
      "metadata": {
        "id": "QzR7R_NhjTOC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tutorial 9: Sentiment Analysis with `nltk.sentiment.SentimentAnalyzer` and VADER tools"
      ],
      "metadata": {
        "id": "COYEfQzej8-h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Step 1: Exploring the `subjectivity` corpus***\n",
        "\n",
        "The Subjectivity Dataset contains 5000 subjective and 5000 objective processed sentences. Learn more about the subjectivity corpus [here](https://www.nltk.org/howto/corpus.html).\n",
        "\n",
        "Import subjectivity corpus and get the file ids."
      ],
      "metadata": {
        "id": "HHAKVRRnlGxq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQ6vs51Tj8F_",
        "outputId": "01c93ac4-ecfc-4560-e115-cf8d0cf8a6e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package subjectivity to /root/nltk_data...\n",
            "[nltk_data]   Package subjectivity is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['plot.tok.gt9.5000', 'quote.tok.gt9.5000']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('subjectivity')\n",
        "from nltk.corpus import subjectivity\n",
        "\n",
        "subjectivity.fileids()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get tokens in plot.tok file"
      ],
      "metadata": {
        "id": "bbPO1cNqmD_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subjectivity.sents('plot.tok.gt9.5000')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OvcGQBpmE5T",
        "outputId": "dc348af1-9a46-49cd-c84d-a543818e4ddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['the', 'movie', 'begins', 'in', 'the', 'past', 'where', 'a', 'young', 'boy', 'named', 'sam', 'attempts', 'to', 'save', 'celebi', 'from', 'a', 'hunter', '.'], ['emerging', 'from', 'the', 'human', 'psyche', 'and', 'showing', 'characteristics', 'of', 'abstract', 'expressionism', ',', 'minimalism', 'and', 'russian', 'constructivism', ',', 'graffiti', 'removal', 'has', 'secured', 'its', 'place', 'in', 'the', 'history', 'of', 'modern', 'art', 'while', 'being', 'created', 'by', 'artists', 'who', 'are', 'unconscious', 'of', 'their', 'artistic', 'achievements', '.'], ...]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get tokens in quote.tok file"
      ],
      "metadata": {
        "id": "BspFeKyCmomm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subjectivity.sents('quote.tok.gt9.5000')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSZ_rKt8mvzk",
        "outputId": "fc29a2ca-68f7-4355-c2af-b5a827e9dbff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['smart', 'and', 'alert', ',', 'thirteen', 'conversations', 'about', 'one', 'thing', 'is', 'a', 'small', 'gem', '.'], ['color', ',', 'musical', 'bounce', 'and', 'warm', 'seas', 'lapping', 'on', 'island', 'shores', '.', 'and', 'just', 'enough', 'science', 'to', 'send', 'you', 'home', 'thinking', '.'], ...]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieve the categories in subjectivity corpus (objective and subjective sentences)."
      ],
      "metadata": {
        "id": "MUq_FHPgmzcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subjectivity.categories() # The mapping between documents and categories does not depend on the file structure."
      ],
      "metadata": {
        "id": "iFSv2oNqmy5c",
        "outputId": "260e22f2-bb3b-46ef-9248-4651ecf2dccd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['obj', 'subj']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get tokens in subjectivity that are categorized as \"objective\""
      ],
      "metadata": {
        "id": "CcnY55Pjnhsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subjectivity.sents(categories='obj')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOTtbpLjnh2p",
        "outputId": "41ecd593-d959-4331-debb-facce1e8328a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['the', 'movie', 'begins', 'in', 'the', 'past', 'where', 'a', 'young', 'boy', 'named', 'sam', 'attempts', 'to', 'save', 'celebi', 'from', 'a', 'hunter', '.'], ['emerging', 'from', 'the', 'human', 'psyche', 'and', 'showing', 'characteristics', 'of', 'abstract', 'expressionism', ',', 'minimalism', 'and', 'russian', 'constructivism', ',', 'graffiti', 'removal', 'has', 'secured', 'its', 'place', 'in', 'the', 'history', 'of', 'modern', 'art', 'while', 'being', 'created', 'by', 'artists', 'who', 'are', 'unconscious', 'of', 'their', 'artistic', 'achievements', '.'], ...]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get tokens in subjectivity that are categorized as \"subjective\""
      ],
      "metadata": {
        "id": "S-aYzaRQoOw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subjectivity.sents(categories='subj')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J36LTi4PoO4b",
        "outputId": "81341808-62ea-46ee-d8d8-f31a5dc8d1d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['smart', 'and', 'alert', ',', 'thirteen', 'conversations', 'about', 'one', 'thing', 'is', 'a', 'small', 'gem', '.'], ['color', ',', 'musical', 'bounce', 'and', 'warm', 'seas', 'lapping', 'on', 'island', 'shores', '.', 'and', 'just', 'enough', 'science', 'to', 'send', 'you', 'home', 'thinking', '.'], ...]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###***Step 2: Building and testing a classifier with `SentimentAnalyzer`***"
      ],
      "metadata": {
        "id": "-kh_y5Sloiln"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import necessary classifiers and modules. "
      ],
      "metadata": {
        "id": "Df9CQPoVoqgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.classify import NaiveBayesClassifier\n",
        "from nltk.sentiment import SentimentAnalyzer # SentimentAnalyzer is a tool to implement and facilitate Sentiment Analysis.\n",
        "from nltk.sentiment.util import (mark_negation, extract_unigram_feats) # mark_negation(): Append _NEG suffix to words that appear in the scope between a negation and a punctuation mark. extract_unigram_feats(): Populate a dictionary of unigram features, reflecting the presence/absence in the document of each of the tokens in unigrams.\n"
      ],
      "metadata": {
        "id": "uW1gngyPoqpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set number of instances at 100; then create two new lists for objective and subjective docs and put sentences up to number of n_instancse (100) in each list. Each document is represented by a tuple (sentence, label). The sentence is tokenized, so it is represented by a list of strings.\n",
        "\n",
        "Print length of each list to check they both contain 100 sentences."
      ],
      "metadata": {
        "id": "_Ob_727eXrYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_instances = 100\n",
        "obj_docs = [(sent, 'obj') for sent in subjectivity.sents(categories='obj')[:n_instances]]\n",
        "subj_docs = [(sent, 'subj') for sent in subjectivity.sents(categories='subj')[:n_instances]]\n",
        "len(obj_docs), len(subj_docs)"
      ],
      "metadata": {
        "id": "6ifXBgMoXrja",
        "outputId": "2f39cea0-56df-428b-ab9d-463555fbba5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print a sentence in obj_docs list to check:"
      ],
      "metadata": {
        "id": "r23Kr1xxYcjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "obj_docs[0]"
      ],
      "metadata": {
        "id": "U1idOEHVYcq3",
        "outputId": "ddfd78df-e00c-4942-d243-9f95ef07f87c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['the',\n",
              "  'movie',\n",
              "  'begins',\n",
              "  'in',\n",
              "  'the',\n",
              "  'past',\n",
              "  'where',\n",
              "  'a',\n",
              "  'young',\n",
              "  'boy',\n",
              "  'named',\n",
              "  'sam',\n",
              "  'attempts',\n",
              "  'to',\n",
              "  'save',\n",
              "  'celebi',\n",
              "  'from',\n",
              "  'a',\n",
              "  'hunter',\n",
              "  '.'],\n",
              " 'obj')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Divde sentences into training and testing groups; first 80 sentences of each are for training, last 20 for testing. Split evenly for objective and subjective docs, then combine into two larger groups (all training and all testing)."
      ],
      "metadata": {
        "id": "2LfDV64CYj7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_obj_docs = obj_docs[:80]\n",
        "test_obj_docs = obj_docs[80:100]\n",
        "train_subj_docs = subj_docs[:80]\n",
        "test_subj_docs = subj_docs[80:100]\n",
        "\n",
        "training_docs = train_obj_docs + train_subj_docs\n",
        "testing_docs = test_obj_docs + test_subj_docs"
      ],
      "metadata": {
        "id": "jg1aXbTsYkCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define sentiment analyzer as `SentimentAnalyzer()` and use it to append _NEG suffix to words that appear between a sensed negation and a punctuation mark."
      ],
      "metadata": {
        "id": "cvg-fUBHY3sy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentim_analyzer = SentimentAnalyzer()\n",
        "all_words_neg = sentim_analyzer.all_words([mark_negation(doc) for doc in training_docs])\n",
        "#all_words_neg"
      ],
      "metadata": {
        "id": "Nt3vhXFgY3Kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Return the list of most common 1-word features in all_words_neg, with a minimum frequency of 4 appearances."
      ],
      "metadata": {
        "id": "ICLzdAz_Zk9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unigram_feats = sentim_analyzer.unigram_word_feats(all_words_neg, min_freq=4)\n",
        "len(unigram_feats)"
      ],
      "metadata": {
        "id": "W0sx3HcoZldZ",
        "outputId": "d55523ba-a6f4-4b5e-ba46-043dfbf64de6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add unigram_features to list of features that the sentiment analyzer will extract from the data."
      ],
      "metadata": {
        "id": "I_x6dJbicnFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentim_analyzer.add_feat_extractor(extract_unigram_feats, unigrams=unigram_feats)"
      ],
      "metadata": {
        "id": "0l2UG9qNcg6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Redefine training and test set to include whether or not sents include the `unigram_feats`"
      ],
      "metadata": {
        "id": "wcIWyc4YcTl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = sentim_analyzer.apply_features(training_docs)\n",
        "test_set = sentim_analyzer.apply_features(testing_docs)\n",
        "#training_set[0]"
      ],
      "metadata": {
        "id": "Rc_HWRZPbiJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now train our classifier on the training set, and subsequently output the evaluation results. "
      ],
      "metadata": {
        "id": "OmOgpJ21bh_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = NaiveBayesClassifier.train\n",
        "classifier = sentim_analyzer.train(trainer, training_set)\n"
      ],
      "metadata": {
        "id": "I1ZDFgfccTtW",
        "outputId": "97ab854b-b70d-4e57-8074-809a7fd1bbec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training classifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation of results from [Python NLTK Cookbook:](https://streamhacker.com/2010/05/17/text-classification-sentiment-analysis-precision-recall/)\n",
        "\n",
        "*  **Accuracy** measures the number of elements correctly identified in a data set.\n",
        "*  **F-measure** is the weighted harmonic mean of precision and recall. \n",
        "*  **Precision** measures the exactness of a classifier. A higher precision means less false positives, while a lower precision means more false positives.\n",
        "*   **Recall** measures the completeness, or sensitivity, of a classifier. Higher recall means less false negatives, while lower recall means more false negatives. Often improves inverse of precision.\n"
      ],
      "metadata": {
        "id": "HsO80ZOveRbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for key,value in sorted(sentim_analyzer.evaluate(test_set).items()):\n",
        "    print('{0}: {1}'.format(key, value))"
      ],
      "metadata": {
        "id": "iZgR6_eSd-TJ",
        "outputId": "9fa43753-8902-433d-b1c3-b2b6533d4229",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating NaiveBayesClassifier results...\n",
            "Accuracy: 0.8\n",
            "F-measure [obj]: 0.8\n",
            "F-measure [subj]: 0.8\n",
            "Precision [obj]: 0.8\n",
            "Precision [subj]: 0.8\n",
            "Recall [obj]: 0.8\n",
            "Recall [subj]: 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Step 3: Building and testing a classifier with `nltk.sentiment.vader.SentimentIntensityAnalyzer`***"
      ],
      "metadata": {
        "id": "houZ2eJQfyrg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import `SentimentIntensityAnalyzer `from [Vader](http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf). This will assign an \"intensity score\" to each sentence based on its identified sentiment."
      ],
      "metadata": {
        "id": "y74QTxjAgDIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
      ],
      "metadata": {
        "id": "ktyOwbwJfy0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add list of sentences for analysis."
      ],
      "metadata": {
        "id": "HaN71m4Xgr0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"You are a jerk, and I will step on you.\",\n",
        "    \"THIS SUX!!!\",\n",
        "    \"This kinda sux...\",\n",
        "    \"You're good, man\",\n",
        "    \"HAHAHA YOU ARE THE BEST!!!!! VERY FUNNY!!!\"\n",
        "            ]"
      ],
      "metadata": {
        "id": "2BsReT4tgsCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use SentimentIntesnityAnalyzer (defined as sid) to get \"intensity\" of each sentence in list"
      ],
      "metadata": {
        "id": "-hXXSPfng3PM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "for sentence in sentences:\n",
        "    print('\\n' + sentence)\n",
        "    ss = sid.polarity_scores(sentence)\n",
        "    for k in sorted(ss):\n",
        "        print('{0}: {1}, '.format(k, ss[k]), end='')"
      ],
      "metadata": {
        "id": "8UCeoLBXg3bI",
        "outputId": "c06a619f-c35f-456f-bc1d-52ca7ec859bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "\n",
            "You are a jerk, and I will step on you.\n",
            "compound: -0.34, neg: 0.255, neu: 0.745, pos: 0.0, \n",
            "THIS SUX!!!\n",
            "compound: -0.5229, neg: 0.771, neu: 0.229, pos: 0.0, \n",
            "This kinda sux...\n",
            "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
            "You're good, man\n",
            "compound: 0.4404, neg: 0.0, neu: 0.408, pos: 0.592, \n",
            "HAHAHA YOU ARE THE BEST!!!!! VERY FUNNY!!!\n",
            "compound: 0.8386, neg: 0.0, neu: 0.386, pos: 0.614, "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tutorial 10: Gensim Word2Vec"
      ],
      "metadata": {
        "id": "ZuswKzvMl7JV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on [Dive Into NLTK, Part X: Play with Word2Vec Models based on NLTK Corpus by TextMiner](https://textminingonline.com/dive-into-nltk-part-x-play-with-word2vec-models-based-on-nltk-corpus)\n",
        "\n",
        "The word2vec algorithm uses a **neural network model** to learn **word associations** from a large corpus of text. Once trained, such a model can detect **synonymous words** or **suggest additional words** for a partial sentence. \n",
        "\n",
        "As the name implies, word2vec represents each distinct word with a **particular list of numbers** called a vector. The vectors are chosen carefully such that a simple mathematical function (the cosine similarity between the vectors) indicates the **level of semantic similarity** between the words represented by those vectors. \n",
        "\n",
        "[Learn more...](https://machinelearningmastery.com/develop-word-embeddings-python-gensim/)"
      ],
      "metadata": {
        "id": "QyNguEx7mC-6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Step 1: Exploring the gutenburg corpus***\n",
        "Project Gutenberg (PG) is a volunteer effort to digitize and archive cultural works. Most of the items in its collection are full texts of public domain books."
      ],
      "metadata": {
        "id": "QpVKjJ05naLZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "NPbB2UiGl6ic",
        "outputId": "69b7609c-43ee-4642-9d64-8405e16abc4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Project Gutenberg Selections http://gutenberg.net/  This corpus contains etexts from from Project Gutenberg, by the following authors:  * Jane Austen (3) * William Blake (2) * Thornton W. Burgess * Sarah Cone Bryant * Lewis Carroll * G. K. Chesterton (3) * Maria Edgeworth * King James Bible * Herman Melville * John Milton * William Shakespeare (3) * Walt Whitman  The beginning of the body of each book could not be identified automatically, so the semi-generic header of each file has been removed, and included below. Some source files ended with a line \"End of The Project Gutenberg Etext...\", and this has been deleted.  Information about Project Gutenberg (one page)  We produce about two million dollars for each hour we work.  The fifty hours is one conservative estimate for how long it we take to get any etext selected, entered, proofread, edited, copyright searched and analyzed, the copyright letters written, etc.  This projected audience is one hundred million readers.  If our value per text is nominally estimated at one dollar, then we produce 2 million dollars per hour this year we, will have to do four text files per month:  thus upping our productivity from one million. The Goal of Project Gutenberg is to Give Away One Trillion Etext Files by the December 31, 2001.  [10,000 x 100,000,000=Trillion] This is ten thousand titles each to one hundred million readers, which is 10% of the expected number of computer users by the end of the year 2001.  We need your donations more than ever!  All donations should be made to \"Project Gutenberg/IBC\", and are tax deductible to the extent allowable by law (\"IBC\" is Illinois Benedictine College).  (Subscriptions to our paper newsletter go to IBC, too)  For these and other matters, please mail to:  Project Gutenberg P. O. Box  2782 Champaign, IL 61825  When all other email fails try our Michael S. Hart, Executive Director: hart@vmd.cso.uiuc.edu (internet)   hart@uiucvmd   (bitnet)  We would prefer to send you this information by email (Internet, Bitnet, Compuserve, ATTMAIL or MCImail).  ****** If you have an FTP program (or emulator), please FTP directly to the Project Gutenberg archives: [Mac users, do NOT point and click. . .type]  ftp mrcnext.cso.uiuc.edu login:  anonymous password:  your@login cd etext/etext91 or cd etext92 or cd etext93 [for new books]  [now also in cd etext/etext93] or cd etext/articles [get suggest gut for more information] dir [to see files] get or mget [to get files. . .set bin for zip files] get INDEX100.GUT get INDEX200.GUT for a list of books and get NEW.GUT for general information and mget GUT* for newsletters.  **Information prepared by the Project Gutenberg legal advisor** (Three Pages)   ***START**THE SMALL PRINT!**FOR PUBLIC DOMAIN ETEXTS**START*** Why is this \"Small Print!\" statement here?  You know: lawyers. They tell us you might sue us if there is something wrong with your copy of this etext, even if you got it for free from someone other than us, and even if what\\'s wrong is not our fault.  So, among other things, this \"Small Print!\" statement disclaims most of our liability to you.  It also tells you how you can distribute copies of this etext if you want to.  *BEFORE!* YOU USE OR READ THIS ETEXT By using or reading any part of this PROJECT GUTENBERG-tm etext, you indicate that you understand, agree to and accept this \"Small Print!\" statement.  If you do not, you can receive a refund of the money (if any) you paid for this etext by sending a request within 30 days of receiving it to the person you got it from.  If you received this etext on a physical medium (such as a disk), you must return it with your request.  ABOUT PROJECT GUTENBERG-TM ETEXTS This PROJECT GUTENBERG-tm etext, like most PROJECT GUTENBERG- tm etexts, is a \"public domain\" work distributed by Professor Michael S. Hart through the Project Gutenberg Association at Illinois Benedictine College (the \"Project\").  Among other things, this means that no one owns a United States copyright on or for this work, so the Project (and you!) can copy and distribute it in the United States without permission and without paying copyright royalties.  Special rules, set forth below, apply if you wish to copy and distribute this etext under the Project\\'s \"PROJECT GUTENBERG\" trademark.  To create these etexts, the Project expends considerable efforts to identify, transcribe and proofread public domain works.  Despite these efforts, the Project\\'s etexts and any medium they may be on may contain \"Defects\".  Among other things, Defects may take the form of incomplete, inaccurate or corrupt data, transcription errors, a copyright or other intellectual property infringement, a defective or damaged disk or other etext medium, a computer virus, or computer codes that damage or cannot be read by your equipment.  LIMITED WARRANTY; DISCLAIMER OF DAMAGES But for the \"Right of Replacement or Refund\" described below, [1] the Project (and any other party you may receive this etext from as a PROJECT GUTENBERG-tm etext) disclaims all liability to you for damages, costs and expenses, including legal fees, and [2] YOU HAVE NO REMEDIES FOR NEGLIGENCE OR UNDER STRICT LIABILITY, OR FOR BREACH OF WARRANTY OR CONTRACT, INCLUDING BUT NOT LIMITED TO INDIRECT, CONSEQUENTIAL, PUNITIVE OR INCIDENTAL DAMAGES, EVEN IF YOU GIVE NOTICE OF THE POSSIBILITY OF SUCH DAMAGES.  If you discover a Defect in this etext within 90 days of receiving it, you can receive a refund of the money (if any) you paid for it by sending an explanatory note within that time to the person you received it from.  If you received it on a physical medium, you must return it with your note, and such person may choose to alternatively give you a replacement copy.  If you received it electronically, such person may choose to alternatively give you a second opportunity to receive it electronically.  THIS ETEXT IS OTHERWISE PROVIDED TO YOU \"AS-IS\".  NO OTHER WARRANTIES OF ANY KIND, EXPRESS OR IMPLIED, ARE MADE TO YOU AS TO THE ETEXT OR ANY MEDIUM IT MAY BE ON, INCLUDING BUT NOT LIMITED TO WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE.  Some states do not allow disclaimers of implied warranties or the exclusion or limitation of consequential damages, so the above disclaimers and exclusions may not apply to you, and you may have other legal rights.  INDEMNITY You will indemnify and hold the Project, its directors, officers, members and agents harmless from all liability, cost and expense, including legal fees, that arise directly or indirectly from any of the following that you do or cause: [1] distribution of this etext, [2] alteration, modification, or addition to the etext, or [3] any Defect.  DISTRIBUTION UNDER \"PROJECT GUTENBERG-tm\" You may distribute copies of this etext electronically, or by disk, book or any other medium if you either delete this \"Small Print!\" and all other references to Project Gutenberg, or:  [1]  Only give exact copies of it.  Among other things, this      requires that you do not remove, alter or modify the      etext or this \"small print!\" statement.  You may however,      if you wish, distribute this etext in machine readable      binary, compressed, mark-up, or proprietary form,      including any form resulting from conversion by word pro-      cessing or hypertext software, but only so long as      *EITHER*:       [*]  The etext, when displayed, is clearly readable, and           does *not* contain characters other than those           intended by the author of the work, although tilde           (~), asterisk (*) and underline (_) characters may           be used to convey punctuation intended by the           author, and additional characters may be used to           indicate hypertext links; OR       [*]  The etext may be readily converted by the reader at           no expense into plain ASCII, EBCDIC or equivalent           form by the program that displays the etext (as is           the case, for instance, with most word processors);           OR       [*]  You provide, or agree to also provide on request at           no additional cost, fee or expense, a copy of the           etext in its original plain ASCII form (or in EBCDIC           or other equivalent proprietary form).  [2]  Honor the etext refund and replacement provisions of this      \"Small Print!\" statement.  [3]  Pay a trademark license fee to the Project of 20% of the      net profits you derive calculated using the method you      already use to calculate your applicable taxes.  If you      don\\'t derive profits, no royalty is due.  Royalties are      payable to \"Project Gutenberg Association / Illinois      Benedictine College\" within the 60 days following each      date you prepare (or were legally required to prepare)      your annual (or equivalent periodic) tax return.  WHAT IF YOU *WANT* TO SEND MONEY EVEN IF YOU DON\\'T HAVE TO? The Project gratefully accepts contributions in money, time, scanning machines, OCR software, public domain etexts, royalty free copyright licenses, and every other sort of contribution you can think of.  Money should be paid to \"Project Gutenberg Association / Illinois Benedictine College\".  This \"Small Print!\" by Charles B. Kramer, Attorney Internet (72600.2026@compuserve.com); TEL: (212-254-5093) *END*THE SMALL PRINT! FOR PUBLIC DOMAIN ETEXTS*Ver.04.29.93*END* '"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('gutenberg')\n",
        "from nltk.corpus import gutenberg\n",
        "gutenberg.readme().replace('\\n', ' ')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explore file ids in Project Gutenberg - list of available texts."
      ],
      "metadata": {
        "id": "mFHG4CIFnpKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gutenberg.fileids()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kT4y6fXhnpRw",
        "outputId": "52ecfc8b-cd51-4ba6-b28f-93fe60b249ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['austen-emma.txt',\n",
              " 'austen-persuasion.txt',\n",
              " 'austen-sense.txt',\n",
              " 'bible-kjv.txt',\n",
              " 'blake-poems.txt',\n",
              " 'bryant-stories.txt',\n",
              " 'burgess-busterbrown.txt',\n",
              " 'carroll-alice.txt',\n",
              " 'chesterton-ball.txt',\n",
              " 'chesterton-brown.txt',\n",
              " 'chesterton-thursday.txt',\n",
              " 'edgeworth-parents.txt',\n",
              " 'melville-moby_dick.txt',\n",
              " 'milton-paradise.txt',\n",
              " 'shakespeare-caesar.txt',\n",
              " 'shakespeare-hamlet.txt',\n",
              " 'shakespeare-macbeth.txt',\n",
              " 'whitman-leaves.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get all sentences in the King James Bible text and print length."
      ],
      "metadata": {
        "id": "gO3j-0MGn02b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "bible_kjv_sents = gutenberg.sents('bible-kjv.txt')\n",
        "len(bible_kjv_sents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHfUxcUtn098",
        "outputId": "a7b09a6f-45a9-433e-dc26-080a6a2683aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30103"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Step 2: Implementing Word2Vec***"
      ],
      "metadata": {
        "id": "aFPLO2LBoGM7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean text of punctuation and lowercase all words in sentences, print example sentence to check cleaning."
      ],
      "metadata": {
        "id": "RdzY1snxn__s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "\n",
        "discard_punctuation_and_lowercased_sents = [[word.lower() for word in sent if word not in punctuation and word.isalpha()] \n",
        "                                            for sent in bible_kjv_sents]\n",
        "discard_punctuation_and_lowercased_sents[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pAyi5ssoAI0",
        "outputId": "4430dc71-1e39-497e-8ac8-ccdee7271140"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['in',\n",
              " 'the',\n",
              " 'beginning',\n",
              " 'god',\n",
              " 'created',\n",
              " 'the',\n",
              " 'heaven',\n",
              " 'and',\n",
              " 'the',\n",
              " 'earth']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import word2vec and create model based on KJV text; get and save word vectors."
      ],
      "metadata": {
        "id": "hb_NQAr9oaW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import word2vec\n",
        "\n",
        "bible_kjv_word2vec_model = word2vec.Word2Vec(discard_punctuation_and_lowercased_sents, min_count=5, size=200)\n",
        "bible_kjv_word2vec_model.save('bible_word2vec_gensim')\n",
        "# model = Word2Vec.load(fname) # To load a model\n",
        "word_vectors = bible_kjv_word2vec_model.wv\n",
        "del bible_kjv_word2vec_model # When we finish training the model, we can only delete it and keep the word vectors.\n",
        "word_vectors.save_word2vec_format('bible_word2vec_org', 'bible_word2vec_vocabulary')\n",
        "len(word_vectors.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIc3hSbHoagC",
        "outputId": "4c15b51d-734a-4fb5-abcd-491bd0bec14a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5279"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get most similar word vectors to \"god.\" \"Most similar\" means closest in the word graph. Word2vec is essentially about proportions of word occurrences in relations holding in general over large corpora of text. \n",
        "\n",
        "Consider the word analogy ‘man is to woman as king is to X’ which was famously demonstrated in word2vec. The algorithm is able to come up with an answer, *queen*, almost magically by simple vector differences. The main idea, called distributional hypothesis, is that similar words appear in similar contexts of words around them.\n"
      ],
      "metadata": {
        "id": "asPUNwXYpFui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors.most_similar(['god']) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCg2eKmLpF3l",
        "outputId": "8e0a31f2-88e2-4cce-8266-adfcfd44d21c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('truth', 0.7798963785171509),\n",
              " ('salvation', 0.7758899927139282),\n",
              " ('lord', 0.7544775009155273),\n",
              " ('hosts', 0.7544087171554565),\n",
              " ('faith', 0.7490318417549133),\n",
              " ('spirit', 0.7441205978393555),\n",
              " ('christ', 0.7392501831054688),\n",
              " ('fear', 0.712788462638855),\n",
              " ('glory', 0.7098792791366577),\n",
              " ('grace', 0.7070826292037964)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the most similar words to another word, this time displaying only the top 3 most similar."
      ],
      "metadata": {
        "id": "ksUAtldjpaQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors.most_similar(['heaven'], topn=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Vqd0YsspaYU",
        "outputId": "6f38dd7a-aa8b-4f63-d8a5-e2dc53ce0846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('earth', 0.7397711277008057),\n",
              " ('heavens', 0.7071738243103027),\n",
              " ('darkness', 0.6421352624893188)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try out analogy above, getting vector difference between \"king\" and unknown as based on that between two givens (woman and man)"
      ],
      "metadata": {
        "id": "QHJzlKzVpryZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbjzNoFjpr5a",
        "outputId": "28cdf5b5-6e07-4798-c233-87525ab2ef5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.6202816367149353)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `_cosmul` variant uses a slightly-different comparison when using multiple positive/negative examples (such as when asking about analogies). One paper has shown it does better:\n"
      ],
      "metadata": {
        "id": "j-_R4Rw7qFVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors.most_similar_cosmul(positive=['woman', 'king'], negative=['man'], topn=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uCeUoz0qFzx",
        "outputId": "e9ee6ade-6435-43b9-d1aa-644ebe790233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.970683217048645)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the similarity between two words"
      ],
      "metadata": {
        "id": "Q8qRDB1bqNwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors.similarity('lord', 'god')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEts7g6qqN3I",
        "outputId": "21b9275e-16c0-428c-860b-39b50f9c4e22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7544775"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get a word that does not \"match\" given words (significantly different vector)"
      ],
      "metadata": {
        "id": "2XXZL8lFqQDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors.doesnt_match(\"lord god salvation food spirit\".split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "6E15hcqNqQKy",
        "outputId": "8f61632d-4014-4251-e023-fdc3f05d5022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'food'"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}