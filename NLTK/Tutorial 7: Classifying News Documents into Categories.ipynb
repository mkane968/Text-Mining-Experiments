{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial 4-2: Classifying News Documents into Categories.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPl6pOPIhjRykcXRkUrdU0N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkane968/Text-Mining-Experiments/blob/main/NLTK/Tutorial%207%3A%20Classifying%20News%20Documents%20into%20Categories.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial 7: Classifying News Documents into Categories\n",
        "\n",
        "Based on Another Excercise: Classifying News Documents in Categories: sport, humor, adventure, science fiction, etc... in [Natural Language Processing with Python/NLTK by Luciano M. Guasco](https://github.com/luchux/ipython-notebook-nltk/blob/master/NLP%20-%20MelbDjango.ipynb)"
      ],
      "metadata": {
        "id": "lKOqWc42zipI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exploring the Brown corpus**\n",
        "\n",
        "The Corpus consists of 500 samples, distributed across 15 genres. Each sample began at a random sentence-boundary in the article or other unit chosen, and continued up to the first sentence boundary after 2,000 words.\n",
        "\n",
        "A. PRESS: Reportage (44 texts)\n",
        "\n",
        "B. PRESS: Editorial (27 texts)\n",
        "\n",
        "C. PRESS: Reviews (17 texts)\n",
        "\n",
        "D. RELIGION (17 texts)\n",
        "\n",
        "E. SKILL AND HOBBIES (36 texts)\n",
        "\n",
        "F. POPULAR LORE (48 texts)\n",
        "\n",
        "G. BELLES-LETTRES - Biography, Memoirs, etc. (75 texts)\n",
        "\n",
        "H. MISCELLANEOUS: US Government & House Organs (30 texts)\n",
        "\n",
        "J. LEARNED - Natural sciences, Medicine, Mathematics, etc. (80 texts)\n",
        "\n",
        "K. FICTION: General (29 texts)\n",
        "\n",
        "L. FICTION: Mystery and Detective Fiction (24 texts)\n",
        "\n",
        "M. FICTION: Science (6 texts)\n",
        "\n",
        "N. FICTION: Adventure and Western (29 texts)\n",
        "\n",
        "P. FICTION: Romance and Love Story (29 texts)\n",
        "\n",
        "R. HUMOR (9 texts)"
      ],
      "metadata": {
        "id": "GKj3q9-Dz852"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download brown corpus and clean spacing"
      ],
      "metadata": {
        "id": "fn__CLdFfKjs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "M0YDRqAazEh1",
        "outputId": "5ca5a9e3-1ea5-40c6-e81d-f70a3aa4e796"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'BROWN CORPUS  A Standard Corpus of Present-Day Edited American English, for use with Digital Computers.  by W. N. Francis and H. Kucera (1964) Department of Linguistics, Brown University Providence, Rhode Island, USA  Revised 1971, Revised and Amplified 1979  http://www.hit.uib.no/icame/brown/bcm.html  Distributed with the permission of the copyright holder, redistribution permitted. '"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('brown')\n",
        "\n",
        "from nltk.corpus import brown\n",
        "\n",
        "brown.readme().replace('\\n', ' ')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print file ids in Brown corpus"
      ],
      "metadata": {
        "id": "h4L0dUWRfM8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "brown.fileids()"
      ],
      "metadata": {
        "id": "VE3wqzpj0i9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get categories (genres of text) in Brown corpus"
      ],
      "metadata": {
        "id": "RYliITtefPV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "brown.categories()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IEyOteC0rkD",
        "outputId": "e97f59e3-5d8c-4b7f-c35c-47ccbc847e36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['adventure',\n",
              " 'belles_lettres',\n",
              " 'editorial',\n",
              " 'fiction',\n",
              " 'government',\n",
              " 'hobbies',\n",
              " 'humor',\n",
              " 'learned',\n",
              " 'lore',\n",
              " 'mystery',\n",
              " 'news',\n",
              " 'religion',\n",
              " 'reviews',\n",
              " 'romance',\n",
              " 'science_fiction']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print first sentence in specified file of brown corpus"
      ],
      "metadata": {
        "id": "82yw2YGmfXJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "brown.sents('ca01')[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atzpifoH0t73",
        "outputId": "c6f2f94a-99b2-4417-d2f4-da52a3bcc6ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'Fulton',\n",
              " 'County',\n",
              " 'Grand',\n",
              " 'Jury',\n",
              " 'said',\n",
              " 'Friday',\n",
              " 'an',\n",
              " 'investigation',\n",
              " 'of',\n",
              " \"Atlanta's\",\n",
              " 'recent',\n",
              " 'primary',\n",
              " 'election',\n",
              " 'produced',\n",
              " '``',\n",
              " 'no',\n",
              " 'evidence',\n",
              " \"''\",\n",
              " 'that',\n",
              " 'any',\n",
              " 'irregularities',\n",
              " 'took',\n",
              " 'place',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile a list of most popular words in the corpus\n",
        "\n",
        "Takes a bunch of tokens and returns the frequencies of all unique cases."
      ],
      "metadata": {
        "id": "c1rg4JBW020n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import FreqDist \n",
        "# Check if the word is alphabetical avoids including stuff like `` and '' which are actually pretty common. \n",
        "# Note that it also omits words such as 1 (very common), aug., 1913, $30, 13th, over-all etc. Another option would have been .isalnum().\n",
        "words_in_corpora = FreqDist(w.lower() for w in brown.words() if w.isalpha()) \n",
        "#words_in_corpora"
      ],
      "metadata": {
        "id": "B6fiKm5u047P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use this instead of sorted() to sort dictionary into a (mutable) list in order to delete the second column as opposed to into a tuple (immutable).\n"
      ],
      "metadata": {
        "id": "QcxK8N3Bffnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_corpora_freq_sorted = list(map(list, words_in_corpora.items()))\n",
        "#words_in_corpora_freq_sorted"
      ],
      "metadata": {
        "id": "mZJxzbwW1FpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sort words in corpus based on frequency"
      ],
      "metadata": {
        "id": "phNhzkhDfjUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_corpora_freq_sorted.sort(key=lambda x: x[1], reverse=True) # Using a lambda function is an alternative to using the operator library.\n",
        "words_in_corpora_freq_sorted"
      ],
      "metadata": {
        "id": "sYXSGlC71Si1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Put 1500 most frequent words in list into variable and delete word count (list item 1)\n"
      ],
      "metadata": {
        "id": "YsKiguyaflUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best1500 = words_in_corpora_freq_sorted[:1500]\n",
        "\n",
        "for list_item in best1500:\n",
        "    del list_item[1]\n",
        "\n",
        "#best1500"
      ],
      "metadata": {
        "id": "E4PU67jv1XVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since best1500 is now a list of words, it should be flattened. \n",
        "\n",
        "Break down the list into its individual sublists and then chain them. \n",
        "\n",
        "Chain further breaks down each sublist into its individual components so this approach can be used to flatten any list of lists."
      ],
      "metadata": {
        "id": "1BbKRgcRfyK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "chain = itertools.chain(*best1500) \n",
        "best1500 = list(chain) # chain is of type itertools.chain so we need the cast\n",
        "#best1500"
      ],
      "metadata": {
        "id": "EFAxauxc1ioy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Receives a list of words and removes stop words from list"
      ],
      "metadata": {
        "id": "qVwANZqhf7dI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stopw = stopwords.words('english')\n",
        "\n",
        "def nonstop(listwords):\n",
        "    return [word for word in listwords if word not in stopw]\n",
        "\n",
        "best1500_words_corpora = nonstop(best1500) # Note how this will probably contain less than 1500 words.\n",
        "#best1500_words_corpora"
      ],
      "metadata": {
        "id": "j096l7hX1uFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Converting corpus to form suitable for classification:*** Each file in the corpus will eventually be represented by a dictionary showing the presence of the corpusâ€™ most popular words in the particular file."
      ],
      "metadata": {
        "id": "OV9lfJZL13cB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# documents = [(nonstop(brown.words(fileid)), category) for category in brown.categories() for fileid in brown.fileids(category)]\n",
        "# documents # Note how documents is a list of tuples.\n",
        "\n",
        "# The code above generates a representation of the corpus but without removing punctuation. This is better:\n",
        "documents = [([item.lower() for item in nonstop(brown.words(fileid)) if item.isalpha()], category)\n",
        "             for category in brown.categories()\n",
        "             for fileid in brown.fileids(category)]\n",
        "documents # Note how documents is a list of tuples."
      ],
      "metadata": {
        "id": "ZTPt6D6312cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shuffle items in list of tuples"
      ],
      "metadata": {
        "id": "UzCvFVuhgBIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from random import shuffle\n",
        "\n",
        "shuffle(documents)\n",
        "documents"
      ],
      "metadata": {
        "id": "GfZ4KzwM2KWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given a document extract features (the presence or not of the 1500 most frequent words of the corpus)"
      ],
      "metadata": {
        "id": "U-_m2i9ygCQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def document_features(doc):\n",
        "    doc_set_words = set(doc) # Checking whether a word occurs in a set is much faster than checking whether it occurs in a list.\n",
        "    features_dic = {} # Features is a dictionary\n",
        "    for word in best1500_words_corpora:\n",
        "        features_dic['has(%s)' % word] = (word in doc_set_words)\n",
        "    return features_dic\n",
        "\n",
        "doc_features_set = [(document_features(d),c) for (d,c) in documents]\n",
        "doc_features_set[0]"
      ],
      "metadata": {
        "id": "b94GlVcq2TFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now build the classifer to determine what category documents fall into based on most frequent words"
      ],
      "metadata": {
        "id": "UoJRCaGG2gXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import NaiveBayesClassifier\n",
        "\n",
        "train_set = doc_features_set[:350] # Since the total is 500\n",
        "test_set  = doc_features_set[150:]\n",
        "\n",
        "classifier = NaiveBayesClassifier.train(train_set)\n",
        "classifier.show_most_informative_features(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIDW05Zx2oS0",
        "outputId": "0e060bbe-975c-43e9-e9a1-8d4ea07da3a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n",
            "             has(walked) = True           myster : learne =     29.7 : 1.0\n",
            "              has(music) = True           review : learne =     28.9 : 1.0\n",
            "                has(ran) = True           advent : learne =     28.5 : 1.0\n",
            "          has(afternoon) = True           fictio : learne =     27.2 : 1.0\n",
            "               has(road) = True           myster : learne =     27.1 : 1.0\n",
            "            has(playing) = True           review : learne =     26.2 : 1.0\n",
            "                has(god) = True           religi : learne =     25.8 : 1.0\n",
            "                has(car) = True            humor : learne =     25.3 : 1.0\n",
            "               has(hair) = True           romanc : learne =     23.8 : 1.0\n",
            "              has(maybe) = True           romanc : learne =     23.8 : 1.0\n",
            "            has(watched) = True           advent : learne =     22.6 : 1.0\n",
            "            has(kitchen) = True            humor : belles =     22.4 : 1.0\n",
            "          has(communism) = True           editor : learne =     22.1 : 1.0\n",
            "             has(berlin) = True           editor : learne =     22.1 : 1.0\n",
            "           has(watching) = True           romanc : learne =     21.7 : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get accuracy of classifier"
      ],
      "metadata": {
        "id": "UW1mLxb1gE8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.classify import accuracy\n",
        "\n",
        "print(accuracy(classifier, test_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nzpfE_12uL8",
        "outputId": "42a60d0b-5964-4208-ff7f-50e4874263bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7371428571428571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test classification of documet 'ca01' (it is under the 'news' category)"
      ],
      "metadata": {
        "id": "lYGTeBoLgGqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.classify(document_features(brown.words('ca01')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kr1sLuUo20TW",
        "outputId": "780afe3a-af05-4be4-f98d-22b220fc3271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'news'"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "# The test text needs to be long enough in order to contain a significant amount of the 1500 most common words in our training corpus.\n",
        "text = \"1 God, infinitely perfect and blessed in himself, in a plan of sheer goodness freely created man to make him share in his own blessed life. For this reason, at every time and in every place, God draws close to man. He calls man to seek him, to know him, to love him with all his strength. He calls together all men, scattered and divided by sin, into the unity of his family, the Church. To accomplish this, when the fullness of time had come, God sent his Son as Redeemer and Saviour. In his Son and through him, he invites men to become, in the Holy Spirit, his adopted children and thus heirs of his blessed life. 2 So that this call should resound throughout the world, Christ sent forth the apostles he had chosen, commissioning them to proclaim the gospel: \\\"Go therefore and make disciples of all nations, baptizing them in the name of the Father and of the Son and of the Holy Spirit, teaching them to observe all that I have commanded you; and lo, I am with you always, to the close of the age.\\\"4 Strengthened by this mission, the apostles \\\"went forth and preached everywhere, while the Lord worked with them and confirmed the message by the signs that attended it.\\\" 3 Those who with God's help have welcomed Christ's call and freely responded to it are urged on by love of Christ to proclaim the Good News everywhere in the world. This treasure, received from the apostles, has been faithfully guarded by their successors. All Christ's faithful are called to hand it on from generation to generation, by professing the faith, by living it in fraternal sharing, and by celebrating it in liturgy and prayer. 4 Quite early on, the name catechesis was given to the totality of the Church's efforts to make disciples, to help men believe that Jesus is the Son of God so that believing they might have life in his name, and to educate and instruct them in this life, thus building up the body of Christ. Catechesis is an education in the faith of children, young people and adults which includes especially the teaching of Christian doctrine imparted, generally speaking, in an organic and systematic way, with a view to initiating the hearers into the fullness of Christian life. While not being formally identified with them, catechesis is built on a certain number of elements of the Church's pastoral mission which have a catechetical aspect, that prepare for catechesis, or spring from it. They are: the initial proclamation of the Gospel or missionary preaching to arouse faith; examination of the reasons for belief; experience of Christian living; celebration of the sacraments; integration into the ecclesial community; and apostolic and missionary witness. Catechesis is intimately bound up with the whole of the Church's life. Not only her geographical extension and numerical increase, but even more her inner growth and correspondence with God's plan depend essentially on catechesis. Periods of renewal in the Church are also intense moments of catechesis. In the great era of the Fathers of the Church, saintly bishops devoted an important part of their ministry to catechesis. St. Cyril of Jerusalem and St. John Chrysostom, St. Ambrose and St. Augustine, and many other Fathers wrote catechetical works that remain models for us. The ministry of catechesis draws ever fresh energy from the councils. the Council of Trent is a noteworthy example of this. It gave catechesis priority in its constitutions and decrees. It lies at the origin of the Roman Catechism, which is also known by the name of that council and which is a work of the first rank as a summary of Christian teaching. The Council of Trent initiated a remarkable organization of the Church's catechesis. Thanks to the work of holy bishops and theologians such as St. Peter Canisius, St. Charles Borromeo, St. Turibius of Mongrovejo or St. Robert Bellarmine, it occasioned the publication of numerous catechisms. It is therefore no surprise that catechesis in the Church has again attracted attention in the wake of the Second Vatican Council, which Pope Paul Vl considered the great catechism of modern times. the General Catechetical Directory (1971) the sessions of the Synod of Bishops devoted to evangelization (1974) and catechesis (1977), the apostolic exhortations Evangelii nuntiandi (1975) and Catechesi tradendae (1979), attest to this. the Extraordinary Synod of Bishops in 1985 asked that a catechism or compendium of all Catholic doctrine regarding both faith and morals be composed. The Holy Father, Pope John Paul II, made the Synod's wish his own, acknowledging that this desire wholly corresponds to a real need of the universal Church and of the particular Churches. He set in motion everything needed to carry out the Synod Fathers' wish.\"\n",
        "\n",
        "tokenizer = RegexpTokenizer(r'\\w+') # Picks out sequences of alphanumeric characters as tokens and drops everything else\n",
        "text_tokens = nonstop(tokenizer.tokenize(text.lower()))\n",
        "text_tokens = [w for w in text_tokens if w.isalpha()]\n",
        "#text_tokens"
      ],
      "metadata": {
        "id": "M-EMaQVd270T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Determine whether list of tokens contain most frequent words set above"
      ],
      "metadata": {
        "id": "ZlOQHMLAgTNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_features = document_features(text_tokens)\n",
        "#text_features"
      ],
      "metadata": {
        "id": "IzMMcZ9T3CBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classifies new document based on presence of frequent words in brown corpus categories"
      ],
      "metadata": {
        "id": "aD_NtICOgV1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.classify(document_features(text_tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JcWp17aY3LzC",
        "outputId": "ec23b1fe-2215-4643-ec91-e72dc8334177"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'belles_lettres'"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}